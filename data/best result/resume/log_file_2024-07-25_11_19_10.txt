2024-07-25 11:19:12:INFO: Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True, 16-bits training: False
2024-07-25 11:19:12:INFO: Training/evaluation parameters Namespace(T_mult=1, adam_epsilon=1e-08, bigram_min_freq=1, char_min_freq=1, config_name='data/berts/bert/config.json', data_dir='data/dataset/NER/resume', dataset='resume', decay_rate=0.999, decay_steps=200, default_label='O', device=device(type='cuda', index=0), do_eval=True, do_predict=True, do_shuffle=True, do_train=True, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, label='all', label_file='data/dataset/NER/resume/labels.txt', label_num=28, lattice=1, lattice_min_freq=1, learning_rate=1e-05, lexicon_name='yj', local_rank=0, logging_dir='data/resume/log', logging_steps=100, max_grad_norm=1.0, max_scan_num=1000, max_seq_length=256, max_steps=-1, max_word_num=5, mid_data_dir='data/dataset/NER/resume/mid_data', mid_label_file='data/dataset/NER/resume/mid_data/labels.json', model_name_or_path='data/berts/bert/pytorch_model.bin', model_type='WCBertCRF_Token', n_gpu=1, no_cuda=False, nodes=2, num_tags=4, num_train_epochs=20, number_normalized=0, only_lexicon_in_train=False, only_train_min_freq=True, output_dir='data/result/NER/resume/lebertcrf', overwrite_cache=True, per_gpu_eval_batch_size=16, per_gpu_train_batch_size=4, rewarm_epoch_num=2, save_steps=600, save_total_limit=50, saved_embedding_dir='data/dataset/NER/resume', scheduler='CAWR', seed=106524, sgd_momentum=0.9, train_clip=False, vocab_file='data/berts/bert/vocab.txt', warmup_steps=190, weight_decay=0.0, word_embed_dim=200, word_embedding='data/embedding/word_embedding.txt', word_min_freq=1, word_vocab_file='data/vocab/tencent_vocab.txt')
2024-07-25 11:19:27:INFO: ***** Running training *****
2024-07-25 11:19:27:INFO:   Num examples = 3821
2024-07-25 11:19:27:INFO:   Num Epochs = 20
2024-07-25 11:19:27:INFO:   Instantaneous batch size per device = 4
2024-07-25 11:19:27:INFO:   Total train batch size (w. parallel, distributed & accumulation) = 4
2024-07-25 11:19:27:INFO:   Gradient Accumulation steps = 1
2024-07-25 11:19:27:INFO:   Total optimization steps = 19120
2024-07-25 11:20:02:INFO: {'loss': 5.689355545043945, 'learning_rate': 5.263157894736842e-06, 'epoch': 0, 'step': 100}
2024-07-25 11:20:29:INFO: {'loss': 2.059731542468071, 'learning_rate': 9.999993114453328e-06, 'epoch': 0, 'step': 200}
2024-07-25 11:20:57:INFO: {'loss': 0.6658371372520924, 'learning_rate': 9.999166871799133e-06, 'epoch': 0, 'step': 300}
2024-07-25 11:21:24:INFO: {'loss': 0.41597548618912694, 'learning_rate': 9.996963780557683e-06, 'epoch': 0, 'step': 400}
2024-07-25 11:21:52:INFO: {'loss': 0.3405097496137023, 'learning_rate': 9.993384447494693e-06, 'epoch': 0, 'step': 500}
2024-07-25 11:22:19:INFO: {'loss': 0.29116401739418507, 'learning_rate': 9.988429858414358e-06, 'epoch': 0, 'step': 600}
2024-07-25 11:22:46:INFO: {'loss': 0.254069485925138, 'learning_rate': 9.982101377887845e-06, 'epoch': 0, 'step': 700}
2024-07-25 11:23:13:INFO: {'loss': 0.2819487167522311, 'learning_rate': 9.974400748877469e-06, 'epoch': 0, 'step': 800}
2024-07-25 11:23:41:INFO: {'loss': 0.20945345567073673, 'learning_rate': 9.96533009225666e-06, 'epoch': 0, 'step': 900}
2024-07-25 11:23:56:INFO: ***** Running Dev *****
2024-07-25 11:23:56:INFO:   Num examples = 463
2024-07-25 11:23:56:INFO:   Batch size = 16
2024-07-25 11:24:06:INFO: {'acc': 0.9565334773218143, 'p': 0.9577352472089314, 'r': 0.94492525570417, 'f1': 0.9512871287128714, 'epoch': 0, 'step': 956}
2024-07-25 11:24:06:INFO: ***** Running Test *****
2024-07-25 11:24:06:INFO:   Num examples = 477
2024-07-25 11:24:06:INFO:   Batch size = 16
2024-07-25 11:24:16:INFO: {'acc': 0.955836551638221, 'p': 0.9590163934426229, 'r': 0.9380466472303207, 'f1': 0.948415622697126, 'epoch': 0, 'step': 956}
2024-07-25 11:24:27:INFO: {'loss': 0.22751292581204324, 'learning_rate': 9.954891906225833e-06, 'epoch': 1, 'step': 1000}
2024-07-25 11:24:54:INFO: {'loss': 0.18097189957741647, 'learning_rate': 9.943089065624343e-06, 'epoch': 1, 'step': 1100}
2024-07-25 11:25:21:INFO: {'loss': 0.1868227766850032, 'learning_rate': 9.929924821138723e-06, 'epoch': 1, 'step': 1200}
2024-07-25 11:25:48:INFO: {'loss': 0.2088564135413617, 'learning_rate': 9.915402798407383e-06, 'epoch': 1, 'step': 1300}
2024-07-25 11:26:14:INFO: {'loss': 0.16702048897743224, 'learning_rate': 9.899526997022054e-06, 'epoch': 1, 'step': 1400}
2024-07-25 11:26:41:INFO: {'loss': 0.12808889885200186, 'learning_rate': 9.882301789426234e-06, 'epoch': 1, 'step': 1500}
2024-07-25 11:27:07:INFO: {'loss': 0.16819071188219822, 'learning_rate': 9.863731919710964e-06, 'epoch': 1, 'step': 1600}
2024-07-25 11:27:34:INFO: {'loss': 0.13733622412546537, 'learning_rate': 9.843822502308213e-06, 'epoch': 1, 'step': 1700}
2024-07-25 11:28:00:INFO: {'loss': 0.18753727310919202, 'learning_rate': 9.822579020582297e-06, 'epoch': 1, 'step': 1800}
2024-07-25 11:28:27:INFO: {'loss': 0.1651024650596082, 'learning_rate': 9.800007325319666e-06, 'epoch': 1, 'step': 1900}
2024-07-25 11:28:30:INFO: ***** Running Dev *****
2024-07-25 11:28:30:INFO:   Num examples = 463
2024-07-25 11:28:30:INFO:   Batch size = 16
2024-07-25 11:28:39:INFO: {'acc': 0.9605156587473002, 'p': 0.9655448717948718, 'r': 0.948072383949646, 'f1': 0.9567288606589917, 'epoch': 1, 'step': 1912}
2024-07-25 11:28:39:INFO: ***** Running Test *****
2024-07-25 11:28:39:INFO:   Num examples = 477
2024-07-25 11:28:39:INFO:   Batch size = 16
2024-07-25 11:28:48:INFO: {'acc': 0.9612557618039118, 'p': 0.9674315321983715, 'r': 0.9526239067055393, 'f1': 0.959970620639001, 'epoch': 1, 'step': 1912}
2024-07-25 11:29:12:INFO: {'loss': 0.1331190046586562, 'learning_rate': 9.776113633117514e-06, 'epoch': 2, 'step': 2000}
2024-07-25 11:29:39:INFO: {'loss': 0.0834590419899905, 'learning_rate': 9.750904524671623e-06, 'epoch': 2, 'step': 2100}
2024-07-25 11:30:06:INFO: {'loss': 0.13924831276817712, 'learning_rate': 9.72438694296394e-06, 'epoch': 2, 'step': 2200}
2024-07-25 11:30:32:INFO: {'loss': 0.13391175986558665, 'learning_rate': 9.696568191350373e-06, 'epoch': 2, 'step': 2300}
2024-07-25 11:30:59:INFO: {'loss': 0.1079091754637193, 'learning_rate': 9.667455931549336e-06, 'epoch': 2, 'step': 2400}
2024-07-25 11:31:25:INFO: {'loss': 0.11626202049024868, 'learning_rate': 9.637058181531583e-06, 'epoch': 2, 'step': 2500}
2024-07-25 11:31:52:INFO: {'loss': 0.12011187256139237, 'learning_rate': 9.605383313311937e-06, 'epoch': 2, 'step': 2600}
2024-07-25 11:32:18:INFO: {'loss': 0.11391771355585661, 'learning_rate': 9.572440050643515e-06, 'epoch': 2, 'step': 2700}
2024-07-25 11:32:45:INFO: {'loss': 0.15489592700818322, 'learning_rate': 9.538237466615057e-06, 'epoch': 2, 'step': 2800}
2024-07-25 11:33:03:INFO: ***** Running Dev *****
2024-07-25 11:33:03:INFO:   Num examples = 463
2024-07-25 11:33:03:INFO:   Batch size = 16
2024-07-25 11:33:12:INFO: {'acc': 0.9624730021598272, 'p': 0.9669811320754716, 'r': 0.967741935483871, 'f1': 0.9673613841918994, 'epoch': 2, 'step': 2868}
2024-07-25 11:33:12:INFO: ***** Running Test *****
2024-07-25 11:33:12:INFO:   Num examples = 477
2024-07-25 11:33:12:INFO:   Batch size = 16
2024-07-25 11:33:21:INFO: {'acc': 0.9674224492338358, 'p': 0.9705014749262537, 'r': 0.9591836734693877, 'f1': 0.9648093841642229, 'epoch': 2, 'step': 2868}
2024-07-25 11:33:30:INFO: {'loss': 0.1057664739433676, 'learning_rate': 9.502784981152066e-06, 'epoch': 3, 'step': 2900}
2024-07-25 11:33:56:INFO: {'loss': 0.08983820524968905, 'learning_rate': 9.466092358422405e-06, 'epoch': 3, 'step': 3000}
2024-07-25 11:34:23:INFO: {'loss': 0.09475116238172632, 'learning_rate': 9.4281697041471e-06, 'epoch': 3, 'step': 3100}
2024-07-25 11:34:50:INFO: {'loss': 0.09272452686942416, 'learning_rate': 9.389027462817066e-06, 'epoch': 3, 'step': 3200}
2024-07-25 11:35:16:INFO: {'loss': 0.09856362135149538, 'learning_rate': 9.348676414816526e-06, 'epoch': 3, 'step': 3300}
2024-07-25 11:35:42:INFO: {'loss': 0.07685776881822676, 'learning_rate': 9.307127673453928e-06, 'epoch': 3, 'step': 3400}
2024-07-25 11:36:09:INFO: {'loss': 0.10535564929065004, 'learning_rate': 9.264392681901166e-06, 'epoch': 3, 'step': 3500}
2024-07-25 11:36:35:INFO: {'loss': 0.0889267052678042, 'learning_rate': 9.220483210041958e-06, 'epoch': 3, 'step': 3600}
2024-07-25 11:37:02:INFO: {'loss': 0.0755471710562415, 'learning_rate': 9.175411351230221e-06, 'epoch': 3, 'step': 3700}
2024-07-25 11:37:28:INFO: {'loss': 0.0865015725565172, 'learning_rate': 9.129189518959393e-06, 'epoch': 3, 'step': 3800}
2024-07-25 11:37:35:INFO: ***** Running Dev *****
2024-07-25 11:37:35:INFO:   Num examples = 463
2024-07-25 11:37:35:INFO:   Batch size = 16
2024-07-25 11:37:44:INFO: {'acc': 0.9721247300215983, 'p': 0.9669551534225019, 'r': 0.9669551534225019, 'f1': 0.9669551534225019, 'epoch': 3, 'step': 3824}
2024-07-25 11:37:44:INFO: ***** Running Test *****
2024-07-25 11:37:44:INFO:   Num examples = 477
2024-07-25 11:37:44:INFO:   Batch size = 16
2024-07-25 11:37:53:INFO: {'acc': 0.9712844150990407, 'p': 0.9727740986019132, 'r': 0.9635568513119533, 'f1': 0.9681435371658733, 'epoch': 3, 'step': 3824}
2024-07-25 11:38:13:INFO: {'loss': 0.06412360252303188, 'learning_rate': 9.081830443443542e-06, 'epoch': 4, 'step': 3900}
2024-07-25 11:38:40:INFO: {'loss': 0.10245146296780148, 'learning_rate': 9.033347168111282e-06, 'epoch': 4, 'step': 4000}
2024-07-25 11:39:07:INFO: {'loss': 0.06913977393684036, 'learning_rate': 8.983753046013403e-06, 'epoch': 4, 'step': 4100}
2024-07-25 11:39:34:INFO: {'loss': 0.051409414077788824, 'learning_rate': 8.933061736145236e-06, 'epoch': 4, 'step': 4200}
2024-07-25 11:40:01:INFO: {'loss': 0.0875606841807894, 'learning_rate': 8.881287199684743e-06, 'epoch': 4, 'step': 4300}
2024-07-25 11:40:27:INFO: {'loss': 0.05313725080595759, 'learning_rate': 8.828443696147403e-06, 'epoch': 4, 'step': 4400}
2024-07-25 11:40:54:INFO: {'loss': 0.06310475771879283, 'learning_rate': 8.774545779458912e-06, 'epoch': 4, 'step': 4500}
2024-07-25 11:41:20:INFO: {'loss': 0.10195627465713188, 'learning_rate': 8.719608293946801e-06, 'epoch': 4, 'step': 4600}
2024-07-25 11:41:47:INFO: {'loss': 0.05839840650402039, 'learning_rate': 8.663646370252093e-06, 'epoch': 4, 'step': 4700}
2024-07-25 11:42:08:INFO: ***** Running Dev *****
2024-07-25 11:42:08:INFO:   Num examples = 463
2024-07-25 11:42:08:INFO:   Batch size = 16
2024-07-25 11:42:17:INFO: {'acc': 0.970707343412527, 'p': 0.9684293606945541, 'r': 0.9653815892997639, 'f1': 0.966903073286052, 'epoch': 4, 'step': 4780}
2024-07-25 11:42:17:INFO: ***** Running Test *****
2024-07-25 11:42:17:INFO:   Num examples = 477
2024-07-25 11:42:17:INFO:   Batch size = 16
2024-07-25 11:42:27:INFO: {'acc': 0.9712844150990407, 'p': 0.9720176730486009, 'r': 0.9620991253644315, 'f1': 0.967032967032967, 'epoch': 4, 'step': 4780}
2024-07-25 11:42:32:INFO: {'loss': 0.06681673028353544, 'learning_rate': 8.606675421162064e-06, 'epoch': 5, 'step': 4800}
2024-07-25 11:42:58:INFO: {'loss': 0.05337255898666626, 'learning_rate': 8.54871113736534e-06, 'epoch': 5, 'step': 4900}
2024-07-25 11:43:25:INFO: {'loss': 0.03247929020988522, 'learning_rate': 8.48976948313043e-06, 'epoch': 5, 'step': 5000}
2024-07-25 11:43:52:INFO: {'loss': 0.06070920947000559, 'learning_rate': 8.429866691908916e-06, 'epoch': 5, 'step': 5100}
2024-07-25 11:44:18:INFO: {'loss': 0.04594566312665847, 'learning_rate': 8.369019261864506e-06, 'epoch': 5, 'step': 5200}
2024-07-25 11:44:45:INFO: {'loss': 0.04498940476303687, 'learning_rate': 8.30724395132919e-06, 'epoch': 5, 'step': 5300}
2024-07-25 11:45:11:INFO: {'loss': 0.03359980162651482, 'learning_rate': 8.24455777418772e-06, 'epoch': 5, 'step': 5400}
2024-07-25 11:45:38:INFO: {'loss': 0.08933032049058966, 'learning_rate': 8.18097799519174e-06, 'epoch': 5, 'step': 5500}
2024-07-25 11:46:05:INFO: {'loss': 0.05116026715913904, 'learning_rate': 8.116522125204783e-06, 'epoch': 5, 'step': 5600}
2024-07-25 11:46:31:INFO: {'loss': 0.07531037633241794, 'learning_rate': 8.05120791637952e-06, 'epoch': 5, 'step': 5700}
2024-07-25 11:46:41:INFO: ***** Running Dev *****
2024-07-25 11:46:41:INFO:   Num examples = 463
2024-07-25 11:46:41:INFO:   Batch size = 16
2024-07-25 11:46:50:INFO: {'acc': 0.9771868250539957, 'p': 0.9753968253968254, 'r': 0.9669551534225019, 'f1': 0.9711576451995259, 'epoch': 5, 'step': 5736}
2024-07-25 11:46:50:INFO: ***** Running Test *****
2024-07-25 11:46:50:INFO:   Num examples = 477
2024-07-25 11:46:50:INFO:   Batch size = 16
2024-07-25 11:46:59:INFO: {'acc': 0.9652423072131556, 'p': 0.9748334566987417, 'r': 0.9599125364431487, 'f1': 0.9673154608887256, 'epoch': 5, 'step': 5736}
2024-07-25 11:47:16:INFO: {'loss': 0.05906343163562269, 'learning_rate': 7.985053357268533e-06, 'epoch': 6, 'step': 5800}
2024-07-25 11:47:43:INFO: {'loss': 0.057595525843426004, 'learning_rate': 7.918076667869996e-06, 'epoch': 6, 'step': 5900}
2024-07-25 11:48:09:INFO: {'loss': 0.04796760316574364, 'learning_rate': 7.850296294609586e-06, 'epoch': 6, 'step': 6000}
2024-07-25 11:48:36:INFO: {'loss': 0.03030355225324456, 'learning_rate': 7.78173090526007e-06, 'epoch': 6, 'step': 6100}
2024-07-25 11:49:02:INFO: {'loss': 0.05504909603932902, 'learning_rate': 7.712399383799896e-06, 'epoch': 6, 'step': 6200}
2024-07-25 11:49:29:INFO: {'loss': 0.028890599378792105, 'learning_rate': 7.642320825212248e-06, 'epoch': 6, 'step': 6300}
2024-07-25 11:49:55:INFO: {'loss': 0.034511237007936874, 'learning_rate': 7.571514530226004e-06, 'epoch': 6, 'step': 6400}
2024-07-25 11:50:22:INFO: {'loss': 0.03216261230129021, 'learning_rate': 7.500000000000001e-06, 'epoch': 6, 'step': 6500}
2024-07-25 11:50:49:INFO: {'loss': 0.057515085790946614, 'learning_rate': 7.4277969307521135e-06, 'epoch': 6, 'step': 6600}
2024-07-25 11:51:13:INFO: ***** Running Dev *****
2024-07-25 11:51:13:INFO:   Num examples = 463
2024-07-25 11:51:13:INFO:   Batch size = 16
2024-07-25 11:51:22:INFO: {'acc': 0.9776592872570194, 'p': 0.9724842767295597, 'r': 0.973249409913454, 'f1': 0.9728666928824223, 'epoch': 6, 'step': 6692}
2024-07-25 11:51:22:INFO: ***** Running Test *****
2024-07-25 11:51:22:INFO:   Num examples = 477
2024-07-25 11:51:22:INFO:   Batch size = 16
2024-07-25 11:51:31:INFO: {'acc': 0.9719696025912545, 'p': 0.9706744868035191, 'r': 0.9650145772594753, 'f1': 0.9678362573099415, 'epoch': 6, 'step': 6692}
2024-07-25 11:51:33:INFO: {'loss': 0.05366652890405021, 'learning_rate': 7.354925208334615e-06, 'epoch': 7, 'step': 6700}
2024-07-25 11:52:00:INFO: {'loss': 0.0234533706973707, 'learning_rate': 7.2814049027572945e-06, 'epoch': 7, 'step': 6800}
2024-07-25 11:52:27:INFO: {'loss': 0.03289146628601884, 'learning_rate': 7.207256262659868e-06, 'epoch': 7, 'step': 6900}
2024-07-25 11:52:53:INFO: {'loss': 0.03500517051397765, 'learning_rate': 7.132499709735187e-06, 'epoch': 7, 'step': 7000}
2024-07-25 11:53:20:INFO: {'loss': 0.022274322147168277, 'learning_rate': 7.057155833104783e-06, 'epoch': 7, 'step': 7100}
2024-07-25 11:53:46:INFO: {'loss': 0.05809220908930001, 'learning_rate': 6.981245383648304e-06, 'epoch': 7, 'step': 7200}
2024-07-25 11:54:13:INFO: {'loss': 0.04984177695847393, 'learning_rate': 6.904789268288399e-06, 'epoch': 7, 'step': 7300}
2024-07-25 11:54:40:INFO: {'loss': 0.037961967873379764, 'learning_rate': 6.82780854423262e-06, 'epoch': 7, 'step': 7400}
2024-07-25 11:55:06:INFO: {'loss': 0.04221335116081718, 'learning_rate': 6.750324413173948e-06, 'epoch': 7, 'step': 7500}
2024-07-25 11:55:33:INFO: {'loss': 0.05571867248918352, 'learning_rate': 6.672358215451506e-06, 'epoch': 7, 'step': 7600}
2024-07-25 11:55:45:INFO: ***** Running Dev *****
2024-07-25 11:55:45:INFO:   Num examples = 463
2024-07-25 11:55:45:INFO:   Batch size = 16
2024-07-25 11:55:54:INFO: {'acc': 0.9731371490280778, 'p': 0.971764705882353, 'r': 0.974822974036192, 'f1': 0.9732914375490966, 'epoch': 7, 'step': 7648}
2024-07-25 11:55:54:INFO: ***** Running Test *****
2024-07-25 11:55:54:INFO:   Num examples = 477
2024-07-25 11:55:54:INFO:   Batch size = 16
2024-07-25 11:56:04:INFO: {'acc': 0.9675470287778747, 'p': 0.9649890590809628, 'r': 0.9642857142857143, 'f1': 0.964637258476121, 'epoch': 7, 'step': 7648}
2024-07-25 11:56:17:INFO: {'loss': 0.023980293848489966, 'learning_rate': 6.593931424173102e-06, 'epoch': 8, 'step': 7700}
2024-07-25 11:56:44:INFO: {'loss': 0.029298732174147517, 'learning_rate': 6.515065639301199e-06, 'epoch': 8, 'step': 7800}
2024-07-25 11:57:11:INFO: {'loss': 0.02454487585247989, 'learning_rate': 6.435782581703944e-06, 'epoch': 8, 'step': 7900}
2024-07-25 11:57:37:INFO: {'loss': 0.02636475589642032, 'learning_rate': 6.356104087172916e-06, 'epoch': 8, 'step': 8000}
2024-07-25 11:58:04:INFO: {'loss': 0.0196416608722393, 'learning_rate': 6.276052100409185e-06, 'epoch': 8, 'step': 8100}
2024-07-25 11:58:31:INFO: {'loss': 0.03231414413764469, 'learning_rate': 6.195648668979417e-06, 'epoch': 8, 'step': 8200}
2024-07-25 11:58:57:INFO: {'loss': 0.04810893862948433, 'learning_rate': 6.11491593724363e-06, 'epoch': 8, 'step': 8300}
2024-07-25 11:59:24:INFO: {'loss': 0.022537493718737096, 'learning_rate': 6.033876140256276e-06, 'epoch': 8, 'step': 8400}
2024-07-25 11:59:50:INFO: {'loss': 0.031419612723784664, 'learning_rate': 5.952551597642377e-06, 'epoch': 8, 'step': 8500}
2024-07-25 12:00:17:INFO: {'loss': 0.033958485290495444, 'learning_rate': 5.870964707450348e-06, 'epoch': 8, 'step': 8600}
2024-07-25 12:00:18:INFO: ***** Running Dev *****
2024-07-25 12:00:18:INFO:   Num examples = 463
2024-07-25 12:00:18:INFO:   Batch size = 16
2024-07-25 12:00:27:INFO: {'acc': 0.9796166306695464, 'p': 0.9762658227848101, 'r': 0.970889063729347, 'f1': 0.9735700197238659, 'epoch': 8, 'step': 8604}
2024-07-25 12:00:27:INFO: ***** Running Test *****
2024-07-25 12:00:27:INFO:   Num examples = 477
2024-07-25 12:00:27:INFO:   Batch size = 16
2024-07-25 12:00:36:INFO: {'acc': 0.9713467048710601, 'p': 0.9699413489736071, 'r': 0.9642857142857143, 'f1': 0.9671052631578948, 'epoch': 8, 'step': 8604}
2024-07-25 12:01:02:INFO: {'loss': 0.017158505079969473, 'learning_rate': 5.789137939983211e-06, 'epoch': 9, 'step': 8700}
2024-07-25 12:01:28:INFO: {'loss': 0.02676668936119313, 'learning_rate': 5.707093831609945e-06, 'epoch': 9, 'step': 8800}
2024-07-25 12:01:55:INFO: {'loss': 0.0195790384519114, 'learning_rate': 5.6248549785586005e-06, 'epoch': 9, 'step': 8900}
2024-07-25 12:02:21:INFO: {'loss': 0.025279083837813233, 'learning_rate': 5.542444030692954e-06, 'epoch': 9, 'step': 9000}
2024-07-25 12:02:48:INFO: {'loss': 0.025104063750486603, 'learning_rate': 5.459883685274378e-06, 'epoch': 9, 'step': 9100}
2024-07-25 12:03:14:INFO: {'loss': 0.016076644508466416, 'learning_rate': 5.377196680710668e-06, 'epoch': 9, 'step': 9200}
2024-07-25 12:03:41:INFO: {'loss': 0.017588280788104385, 'learning_rate': 5.2944057902935195e-06, 'epoch': 9, 'step': 9300}
2024-07-25 12:04:08:INFO: {'loss': 0.03932229359982557, 'learning_rate': 5.211533815926417e-06, 'epoch': 9, 'step': 9400}
2024-07-25 12:04:34:INFO: {'loss': 0.005686642285672861, 'learning_rate': 5.12860358184463e-06, 'epoch': 9, 'step': 9500}
2024-07-25 12:04:50:INFO: ***** Running Dev *****
2024-07-25 12:04:50:INFO:   Num examples = 463
2024-07-25 12:04:50:INFO:   Batch size = 16
2024-07-25 12:04:59:INFO: {'acc': 0.9731371490280778, 'p': 0.9754940711462451, 'r': 0.970889063729347, 'f1': 0.9731861198738171, 'epoch': 9, 'step': 9560}
2024-07-25 12:04:59:INFO: ***** Running Test *****
2024-07-25 12:04:59:INFO:   Num examples = 477
2024-07-25 12:04:59:INFO:   Batch size = 16
2024-07-25 12:05:09:INFO: {'acc': 0.9689174037623022, 'p': 0.9720176730486009, 'r': 0.9620991253644315, 'f1': 0.967032967032967, 'epoch': 9, 'step': 9560}
2024-07-25 12:05:19:INFO: {'loss': 0.020410823003703626, 'learning_rate': 5.04563792832906e-06, 'epoch': 10, 'step': 9600}
2024-07-25 12:05:46:INFO: {'loss': 0.021503036465328477, 'learning_rate': 4.962659705415677e-06, 'epoch': 10, 'step': 9700}
2024-07-25 12:06:12:INFO: {'loss': 0.005682746678226067, 'learning_rate': 4.879691766602261e-06, 'epoch': 10, 'step': 9800}
2024-07-25 12:06:39:INFO: {'loss': 0.01222579089735973, 'learning_rate': 4.79675696255418e-06, 'epoch': 10, 'step': 9900}
2024-07-25 12:07:06:INFO: {'loss': 0.00917239470786626, 'learning_rate': 4.7138781348109845e-06, 'epoch': 10, 'step': 10000}
2024-07-25 12:07:32:INFO: {'loss': 0.02051957108728857, 'learning_rate': 4.631078109495468e-06, 'epoch': 10, 'step': 10100}
2024-07-25 12:07:59:INFO: {'loss': 0.021431570355002805, 'learning_rate': 4.548379691027005e-06, 'epoch': 10, 'step': 10200}
2024-07-25 12:08:25:INFO: {'loss': 0.021315773274163802, 'learning_rate': 4.465805655840864e-06, 'epoch': 10, 'step': 10300}
2024-07-25 12:08:52:INFO: {'loss': 0.01214342816763292, 'learning_rate': 4.383378746115215e-06, 'epoch': 10, 'step': 10400}
2024-07-25 12:09:18:INFO: {'loss': 0.010109937228003218, 'learning_rate': 4.301121663507571e-06, 'epoch': 10, 'step': 10500}
2024-07-25 12:09:23:INFO: ***** Running Dev *****
2024-07-25 12:09:23:INFO:   Num examples = 463
2024-07-25 12:09:23:INFO:   Batch size = 16
2024-07-25 12:09:32:INFO: {'acc': 0.9807640388768899, 'p': 0.9748031496062992, 'r': 0.9740361919748229, 'f1': 0.9744195198740654, 'epoch': 10, 'step': 10516}
2024-07-25 12:09:32:INFO: ***** Running Test *****
2024-07-25 12:09:32:INFO:   Num examples = 477
2024-07-25 12:09:32:INFO:   Batch size = 16
2024-07-25 12:09:41:INFO: {'acc': 0.968605954902205, 'p': 0.971386647101981, 'r': 0.9650145772594753, 'f1': 0.9681901279707497, 'epoch': 10, 'step': 10516}
2024-07-25 12:10:03:INFO: {'loss': 0.014678781512761816, 'learning_rate': 4.219057062902417e-06, 'epoch': 11, 'step': 10600}
2024-07-25 12:10:30:INFO: {'loss': 0.006208303080115911, 'learning_rate': 4.1372075461716885e-06, 'epoch': 11, 'step': 10700}
2024-07-25 12:10:56:INFO: {'loss': 0.011582770401273592, 'learning_rate': 4.055595655949856e-06, 'epoch': 11, 'step': 10800}
2024-07-25 12:11:23:INFO: {'loss': 0.013026279976677414, 'learning_rate': 3.974243869425348e-06, 'epoch': 11, 'step': 10900}
2024-07-25 12:11:50:INFO: {'loss': 0.006507870063974224, 'learning_rate': 3.893174592149976e-06, 'epoch': 11, 'step': 11000}
2024-07-25 12:12:16:INFO: {'loss': 0.01902093276145479, 'learning_rate': 3.812410151868092e-06, 'epoch': 11, 'step': 11100}
2024-07-25 12:12:43:INFO: {'loss': 0.011497347305898985, 'learning_rate': 3.731972792367179e-06, 'epoch': 11, 'step': 11200}
2024-07-25 12:13:09:INFO: {'loss': 0.009750426429750405, 'learning_rate': 3.6518846673515717e-06, 'epoch': 11, 'step': 11300}
2024-07-25 12:13:36:INFO: {'loss': 0.011501277089892029, 'learning_rate': 3.572167834340977e-06, 'epoch': 11, 'step': 11400}
2024-07-25 12:13:55:INFO: ***** Running Dev *****
2024-07-25 12:13:55:INFO:   Num examples = 463
2024-07-25 12:13:55:INFO:   Batch size = 16
2024-07-25 12:14:04:INFO: {'acc': 0.9782667386609071, 'p': 0.9755134281200631, 'r': 0.971675845790716, 'f1': 0.9735908553409538, 'epoch': 11, 'step': 11472}
2024-07-25 12:14:04:INFO: ***** Running Test *****
2024-07-25 12:14:04:INFO:   Num examples = 477
2024-07-25 12:14:04:INFO:   Batch size = 16
2024-07-25 12:14:13:INFO: {'acc': 0.9707860969228853, 'p': 0.9706529713866471, 'r': 0.9642857142857143, 'f1': 0.9674588665447897, 'epoch': 11, 'step': 11472}
2024-07-25 12:14:21:INFO: {'loss': 0.012425730977615785, 'learning_rate': 3.4928442485954826e-06, 'epoch': 12, 'step': 11500}
2024-07-25 12:14:47:INFO: {'loss': 0.008870789178574796, 'learning_rate': 3.413935757068748e-06, 'epoch': 12, 'step': 11600}
2024-07-25 12:15:14:INFO: {'loss': 0.018189450022455277, 'learning_rate': 3.335464092391003e-06, 'epoch': 12, 'step': 11700}
2024-07-25 12:15:40:INFO: {'loss': 0.012160942482896644, 'learning_rate': 3.2574508668835426e-06, 'epoch': 12, 'step': 11800}
2024-07-25 12:16:07:INFO: {'loss': 0.016499755470454146, 'learning_rate': 3.1799175666063615e-06, 'epoch': 12, 'step': 11900}
2024-07-25 12:16:34:INFO: {'loss': 0.01738647111526916, 'learning_rate': 3.102885545440556e-06, 'epoch': 12, 'step': 12000}
2024-07-25 12:17:00:INFO: {'loss': 0.008655036100731196, 'learning_rate': 3.026376019207126e-06, 'epoch': 12, 'step': 12100}
2024-07-25 12:17:27:INFO: {'loss': 0.009868565460567424, 'learning_rate': 2.950410059823816e-06, 'epoch': 12, 'step': 12200}
2024-07-25 12:17:53:INFO: {'loss': 0.010614708925079413, 'learning_rate': 2.8750085895015758e-06, 'epoch': 12, 'step': 12300}
2024-07-25 12:18:20:INFO: {'loss': 0.015398087009880329, 'learning_rate': 2.8001923749822524e-06, 'epoch': 12, 'step': 12400}
2024-07-25 12:18:27:INFO: ***** Running Dev *****
2024-07-25 12:18:27:INFO:   Num examples = 463
2024-07-25 12:18:27:INFO:   Batch size = 16
2024-07-25 12:18:36:INFO: {'acc': 0.9757694384449244, 'p': 0.9731649565903709, 'r': 0.970102281667978, 'f1': 0.9716312056737589, 'epoch': 12, 'step': 12428}
2024-07-25 12:18:36:INFO: ***** Running Test *****
2024-07-25 12:18:36:INFO:   Num examples = 477
2024-07-25 12:18:36:INFO:   Batch size = 16
2024-07-25 12:18:45:INFO: {'acc': 0.9730908184876044, 'p': 0.9692532942898975, 'r': 0.9650145772594753, 'f1': 0.9671292914536157, 'epoch': 12, 'step': 12428}
2024-07-25 12:19:05:INFO: {'loss': 0.010632482045893994, 'learning_rate': 2.7259820218191123e-06, 'epoch': 13, 'step': 12500}
2024-07-25 12:19:31:INFO: {'loss': 0.01161176465354174, 'learning_rate': 2.6523979687017516e-06, 'epoch': 13, 'step': 12600}
2024-07-25 12:19:58:INFO: {'loss': 0.007936992053801077, 'learning_rate': 2.579460481826947e-06, 'epoch': 13, 'step': 12700}
2024-07-25 12:20:24:INFO: {'loss': 0.0076135209026142545, 'learning_rate': 2.5071896493170533e-06, 'epoch': 13, 'step': 12800}
2024-07-25 12:20:51:INFO: {'loss': 0.011669271066971305, 'learning_rate': 2.4356053756873987e-06, 'epoch': 13, 'step': 12900}
2024-07-25 12:21:18:INFO: {'loss': 0.007349072233096194, 'learning_rate': 2.3647273763642853e-06, 'epoch': 13, 'step': 13000}
2024-07-25 12:21:44:INFO: {'loss': 0.0034069861482430496, 'learning_rate': 2.2945751722550384e-06, 'epoch': 13, 'step': 13100}
2024-07-25 12:22:11:INFO: {'loss': 0.009529771095280921, 'learning_rate': 2.2251680843716617e-06, 'epoch': 13, 'step': 13200}
2024-07-25 12:22:37:INFO: {'loss': 0.010305833844854532, 'learning_rate': 2.1565252285095158e-06, 'epoch': 13, 'step': 13300}
2024-07-25 12:23:00:INFO: ***** Running Dev *****
2024-07-25 12:23:00:INFO:   Num examples = 463
2024-07-25 12:23:00:INFO:   Batch size = 16
2024-07-25 12:23:09:INFO: {'acc': 0.9777942764578834, 'p': 0.9763220205209155, 'r': 0.973249409913454, 'f1': 0.9747832939322301, 'epoch': 13, 'step': 13384}
2024-07-25 12:23:09:INFO: ***** Running Test *****
2024-07-25 12:23:09:INFO:   Num examples = 477
2024-07-25 12:23:09:INFO:   Batch size = 16
2024-07-25 12:23:18:INFO: {'acc': 0.9708483866949047, 'p': 0.9685442574981712, 'r': 0.9650145772594753, 'f1': 0.9667761956918584, 'epoch': 13, 'step': 13384}
2024-07-25 12:23:22:INFO: {'loss': 0.0018271834094161932, 'learning_rate': 2.088665509982534e-06, 'epoch': 14, 'step': 13400}
2024-07-25 12:23:49:INFO: {'loss': 0.01038975523813633, 'learning_rate': 2.0216076184164045e-06, 'epoch': 14, 'step': 13500}
2024-07-25 12:24:15:INFO: {'loss': 0.003841286500812657, 'learning_rate': 1.955370022601157e-06, 'epoch': 14, 'step': 13600}
2024-07-25 12:24:42:INFO: {'loss': 0.006360782479332556, 'learning_rate': 1.8899709654045607e-06, 'epoch': 14, 'step': 13700}
2024-07-25 12:25:09:INFO: {'loss': 0.001863966076828092, 'learning_rate': 1.8254284587477683e-06, 'epoch': 14, 'step': 13800}
2024-07-25 12:25:35:INFO: {'loss': 0.0032000289824304674, 'learning_rate': 1.7617602786445403e-06, 'epoch': 14, 'step': 13900}
2024-07-25 12:26:02:INFO: {'loss': 0.010442775508743125, 'learning_rate': 1.698983960305458e-06, 'epoch': 14, 'step': 14000}
2024-07-25 12:26:28:INFO: {'loss': 0.01191721820056273, 'learning_rate': 1.637116793308453e-06, 'epoch': 14, 'step': 14100}
2024-07-25 12:26:55:INFO: {'loss': 0.006084346225002264, 'learning_rate': 1.5761758168369863e-06, 'epoch': 14, 'step': 14200}
2024-07-25 12:27:22:INFO: {'loss': 0.004617228171543957, 'learning_rate': 1.5161778149871874e-06, 'epoch': 14, 'step': 14300}
2024-07-25 12:27:32:INFO: ***** Running Dev *****
2024-07-25 12:27:32:INFO:   Num examples = 463
2024-07-25 12:27:32:INFO:   Batch size = 16
2024-07-25 12:27:41:INFO: {'acc': 0.9773893088552916, 'p': 0.9724409448818898, 'r': 0.971675845790716, 'f1': 0.9720582447855176, 'epoch': 14, 'step': 14340}
2024-07-25 12:27:41:INFO: ***** Running Test *****
2024-07-25 12:27:41:INFO:   Num examples = 477
2024-07-25 12:27:41:INFO:   Batch size = 16
2024-07-25 12:27:50:INFO: {'acc': 0.9709106764669241, 'p': 0.96996336996337, 'r': 0.9650145772594753, 'f1': 0.9674826452320059, 'epoch': 14, 'step': 14340}
2024-07-25 12:28:06:INFO: {'loss': 0.02195599136052806, 'learning_rate': 1.457139312145262e-06, 'epoch': 15, 'step': 14400}
2024-07-25 12:28:33:INFO: {'loss': 0.004434968819443838, 'learning_rate': 1.39907656843641e-06, 'epoch': 15, 'step': 14500}
2024-07-25 12:29:00:INFO: {'loss': 0.0054023153890761936, 'learning_rate': 1.3420055752465362e-06, 'epoch': 15, 'step': 14600}
2024-07-25 12:29:26:INFO: {'loss': 0.0043549358048812796, 'learning_rate': 1.285942050817971e-06, 'epoch': 15, 'step': 14700}
2024-07-25 12:29:53:INFO: {'loss': 0.003166678724758185, 'learning_rate': 1.2309014359204251e-06, 'epoch': 15, 'step': 14800}
2024-07-25 12:30:19:INFO: {'loss': 0.004045578394791392, 'learning_rate': 1.1768988895983574e-06, 'epoch': 15, 'step': 14900}
2024-07-25 12:30:46:INFO: {'loss': 0.002254436260211605, 'learning_rate': 1.123949284995935e-06, 'epoch': 15, 'step': 15000}
2024-07-25 12:31:12:INFO: {'loss': 0.004950802069918154, 'learning_rate': 1.0720672052607417e-06, 'epoch': 15, 'step': 15100}
2024-07-25 12:31:39:INFO: {'loss': 0.006763817028418089, 'learning_rate': 1.021266939527356e-06, 'epoch': 15, 'step': 15200}
2024-07-25 12:32:05:INFO: ***** Running Dev *****
2024-07-25 12:32:05:INFO:   Num examples = 463
2024-07-25 12:32:05:INFO:   Batch size = 16
2024-07-25 12:32:14:INFO: {'acc': 0.9773893088552916, 'p': 0.9717425431711146, 'r': 0.9740361919748229, 'f1': 0.9728880157170923, 'epoch': 15, 'step': 15296}
2024-07-25 12:32:14:INFO: ***** Running Test *****
2024-07-25 12:32:14:INFO:   Num examples = 477
2024-07-25 12:32:14:INFO:   Batch size = 16
2024-07-25 12:32:23:INFO: {'acc': 0.9722810514513517, 'p': 0.9721407624633431, 'r': 0.9664723032069971, 'f1': 0.9692982456140351, 'epoch': 15, 'step': 15296}
2024-07-25 12:32:24:INFO: {'loss': 0.01714598724790676, 'learning_rate': 9.71562478981886e-07, 'epoch': 16, 'step': 15300}
2024-07-25 12:32:50:INFO: {'loss': 0.013094220242389838, 'learning_rate': 9.229675130085919e-07, 'epoch': 16, 'step': 15400}
2024-07-25 12:33:17:INFO: {'loss': 0.0006475492965614649, 'learning_rate': 8.754954254196096e-07, 'epoch': 16, 'step': 15500}
2024-07-25 12:33:44:INFO: {'loss': 0.009182241947592047, 'learning_rate': 8.2915929076884e-07, 'epoch': 16, 'step': 15600}
2024-07-25 12:34:10:INFO: {'loss': 0.01067336686337967, 'learning_rate': 7.839718707510153e-07, 'epoch': 16, 'step': 15700}
2024-07-25 12:34:37:INFO: {'loss': 0.002911971095923036, 'learning_rate': 7.399456106869296e-07, 'epoch': 16, 'step': 15800}
2024-07-25 12:35:03:INFO: {'loss': 0.0016077662045813667, 'learning_rate': 6.97092636095798e-07, 'epoch': 16, 'step': 15900}
2024-07-25 12:35:30:INFO: {'loss': 0.002727967819364494, 'learning_rate': 6.554247493557048e-07, 'epoch': 16, 'step': 16000}
2024-07-25 12:35:57:INFO: {'loss': 0.003024240650918273, 'learning_rate': 6.149534264530433e-07, 'epoch': 16, 'step': 16100}
2024-07-25 12:36:23:INFO: {'loss': 0.001299785398084623, 'learning_rate': 5.756898138218448e-07, 'epoch': 16, 'step': 16200}
2024-07-25 12:36:37:INFO: ***** Running Dev *****
2024-07-25 12:36:37:INFO:   Num examples = 463
2024-07-25 12:36:37:INFO:   Batch size = 16
2024-07-25 12:36:46:INFO: {'acc': 0.9788741900647948, 'p': 0.9717425431711146, 'r': 0.9740361919748229, 'f1': 0.9728880157170923, 'epoch': 16, 'step': 16252}
2024-07-25 12:36:46:INFO: ***** Running Test *****
2024-07-25 12:36:46:INFO:   Num examples = 477
2024-07-25 12:36:46:INFO:   Batch size = 16
2024-07-25 12:36:56:INFO: {'acc': 0.9719696025912545, 'p': 0.9692757863935626, 'r': 0.9657434402332361, 'f1': 0.9675063891931361, 'epoch': 16, 'step': 16252}
2024-07-25 12:37:08:INFO: {'loss': 0.004616919557720394, 'learning_rate': 5.376447252738848e-07, 'epoch': 17, 'step': 16300}
2024-07-25 12:37:35:INFO: {'loss': 0.005287957796695082, 'learning_rate': 5.008286390203876e-07, 'epoch': 17, 'step': 16400}
2024-07-25 12:38:02:INFO: {'loss': 0.00467574231399567, 'learning_rate': 4.6525169478616073e-07, 'epoch': 17, 'step': 16500}
2024-07-25 12:38:28:INFO: {'loss': 0.002662095448049513, 'learning_rate': 4.309236910169562e-07, 'epoch': 17, 'step': 16600}
2024-07-25 12:38:55:INFO: {'loss': 0.0021380371785880924, 'learning_rate': 3.9785408218082964e-07, 'epoch': 17, 'step': 16700}
2024-07-25 12:39:21:INFO: {'loss': 0.0020099982903957424, 'learning_rate': 3.6605197616423116e-07, 'epoch': 17, 'step': 16800}
2024-07-25 12:39:48:INFO: {'loss': 0.0032612257952223445, 'learning_rate': 3.355261317635472e-07, 'epoch': 17, 'step': 16900}
2024-07-25 12:40:15:INFO: {'loss': 0.012501046628235599, 'learning_rate': 3.062849562727982e-07, 'epoch': 17, 'step': 17000}
2024-07-25 12:40:41:INFO: {'loss': 0.002183442329160243, 'learning_rate': 2.7833650316813123e-07, 'epoch': 17, 'step': 17100}
2024-07-25 12:41:08:INFO: {'loss': 0.0031435243904024903, 'learning_rate': 2.51688469889772e-07, 'epoch': 17, 'step': 17200}
2024-07-25 12:41:10:INFO: ***** Running Dev *****
2024-07-25 12:41:10:INFO:   Num examples = 463
2024-07-25 12:41:10:INFO:   Batch size = 16
2024-07-25 12:41:19:INFO: {'acc': 0.9780642548596112, 'p': 0.9732914375490966, 'r': 0.974822974036192, 'f1': 0.9740566037735849, 'epoch': 17, 'step': 17208}
2024-07-25 12:41:19:INFO: ***** Running Test *****
2024-07-25 12:41:19:INFO:   Num examples = 477
2024-07-25 12:41:19:INFO:   Batch size = 16
2024-07-25 12:41:28:INFO: {'acc': 0.9716581537311574, 'p': 0.9692757863935626, 'r': 0.9657434402332361, 'f1': 0.9675063891931361, 'epoch': 17, 'step': 17208}
2024-07-25 12:41:52:INFO: {'loss': 0.0039254191986924526, 'learning_rate': 2.263481957220276e-07, 'epoch': 18, 'step': 17300}
2024-07-25 12:42:19:INFO: {'loss': 0.0017983805132439556, 'learning_rate': 2.0232265977193465e-07, 'epoch': 18, 'step': 17400}
2024-07-25 12:42:46:INFO: {'loss': 0.0005915832614891769, 'learning_rate': 1.7961847904710173e-07, 'epoch': 18, 'step': 17500}
2024-07-25 12:43:12:INFO: {'loss': 0.002650413177975679, 'learning_rate': 1.5824190663328521e-07, 'epoch': 18, 'step': 17600}
2024-07-25 12:43:39:INFO: {'loss': 0.003834883054742022, 'learning_rate': 1.3819882997218981e-07, 'epoch': 18, 'step': 17700}
2024-07-25 12:44:05:INFO: {'loss': 0.0023914572845092153, 'learning_rate': 1.1949476923997394e-07, 'epoch': 18, 'step': 17800}
2024-07-25 12:44:32:INFO: {'loss': 0.012349828625415284, 'learning_rate': 1.0213487582691139e-07, 'epoch': 18, 'step': 17900}
2024-07-25 12:44:59:INFO: {'loss': 0.003816595109640275, 'learning_rate': 8.612393091861349e-08, 'epoch': 18, 'step': 18000}
2024-07-25 12:45:25:INFO: {'loss': 0.008997114615997361, 'learning_rate': 7.146634417922016e-08, 'epoch': 18, 'step': 18100}
2024-07-25 12:45:42:INFO: ***** Running Dev *****
2024-07-25 12:45:42:INFO:   Num examples = 463
2024-07-25 12:45:42:INFO:   Batch size = 16
2024-07-25 12:45:51:INFO: {'acc': 0.9774568034557235, 'p': 0.9725274725274725, 'r': 0.974822974036192, 'f1': 0.9736738703339883, 'epoch': 18, 'step': 18164}
2024-07-25 12:45:51:INFO: ***** Running Test *****
2024-07-25 12:45:51:INFO:   Num examples = 477
2024-07-25 12:45:51:INFO:   Batch size = 16
2024-07-25 12:46:01:INFO: {'acc': 0.9716581537311574, 'p': 0.9692757863935626, 'r': 0.9657434402332361, 'f1': 0.9675063891931361, 'epoch': 18, 'step': 18164}
2024-07-25 12:46:10:INFO: {'loss': 0.0012219824165572392, 'learning_rate': 5.816615253690539e-08, 'epoch': 19, 'step': 18200}
2024-07-25 12:46:37:INFO: {'loss': 0.0027815446681688626, 'learning_rate': 4.622701907204652e-08, 'epoch': 19, 'step': 18300}
2024-07-25 12:47:03:INFO: {'loss': 0.0028315795344337857, 'learning_rate': 3.565223200835577e-08, 'epoch': 19, 'step': 18400}
2024-07-25 12:47:30:INFO: {'loss': 0.0018210137582218523, 'learning_rate': 2.644470380724906e-08, 'epoch': 19, 'step': 18500}
2024-07-25 12:47:56:INFO: {'loss': 0.000633428390269728, 'learning_rate': 1.8606970365710465e-08, 'epoch': 19, 'step': 18600}
2024-07-25 12:48:23:INFO: {'loss': 0.006157786750920877, 'learning_rate': 1.214119031786809e-08, 'epoch': 19, 'step': 18700}
2024-07-25 12:48:50:INFO: {'loss': 0.000986826339487834, 'learning_rate': 7.049144440469669e-09, 'epoch': 19, 'step': 18800}
2024-07-25 12:49:16:INFO: {'loss': 0.0013647531368405907, 'learning_rate': 3.332235162429864e-09, 'epoch': 19, 'step': 18900}
2024-07-25 12:49:43:INFO: {'loss': 0.0019564602306877533, 'learning_rate': 9.914861785803587e-10, 'epoch': 19, 'step': 19000}
2024-07-25 12:50:09:INFO: {'loss': 0.00826588461239453, 'learning_rate': 2.7542167727601098e-11, 'epoch': 19, 'step': 19100}
2024-07-25 12:50:15:INFO: ***** Running Dev *****
2024-07-25 12:50:15:INFO:   Num examples = 463
2024-07-25 12:50:15:INFO:   Batch size = 16
2024-07-25 12:50:24:INFO: {'acc': 0.9774568034557235, 'p': 0.9725274725274725, 'r': 0.974822974036192, 'f1': 0.9736738703339883, 'epoch': 19, 'step': 19120}
2024-07-25 12:50:24:INFO: ***** Running Test *****
2024-07-25 12:50:24:INFO:   Num examples = 477
2024-07-25 12:50:24:INFO:   Batch size = 16
2024-07-25 12:50:33:INFO: {'acc': 0.9716581537311574, 'p': 0.9692757863935626, 'r': 0.9657434402332361, 'f1': 0.9675063891931361, 'epoch': 19, 'step': 19120}
2024-07-25 12:50:33:INFO: 

Training completed. Do not forget to share your model on huggingface.co/models =)


2024-07-25 12:50:33:INFO: *** Dev Evaluate ***
2024-07-25 12:50:34:INFO: ***** Running dev *****
2024-07-25 12:50:34:INFO:   Num examples = 463
2024-07-25 12:50:34:INFO:   Batch size = 16
2024-07-25 12:50:42:INFO: Dev Result: acc: 0.9775, p: 0.9725, r: 0.9748, f1: 0.9737

2024-07-25 12:50:42:INFO: *** Test Evaluate ***
2024-07-25 12:50:43:INFO: ***** Running test *****
2024-07-25 12:50:43:INFO:   Num examples = 477
2024-07-25 12:50:43:INFO:   Batch size = 16
2024-07-25 12:50:52:INFO: Test Result: acc: 0.9717, p: 0.9693, r: 0.9657, f1: 0.9675

