2024-09-20 11:15:10:INFO: Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True, 16-bits training: False
2024-09-20 11:15:10:INFO: Training/evaluation parameters Namespace(T_mult=1, adam_epsilon=1e-08, bigram_min_freq=1, char_min_freq=1, config_name='data/berts/bert/config.json', data_dir='data/dataset/NER/resume', dataset='resume', decay_rate=0.999, decay_steps=200, default_label='O', device=device(type='cuda', index=0), do_eval=True, do_predict=True, do_shuffle=True, do_train=True, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, label='all', label_file='data/dataset/NER/resume/labels.txt', label_num=28, lattice=1, lattice_min_freq=1, learning_rate=1e-05, lexicon_name='yj', local_rank=0, logging_dir='data/resume/log', logging_steps=100, max_grad_norm=1.0, max_scan_num=1000, max_seq_length=256, max_steps=-1, max_word_num=5, mid_data_dir='data/dataset/NER/resume/mid_data', mid_label_file='data/dataset/NER/resume/mid_data/labels.json', model_name_or_path='data/berts/bert/pytorch_model.bin', model_type='WCBertCRF_Token', n_gpu=1, no_cuda=False, nodes=2, num_tags=4, num_train_epochs=20, number_normalized=0, only_lexicon_in_train=False, only_train_min_freq=True, output_dir='data/result/NER/resume/lebertcrf', overwrite_cache=True, per_gpu_eval_batch_size=16, per_gpu_train_batch_size=4, rewarm_epoch_num=2, save_steps=600, save_total_limit=50, saved_embedding_dir='data/dataset/NER/resume', scheduler='CAWR', seed=106524, sgd_momentum=0.9, train_clip=False, vocab_file='data/berts/bert/vocab.txt', warmup_steps=190, weight_decay=0.0, word_embed_dim=200, word_embedding='data/embedding/word_embedding.txt', word_min_freq=1, word_vocab_file='data/vocab/tencent_vocab.txt')
2024-09-20 11:15:26:INFO: ***** Running training *****
2024-09-20 11:15:26:INFO:   Num examples = 3821
2024-09-20 11:15:26:INFO:   Num Epochs = 20
2024-09-20 11:15:26:INFO:   Instantaneous batch size per device = 4
2024-09-20 11:15:26:INFO:   Total train batch size (w. parallel, distributed & accumulation) = 4
2024-09-20 11:15:26:INFO:   Gradient Accumulation steps = 1
2024-09-20 11:15:26:INFO:   Total optimization steps = 19120
2024-09-20 11:16:01:INFO: {'loss': 5.688826115131378, 'learning_rate': 5.263157894736842e-06, 'epoch': 0, 'step': 100}
2024-09-20 11:16:26:INFO: {'loss': 2.052747796475887, 'learning_rate': 9.999993114453328e-06, 'epoch': 0, 'step': 200}
2024-09-20 11:16:51:INFO: {'loss': 0.6611307118833065, 'learning_rate': 9.999166871799133e-06, 'epoch': 0, 'step': 300}
2024-09-20 11:17:17:INFO: {'loss': 0.41417169228196143, 'learning_rate': 9.996963780557683e-06, 'epoch': 0, 'step': 400}
2024-09-20 11:17:42:INFO: {'loss': 0.33790398713201286, 'learning_rate': 9.993384447494693e-06, 'epoch': 0, 'step': 500}
2024-09-20 11:18:07:INFO: {'loss': 0.28992348654195665, 'learning_rate': 9.988429858414358e-06, 'epoch': 0, 'step': 600}
2024-09-20 11:18:32:INFO: {'loss': 0.2534164057858288, 'learning_rate': 9.982101377887845e-06, 'epoch': 0, 'step': 700}
2024-09-20 11:18:56:INFO: {'loss': 0.28144015185534954, 'learning_rate': 9.974400748877469e-06, 'epoch': 0, 'step': 800}
2024-09-20 11:19:21:INFO: {'loss': 0.2098189727216959, 'learning_rate': 9.96533009225666e-06, 'epoch': 0, 'step': 900}
2024-09-20 11:19:35:INFO: ***** Running Dev *****
2024-09-20 11:19:35:INFO:   Num examples = 463
2024-09-20 11:19:35:INFO:   Batch size = 16
2024-09-20 11:19:44:INFO: {'acc': 0.9551835853131749, 'p': 0.9540047581284695, 'r': 0.946498819826908, 'f1': 0.9502369668246446, 'epoch': 0, 'step': 956}
2024-09-20 11:19:44:INFO: ***** Running Test *****
2024-09-20 11:19:44:INFO:   Num examples = 477
2024-09-20 11:19:44:INFO:   Batch size = 16
2024-09-20 11:19:52:INFO: {'acc': 0.9569577675345708, 'p': 0.9562314540059347, 'r': 0.9395043731778425, 'f1': 0.9477941176470588, 'epoch': 0, 'step': 956}
2024-09-20 11:20:03:INFO: {'loss': 0.22586860687937588, 'learning_rate': 9.954891906225833e-06, 'epoch': 1, 'step': 1000}
2024-09-20 11:20:28:INFO: {'loss': 0.18001217316836118, 'learning_rate': 9.943089065624343e-06, 'epoch': 1, 'step': 1100}
2024-09-20 11:20:53:INFO: {'loss': 0.18705615401268005, 'learning_rate': 9.929924821138723e-06, 'epoch': 1, 'step': 1200}
2024-09-20 11:21:18:INFO: {'loss': 0.20800935983657837, 'learning_rate': 9.915402798407383e-06, 'epoch': 1, 'step': 1300}
2024-09-20 11:21:43:INFO: {'loss': 0.1656166670238599, 'learning_rate': 9.899526997022054e-06, 'epoch': 1, 'step': 1400}
2024-09-20 11:22:07:INFO: {'loss': 0.1277322238369379, 'learning_rate': 9.882301789426234e-06, 'epoch': 1, 'step': 1500}
2024-09-20 11:22:32:INFO: {'loss': 0.1669912072713487, 'learning_rate': 9.863731919710964e-06, 'epoch': 1, 'step': 1600}
2024-09-20 11:22:57:INFO: {'loss': 0.13698385082301684, 'learning_rate': 9.843822502308213e-06, 'epoch': 1, 'step': 1700}
2024-09-20 11:23:21:INFO: {'loss': 0.18724151505623013, 'learning_rate': 9.822579020582297e-06, 'epoch': 1, 'step': 1800}
2024-09-20 11:23:46:INFO: {'loss': 0.16603978672646919, 'learning_rate': 9.800007325319666e-06, 'epoch': 1, 'step': 1900}
2024-09-20 11:23:49:INFO: ***** Running Dev *****
2024-09-20 11:23:49:INFO:   Num examples = 463
2024-09-20 11:23:49:INFO:   Batch size = 16
2024-09-20 11:23:57:INFO: {'acc': 0.9608531317494601, 'p': 0.9648842777334398, 'r': 0.9512195121951219, 'f1': 0.9580031695721076, 'epoch': 1, 'step': 1912}
2024-09-20 11:23:57:INFO: ***** Running Test *****
2024-09-20 11:23:57:INFO:   Num examples = 477
2024-09-20 11:23:57:INFO:   Batch size = 16
2024-09-20 11:24:06:INFO: {'acc': 0.9606328640837175, 'p': 0.966715976331361, 'r': 0.9526239067055393, 'f1': 0.9596182085168868, 'epoch': 1, 'step': 1912}
2024-09-20 11:24:28:INFO: {'loss': 0.13365879658726043, 'learning_rate': 9.776113633117514e-06, 'epoch': 2, 'step': 2000}
2024-09-20 11:24:53:INFO: {'loss': 0.08536620451544877, 'learning_rate': 9.750904524671623e-06, 'epoch': 2, 'step': 2100}
2024-09-20 11:25:17:INFO: {'loss': 0.13863403983064926, 'learning_rate': 9.72438694296394e-06, 'epoch': 2, 'step': 2200}
2024-09-20 11:25:42:INFO: {'loss': 0.13510995673947035, 'learning_rate': 9.696568191350373e-06, 'epoch': 2, 'step': 2300}
2024-09-20 11:26:07:INFO: {'loss': 0.10727851564297453, 'learning_rate': 9.667455931549336e-06, 'epoch': 2, 'step': 2400}
2024-09-20 11:26:31:INFO: {'loss': 0.11875302420812658, 'learning_rate': 9.637058181531583e-06, 'epoch': 2, 'step': 2500}
2024-09-20 11:26:56:INFO: {'loss': 0.10893690749013331, 'learning_rate': 9.605383313311937e-06, 'epoch': 2, 'step': 2600}
2024-09-20 11:27:21:INFO: {'loss': 0.1160384072054876, 'learning_rate': 9.572440050643515e-06, 'epoch': 2, 'step': 2700}
2024-09-20 11:27:46:INFO: {'loss': 0.1497474047052674, 'learning_rate': 9.538237466615057e-06, 'epoch': 2, 'step': 2800}
2024-09-20 11:28:02:INFO: ***** Running Dev *****
2024-09-20 11:28:02:INFO:   Num examples = 463
2024-09-20 11:28:02:INFO:   Batch size = 16
2024-09-20 11:28:11:INFO: {'acc': 0.9644978401727862, 'p': 0.9684044233807267, 'r': 0.964594807238395, 'f1': 0.966495861253449, 'epoch': 2, 'step': 2868}
2024-09-20 11:28:11:INFO: ***** Running Test *****
2024-09-20 11:28:11:INFO:   Num examples = 477
2024-09-20 11:28:11:INFO:   Batch size = 16
2024-09-20 11:28:19:INFO: {'acc': 0.9666126821975831, 'p': 0.9740548554484804, 'r': 0.9577259475218659, 'f1': 0.9658213891951488, 'epoch': 2, 'step': 2868}
2024-09-20 11:28:27:INFO: {'loss': 0.10175625145842787, 'learning_rate': 9.502784981152066e-06, 'epoch': 3, 'step': 2900}
2024-09-20 11:28:52:INFO: {'loss': 0.0930761959264055, 'learning_rate': 9.466092358422405e-06, 'epoch': 3, 'step': 3000}
2024-09-20 11:29:17:INFO: {'loss': 0.09461057465523481, 'learning_rate': 9.4281697041471e-06, 'epoch': 3, 'step': 3100}
2024-09-20 11:29:41:INFO: {'loss': 0.09393012187298154, 'learning_rate': 9.389027462817066e-06, 'epoch': 3, 'step': 3200}
2024-09-20 11:30:06:INFO: {'loss': 0.09716935698699672, 'learning_rate': 9.348676414816526e-06, 'epoch': 3, 'step': 3300}
2024-09-20 11:30:31:INFO: {'loss': 0.07843921134426637, 'learning_rate': 9.307127673453928e-06, 'epoch': 3, 'step': 3400}
2024-09-20 11:30:56:INFO: {'loss': 0.10557585849252064, 'learning_rate': 9.264392681901166e-06, 'epoch': 3, 'step': 3500}
2024-09-20 11:31:20:INFO: {'loss': 0.08589416571136098, 'learning_rate': 9.220483210041958e-06, 'epoch': 3, 'step': 3600}
2024-09-20 11:31:45:INFO: {'loss': 0.07423567885824013, 'learning_rate': 9.175411351230221e-06, 'epoch': 3, 'step': 3700}
2024-09-20 11:32:10:INFO: {'loss': 0.08070610427006614, 'learning_rate': 9.129189518959393e-06, 'epoch': 3, 'step': 3800}
2024-09-20 11:32:16:INFO: ***** Running Dev *****
2024-09-20 11:32:16:INFO:   Num examples = 463
2024-09-20 11:32:16:INFO:   Batch size = 16
2024-09-20 11:32:24:INFO: {'acc': 0.9698974082073434, 'p': 0.9652722967640095, 'r': 0.962234461054288, 'f1': 0.9637509850275808, 'epoch': 3, 'step': 3824}
2024-09-20 11:32:24:INFO: ***** Running Test *****
2024-09-20 11:32:24:INFO:   Num examples = 477
2024-09-20 11:32:24:INFO:   Batch size = 16
2024-09-20 11:32:33:INFO: {'acc': 0.9695403014824966, 'p': 0.9757174392935982, 'r': 0.9664723032069971, 'f1': 0.9710728670816551, 'epoch': 3, 'step': 3824}
2024-09-20 11:32:52:INFO: {'loss': 0.05986143507499946, 'learning_rate': 9.081830443443542e-06, 'epoch': 4, 'step': 3900}
2024-09-20 11:33:16:INFO: {'loss': 0.10523793061198376, 'learning_rate': 9.033347168111282e-06, 'epoch': 4, 'step': 4000}
2024-09-20 11:33:41:INFO: {'loss': 0.0657975964785146, 'learning_rate': 8.983753046013403e-06, 'epoch': 4, 'step': 4100}
2024-09-20 11:34:06:INFO: {'loss': 0.05205334869227954, 'learning_rate': 8.933061736145236e-06, 'epoch': 4, 'step': 4200}
2024-09-20 11:34:31:INFO: {'loss': 0.08166094247288129, 'learning_rate': 8.881287199684743e-06, 'epoch': 4, 'step': 4300}
2024-09-20 11:34:55:INFO: {'loss': 0.05536450091698498, 'learning_rate': 8.828443696147403e-06, 'epoch': 4, 'step': 4400}
2024-09-20 11:35:20:INFO: {'loss': 0.06401487945266127, 'learning_rate': 8.774545779458912e-06, 'epoch': 4, 'step': 4500}
2024-09-20 11:35:45:INFO: {'loss': 0.09838480185666412, 'learning_rate': 8.719608293946801e-06, 'epoch': 4, 'step': 4600}
2024-09-20 11:36:10:INFO: {'loss': 0.06087801055506134, 'learning_rate': 8.663646370252093e-06, 'epoch': 4, 'step': 4700}
2024-09-20 11:36:29:INFO: ***** Running Dev *****
2024-09-20 11:36:29:INFO:   Num examples = 463
2024-09-20 11:36:29:INFO:   Batch size = 16
2024-09-20 11:36:38:INFO: {'acc': 0.9681425485961123, 'p': 0.9722222222222222, 'r': 0.963808025177026, 'f1': 0.9679968391939945, 'epoch': 4, 'step': 4780}
2024-09-20 11:36:38:INFO: ***** Running Test *****
2024-09-20 11:36:38:INFO:   Num examples = 477
2024-09-20 11:36:38:INFO:   Batch size = 16
2024-09-20 11:36:46:INFO: {'acc': 0.9632490345085337, 'p': 0.9725111441307578, 'r': 0.9540816326530612, 'f1': 0.9632082413539368, 'epoch': 4, 'step': 4780}
2024-09-20 11:36:51:INFO: {'loss': 0.06766004787532438, 'learning_rate': 8.606675421162064e-06, 'epoch': 5, 'step': 4800}
2024-09-20 11:37:16:INFO: {'loss': 0.06359181977029948, 'learning_rate': 8.54871113736534e-06, 'epoch': 5, 'step': 4900}
2024-09-20 11:37:41:INFO: {'loss': 0.03343423477203032, 'learning_rate': 8.48976948313043e-06, 'epoch': 5, 'step': 5000}
2024-09-20 11:38:06:INFO: {'loss': 0.05328907846527727, 'learning_rate': 8.429866691908916e-06, 'epoch': 5, 'step': 5100}
2024-09-20 11:38:30:INFO: {'loss': 0.05197947418731928, 'learning_rate': 8.369019261864506e-06, 'epoch': 5, 'step': 5200}
2024-09-20 11:38:55:INFO: {'loss': 0.049013898963166866, 'learning_rate': 8.30724395132919e-06, 'epoch': 5, 'step': 5300}
2024-09-20 11:39:20:INFO: {'loss': 0.03208644215384993, 'learning_rate': 8.24455777418772e-06, 'epoch': 5, 'step': 5400}
2024-09-20 11:39:44:INFO: {'loss': 0.08790583226294985, 'learning_rate': 8.18097799519174e-06, 'epoch': 5, 'step': 5500}
2024-09-20 11:40:09:INFO: {'loss': 0.05590942949387681, 'learning_rate': 8.116522125204783e-06, 'epoch': 5, 'step': 5600}
2024-09-20 11:40:34:INFO: {'loss': 0.07827993202547077, 'learning_rate': 8.05120791637952e-06, 'epoch': 5, 'step': 5700}
2024-09-20 11:40:43:INFO: ***** Running Dev *****
2024-09-20 11:40:43:INFO:   Num examples = 463
2024-09-20 11:40:43:INFO:   Batch size = 16
2024-09-20 11:40:51:INFO: {'acc': 0.9750944924406048, 'p': 0.9714285714285714, 'r': 0.963021243115657, 'f1': 0.9672066376926116, 'epoch': 5, 'step': 5736}
2024-09-20 11:40:51:INFO: ***** Running Test *****
2024-09-20 11:40:51:INFO:   Num examples = 477
2024-09-20 11:40:51:INFO:   Batch size = 16
2024-09-20 11:41:00:INFO: {'acc': 0.9676093185498941, 'p': 0.9720176730486009, 'r': 0.9620991253644315, 'f1': 0.967032967032967, 'epoch': 5, 'step': 5736}
2024-09-20 11:41:15:INFO: {'loss': 0.04814320288329327, 'learning_rate': 7.985053357268533e-06, 'epoch': 6, 'step': 5800}
2024-09-20 11:41:40:INFO: {'loss': 0.05637725844298984, 'learning_rate': 7.918076667869996e-06, 'epoch': 6, 'step': 5900}
2024-09-20 11:42:05:INFO: {'loss': 0.036448103110597006, 'learning_rate': 7.850296294609586e-06, 'epoch': 6, 'step': 6000}
2024-09-20 11:42:30:INFO: {'loss': 0.0321592220761886, 'learning_rate': 7.78173090526007e-06, 'epoch': 6, 'step': 6100}
2024-09-20 11:42:54:INFO: {'loss': 0.049117146123753626, 'learning_rate': 7.712399383799896e-06, 'epoch': 6, 'step': 6200}
2024-09-20 11:43:19:INFO: {'loss': 0.0289333123436154, 'learning_rate': 7.642320825212248e-06, 'epoch': 6, 'step': 6300}
2024-09-20 11:43:44:INFO: {'loss': 0.03459620908632132, 'learning_rate': 7.571514530226004e-06, 'epoch': 6, 'step': 6400}
2024-09-20 11:44:09:INFO: {'loss': 0.038467475412890056, 'learning_rate': 7.500000000000001e-06, 'epoch': 6, 'step': 6500}
2024-09-20 11:44:34:INFO: {'loss': 0.05657711132462282, 'learning_rate': 7.4277969307521135e-06, 'epoch': 6, 'step': 6600}
2024-09-20 11:44:57:INFO: ***** Running Dev *****
2024-09-20 11:44:57:INFO:   Num examples = 463
2024-09-20 11:44:57:INFO:   Batch size = 16
2024-09-20 11:45:05:INFO: {'acc': 0.9704373650107991, 'p': 0.9692429022082019, 'r': 0.9669551534225019, 'f1': 0.9680976762504924, 'epoch': 6, 'step': 6692}
2024-09-20 11:45:05:INFO: ***** Running Test *****
2024-09-20 11:45:05:INFO:   Num examples = 477
2024-09-20 11:45:05:INFO:   Batch size = 16
2024-09-20 11:45:14:INFO: {'acc': 0.9702877787467298, 'p': 0.9734904270986745, 'r': 0.9635568513119533, 'f1': 0.9684981684981685, 'epoch': 6, 'step': 6692}
2024-09-20 11:45:16:INFO: {'loss': 0.051320064769952295, 'learning_rate': 7.354925208334615e-06, 'epoch': 7, 'step': 6700}
2024-09-20 11:45:40:INFO: {'loss': 0.0229728100293687, 'learning_rate': 7.2814049027572945e-06, 'epoch': 7, 'step': 6800}
2024-09-20 11:46:05:INFO: {'loss': 0.025611950384800367, 'learning_rate': 7.207256262659868e-06, 'epoch': 7, 'step': 6900}
2024-09-20 11:46:30:INFO: {'loss': 0.028761763481234083, 'learning_rate': 7.132499709735187e-06, 'epoch': 7, 'step': 7000}
2024-09-20 11:46:55:INFO: {'loss': 0.029156946100265486, 'learning_rate': 7.057155833104783e-06, 'epoch': 7, 'step': 7100}
2024-09-20 11:47:20:INFO: {'loss': 0.055334423358690404, 'learning_rate': 6.981245383648304e-06, 'epoch': 7, 'step': 7200}
2024-09-20 11:47:44:INFO: {'loss': 0.05041310735312436, 'learning_rate': 6.904789268288399e-06, 'epoch': 7, 'step': 7300}
2024-09-20 11:48:09:INFO: {'loss': 0.03005973743652248, 'learning_rate': 6.82780854423262e-06, 'epoch': 7, 'step': 7400}
2024-09-20 11:48:34:INFO: {'loss': 0.032454278288569186, 'learning_rate': 6.750324413173948e-06, 'epoch': 7, 'step': 7500}
2024-09-20 11:48:59:INFO: {'loss': 0.05912633797079252, 'learning_rate': 6.672358215451506e-06, 'epoch': 7, 'step': 7600}
2024-09-20 11:49:11:INFO: ***** Running Dev *****
2024-09-20 11:49:11:INFO:   Num examples = 463
2024-09-20 11:49:11:INFO:   Batch size = 16
2024-09-20 11:49:19:INFO: {'acc': 0.9763093952483801, 'p': 0.9733750978856696, 'r': 0.977970102281668, 'f1': 0.9756671899529042, 'epoch': 7, 'step': 7648}
2024-09-20 11:49:19:INFO: ***** Running Test *****
2024-09-20 11:49:19:INFO:   Num examples = 477
2024-09-20 11:49:19:INFO:   Batch size = 16
2024-09-20 11:49:28:INFO: {'acc': 0.9704123582907687, 'p': 0.9728141072740631, 'r': 0.9650145772594753, 'f1': 0.968898646176363, 'epoch': 7, 'step': 7648}
2024-09-20 11:49:40:INFO: {'loss': 0.030750258304342425, 'learning_rate': 6.593931424173102e-06, 'epoch': 8, 'step': 7700}
2024-09-20 11:50:05:INFO: {'loss': 0.02608579627740255, 'learning_rate': 6.515065639301199e-06, 'epoch': 8, 'step': 7800}
2024-09-20 11:50:30:INFO: {'loss': 0.02214703254802771, 'learning_rate': 6.435782581703944e-06, 'epoch': 8, 'step': 7900}
2024-09-20 11:50:55:INFO: {'loss': 0.02446570242424059, 'learning_rate': 6.356104087172916e-06, 'epoch': 8, 'step': 8000}
2024-09-20 11:51:20:INFO: {'loss': 0.028154448283653436, 'learning_rate': 6.276052100409185e-06, 'epoch': 8, 'step': 8100}
2024-09-20 11:51:45:INFO: {'loss': 0.033539940307764485, 'learning_rate': 6.195648668979417e-06, 'epoch': 8, 'step': 8200}
2024-09-20 11:52:09:INFO: {'loss': 0.045927278083108834, 'learning_rate': 6.11491593724363e-06, 'epoch': 8, 'step': 8300}
2024-09-20 11:52:34:INFO: {'loss': 0.02233799497662403, 'learning_rate': 6.033876140256276e-06, 'epoch': 8, 'step': 8400}
2024-09-20 11:52:59:INFO: {'loss': 0.03908222081437998, 'learning_rate': 5.952551597642377e-06, 'epoch': 8, 'step': 8500}
2024-09-20 11:53:24:INFO: {'loss': 0.02999159239947403, 'learning_rate': 5.870964707450348e-06, 'epoch': 8, 'step': 8600}
2024-09-20 11:53:25:INFO: ***** Running Dev *****
2024-09-20 11:53:25:INFO:   Num examples = 463
2024-09-20 11:53:25:INFO:   Batch size = 16
2024-09-20 11:53:33:INFO: {'acc': 0.9736096112311015, 'p': 0.9746233148295004, 'r': 0.9669551534225019, 'f1': 0.9707740916271721, 'epoch': 8, 'step': 8604}
2024-09-20 11:53:33:INFO: ***** Running Test *****
2024-09-20 11:53:33:INFO:   Num examples = 477
2024-09-20 11:53:33:INFO:   Batch size = 16
2024-09-20 11:53:42:INFO: {'acc': 0.9683567958141274, 'p': 0.971976401179941, 'r': 0.9606413994169096, 'f1': 0.966275659824047, 'epoch': 8, 'step': 8604}
2024-09-20 11:54:05:INFO: {'loss': 0.017900075425059184, 'learning_rate': 5.789137939983211e-06, 'epoch': 9, 'step': 8700}
2024-09-20 11:54:30:INFO: {'loss': 0.024069292961994507, 'learning_rate': 5.707093831609945e-06, 'epoch': 9, 'step': 8800}
2024-09-20 11:54:55:INFO: {'loss': 0.017852869456401094, 'learning_rate': 5.6248549785586005e-06, 'epoch': 9, 'step': 8900}
2024-09-20 11:55:20:INFO: {'loss': 0.021475859579086317, 'learning_rate': 5.542444030692954e-06, 'epoch': 9, 'step': 9000}
2024-09-20 11:55:44:INFO: {'loss': 0.0241547057972457, 'learning_rate': 5.459883685274378e-06, 'epoch': 9, 'step': 9100}
2024-09-20 11:56:09:INFO: {'loss': 0.01682775503359153, 'learning_rate': 5.377196680710668e-06, 'epoch': 9, 'step': 9200}
2024-09-20 11:56:34:INFO: {'loss': 0.025458136102524804, 'learning_rate': 5.2944057902935195e-06, 'epoch': 9, 'step': 9300}
2024-09-20 11:56:59:INFO: {'loss': 0.04996902969806797, 'learning_rate': 5.211533815926417e-06, 'epoch': 9, 'step': 9400}
2024-09-20 11:57:24:INFO: {'loss': 0.007493746482550705, 'learning_rate': 5.12860358184463e-06, 'epoch': 9, 'step': 9500}
2024-09-20 11:57:39:INFO: ***** Running Dev *****
2024-09-20 11:57:39:INFO:   Num examples = 463
2024-09-20 11:57:39:INFO:   Batch size = 16
2024-09-20 11:57:47:INFO: {'acc': 0.978536717062635, 'p': 0.9715639810426541, 'r': 0.967741935483871, 'f1': 0.9696491919590068, 'epoch': 9, 'step': 9560}
2024-09-20 11:57:47:INFO: ***** Running Test *****
2024-09-20 11:57:47:INFO:   Num examples = 477
2024-09-20 11:57:47:INFO:   Batch size = 16
2024-09-20 11:57:56:INFO: {'acc': 0.9686682446742245, 'p': 0.969208211143695, 'r': 0.9635568513119533, 'f1': 0.966374269005848, 'epoch': 9, 'step': 9560}
2024-09-20 11:58:06:INFO: {'loss': 0.0240112175053423, 'learning_rate': 5.04563792832906e-06, 'epoch': 10, 'step': 9600}
2024-09-20 11:58:31:INFO: {'loss': 0.020985742256889352, 'learning_rate': 4.962659705415677e-06, 'epoch': 10, 'step': 9700}
2024-09-20 11:58:55:INFO: {'loss': 0.007205993060920264, 'learning_rate': 4.879691766602261e-06, 'epoch': 10, 'step': 9800}
2024-09-20 11:59:20:INFO: {'loss': 0.014412435548279064, 'learning_rate': 4.79675696255418e-06, 'epoch': 10, 'step': 9900}
2024-09-20 11:59:45:INFO: {'loss': 0.016432049113839185, 'learning_rate': 4.7138781348109845e-06, 'epoch': 10, 'step': 10000}
2024-09-20 12:00:10:INFO: {'loss': 0.014757826411223505, 'learning_rate': 4.631078109495468e-06, 'epoch': 10, 'step': 10100}
2024-09-20 12:00:35:INFO: {'loss': 0.01981431241880273, 'learning_rate': 4.548379691027005e-06, 'epoch': 10, 'step': 10200}
2024-09-20 12:01:00:INFO: {'loss': 0.030591846799661652, 'learning_rate': 4.465805655840864e-06, 'epoch': 10, 'step': 10300}
2024-09-20 12:01:25:INFO: {'loss': 0.016763819418142704, 'learning_rate': 4.383378746115215e-06, 'epoch': 10, 'step': 10400}
2024-09-20 12:01:49:INFO: {'loss': 0.018769913416185773, 'learning_rate': 4.301121663507571e-06, 'epoch': 10, 'step': 10500}
2024-09-20 12:01:53:INFO: ***** Running Dev *****
2024-09-20 12:01:53:INFO:   Num examples = 463
2024-09-20 12:01:53:INFO:   Batch size = 16
2024-09-20 12:02:02:INFO: {'acc': 0.9744195464362851, 'p': 0.9731437598736177, 'r': 0.969315499606609, 'f1': 0.9712258573117856, 'epoch': 10, 'step': 10516}
2024-09-20 12:02:02:INFO: ***** Running Test *****
2024-09-20 12:02:02:INFO:   Num examples = 477
2024-09-20 12:02:02:INFO:   Batch size = 16
2024-09-20 12:02:10:INFO: {'acc': 0.9691665628503799, 'p': 0.9712812960235641, 'r': 0.9613702623906706, 'f1': 0.9663003663003663, 'epoch': 10, 'step': 10516}
2024-09-20 12:02:31:INFO: {'loss': 0.015054705273278159, 'learning_rate': 4.219057062902417e-06, 'epoch': 11, 'step': 10600}
2024-09-20 12:02:56:INFO: {'loss': 0.009047274332324377, 'learning_rate': 4.1372075461716885e-06, 'epoch': 11, 'step': 10700}
2024-09-20 12:03:21:INFO: {'loss': 0.012959786516598798, 'learning_rate': 4.055595655949856e-06, 'epoch': 11, 'step': 10800}
2024-09-20 12:03:46:INFO: {'loss': 0.018220714618555577, 'learning_rate': 3.974243869425348e-06, 'epoch': 11, 'step': 10900}
2024-09-20 12:04:10:INFO: {'loss': 0.007968522884098092, 'learning_rate': 3.893174592149976e-06, 'epoch': 11, 'step': 11000}
2024-09-20 12:04:35:INFO: {'loss': 0.018913772755945503, 'learning_rate': 3.812410151868092e-06, 'epoch': 11, 'step': 11100}
2024-09-20 12:05:00:INFO: {'loss': 0.024118087997960627, 'learning_rate': 3.731972792367179e-06, 'epoch': 11, 'step': 11200}
2024-09-20 12:05:25:INFO: {'loss': 0.011587331156215441, 'learning_rate': 3.6518846673515717e-06, 'epoch': 11, 'step': 11300}
2024-09-20 12:05:49:INFO: {'loss': 0.03255746431517309, 'learning_rate': 3.572167834340977e-06, 'epoch': 11, 'step': 11400}
2024-09-20 12:06:07:INFO: ***** Running Dev *****
2024-09-20 12:06:07:INFO:   Num examples = 463
2024-09-20 12:06:07:INFO:   Batch size = 16
2024-09-20 12:06:15:INFO: {'acc': 0.9752294816414687, 'p': 0.9716088328075709, 'r': 0.969315499606609, 'f1': 0.9704608113430484, 'epoch': 11, 'step': 11472}
2024-09-20 12:06:15:INFO: ***** Running Test *****
2024-09-20 12:06:15:INFO:   Num examples = 477
2024-09-20 12:06:15:INFO:   Batch size = 16
2024-09-20 12:06:24:INFO: {'acc': 0.968169926498069, 'p': 0.9663496708119971, 'r': 0.9628279883381924, 'f1': 0.9645856151880248, 'epoch': 11, 'step': 11472}
2024-09-20 12:06:31:INFO: {'loss': 0.015272719633428552, 'learning_rate': 3.4928442485954826e-06, 'epoch': 12, 'step': 11500}
2024-09-20 12:06:56:INFO: {'loss': 0.009130648162677063, 'learning_rate': 3.413935757068748e-06, 'epoch': 12, 'step': 11600}
2024-09-20 12:07:20:INFO: {'loss': 0.01603123293364888, 'learning_rate': 3.335464092391003e-06, 'epoch': 12, 'step': 11700}
2024-09-20 12:07:45:INFO: {'loss': 0.012152957372481978, 'learning_rate': 3.2574508668835426e-06, 'epoch': 12, 'step': 11800}
2024-09-20 12:08:10:INFO: {'loss': 0.009950571361573566, 'learning_rate': 3.1799175666063615e-06, 'epoch': 12, 'step': 11900}
2024-09-20 12:08:35:INFO: {'loss': 0.018881364290723467, 'learning_rate': 3.102885545440556e-06, 'epoch': 12, 'step': 12000}
2024-09-20 12:08:59:INFO: {'loss': 0.008568953680414779, 'learning_rate': 3.026376019207126e-06, 'epoch': 12, 'step': 12100}
2024-09-20 12:09:24:INFO: {'loss': 0.014377635714718054, 'learning_rate': 2.950410059823816e-06, 'epoch': 12, 'step': 12200}
2024-09-20 12:09:49:INFO: {'loss': 0.010742979951251072, 'learning_rate': 2.8750085895015758e-06, 'epoch': 12, 'step': 12300}
2024-09-20 12:10:14:INFO: {'loss': 0.012250968721975824, 'learning_rate': 2.8001923749822524e-06, 'epoch': 12, 'step': 12400}
2024-09-20 12:10:21:INFO: ***** Running Dev *****
2024-09-20 12:10:21:INFO:   Num examples = 463
2024-09-20 12:10:21:INFO:   Batch size = 16
2024-09-20 12:10:29:INFO: {'acc': 0.9771193304535637, 'p': 0.970125786163522, 'r': 0.970889063729347, 'f1': 0.9705072748721981, 'epoch': 12, 'step': 12428}
2024-09-20 12:10:29:INFO: ***** Running Test *****
2024-09-20 12:10:29:INFO:   Num examples = 477
2024-09-20 12:10:29:INFO:   Batch size = 16
2024-09-20 12:10:38:INFO: {'acc': 0.9699763298866326, 'p': 0.9691629955947136, 'r': 0.9620991253644315, 'f1': 0.9656181419166057, 'epoch': 12, 'step': 12428}
2024-09-20 12:10:55:INFO: {'loss': 0.015584940743233347, 'learning_rate': 2.7259820218191123e-06, 'epoch': 13, 'step': 12500}
2024-09-20 12:11:20:INFO: {'loss': 0.015588704582637548, 'learning_rate': 2.6523979687017516e-06, 'epoch': 13, 'step': 12600}
2024-09-20 12:11:45:INFO: {'loss': 0.006155413786677855, 'learning_rate': 2.579460481826947e-06, 'epoch': 13, 'step': 12700}
2024-09-20 12:12:10:INFO: {'loss': 0.0033730161999937992, 'learning_rate': 2.5071896493170533e-06, 'epoch': 13, 'step': 12800}
2024-09-20 12:12:35:INFO: {'loss': 0.013193110338577299, 'learning_rate': 2.4356053756873987e-06, 'epoch': 13, 'step': 12900}
2024-09-20 12:13:00:INFO: {'loss': 0.0049931488921674825, 'learning_rate': 2.3647273763642853e-06, 'epoch': 13, 'step': 13000}
2024-09-20 12:13:25:INFO: {'loss': 0.0027029239005037196, 'learning_rate': 2.2945751722550384e-06, 'epoch': 13, 'step': 13100}
2024-09-20 12:13:49:INFO: {'loss': 0.007895408856163612, 'learning_rate': 2.2251680843716617e-06, 'epoch': 13, 'step': 13200}
2024-09-20 12:14:14:INFO: {'loss': 0.014496741338530229, 'learning_rate': 2.1565252285095158e-06, 'epoch': 13, 'step': 13300}
2024-09-20 12:14:35:INFO: ***** Running Dev *****
2024-09-20 12:14:35:INFO:   Num examples = 463
2024-09-20 12:14:35:INFO:   Batch size = 16
2024-09-20 12:14:43:INFO: {'acc': 0.9765118790496761, 'p': 0.9777070063694268, 'r': 0.966168371361133, 'f1': 0.9719034428175702, 'epoch': 13, 'step': 13384}
2024-09-20 12:14:43:INFO: ***** Running Test *****
2024-09-20 12:14:43:INFO:   Num examples = 477
2024-09-20 12:14:43:INFO:   Batch size = 16
2024-09-20 12:14:52:INFO: {'acc': 0.968169926498069, 'p': 0.9705665930831494, 'r': 0.9613702623906706, 'f1': 0.9659465397290369, 'epoch': 13, 'step': 13384}
2024-09-20 12:14:56:INFO: {'loss': 0.0034448362704847567, 'learning_rate': 2.088665509982534e-06, 'epoch': 14, 'step': 13400}
2024-09-20 12:15:21:INFO: {'loss': 0.012149902990508964, 'learning_rate': 2.0216076184164045e-06, 'epoch': 14, 'step': 13500}
2024-09-20 12:15:45:INFO: {'loss': 0.007849311596728512, 'learning_rate': 1.955370022601157e-06, 'epoch': 14, 'step': 13600}
2024-09-20 12:16:10:INFO: {'loss': 0.006241572555522907, 'learning_rate': 1.8899709654045607e-06, 'epoch': 14, 'step': 13700}
2024-09-20 12:16:35:INFO: {'loss': 0.0033476936201623174, 'learning_rate': 1.8254284587477683e-06, 'epoch': 14, 'step': 13800}
2024-09-20 12:17:00:INFO: {'loss': 0.0036247336859628375, 'learning_rate': 1.7617602786445403e-06, 'epoch': 14, 'step': 13900}
2024-09-20 12:17:25:INFO: {'loss': 0.0028234203954411894, 'learning_rate': 1.698983960305458e-06, 'epoch': 14, 'step': 14000}
2024-09-20 12:17:49:INFO: {'loss': 0.010694774380860963, 'learning_rate': 1.637116793308453e-06, 'epoch': 14, 'step': 14100}
2024-09-20 12:18:14:INFO: {'loss': 0.007007552542115718, 'learning_rate': 1.5761758168369863e-06, 'epoch': 14, 'step': 14200}
2024-09-20 12:18:39:INFO: {'loss': 0.005713666782301061, 'learning_rate': 1.5161778149871874e-06, 'epoch': 14, 'step': 14300}
2024-09-20 12:18:49:INFO: ***** Running Dev *****
2024-09-20 12:18:49:INFO:   Num examples = 463
2024-09-20 12:18:49:INFO:   Batch size = 16
2024-09-20 12:18:57:INFO: {'acc': 0.9742170626349892, 'p': 0.9723538704581358, 'r': 0.96852871754524, 'f1': 0.9704375246353961, 'epoch': 14, 'step': 14340}
2024-09-20 12:18:57:INFO: ***** Running Test *****
2024-09-20 12:18:57:INFO:   Num examples = 477
2024-09-20 12:18:57:INFO:   Batch size = 16
2024-09-20 12:19:06:INFO: {'acc': 0.9695403014824966, 'p': 0.9684519442406456, 'r': 0.9620991253644315, 'f1': 0.9652650822669104, 'epoch': 14, 'step': 14340}
2024-09-20 12:19:21:INFO: {'loss': 0.015866725906528246, 'learning_rate': 1.457139312145262e-06, 'epoch': 15, 'step': 14400}
2024-09-20 12:19:46:INFO: {'loss': 0.003875160972040703, 'learning_rate': 1.39907656843641e-06, 'epoch': 15, 'step': 14500}
2024-09-20 12:20:11:INFO: {'loss': 0.0048402683455447005, 'learning_rate': 1.3420055752465362e-06, 'epoch': 15, 'step': 14600}
2024-09-20 12:20:36:INFO: {'loss': 0.0034607331429606348, 'learning_rate': 1.285942050817971e-06, 'epoch': 15, 'step': 14700}
2024-09-20 12:21:00:INFO: {'loss': 0.004325107272238711, 'learning_rate': 1.2309014359204251e-06, 'epoch': 15, 'step': 14800}
2024-09-20 12:21:25:INFO: {'loss': 0.004678707148068497, 'learning_rate': 1.1768988895983574e-06, 'epoch': 15, 'step': 14900}
2024-09-20 12:21:50:INFO: {'loss': 0.004806738924930869, 'learning_rate': 1.123949284995935e-06, 'epoch': 15, 'step': 15000}
2024-09-20 12:22:15:INFO: {'loss': 0.005539158880665127, 'learning_rate': 1.0720672052607417e-06, 'epoch': 15, 'step': 15100}
2024-09-20 12:22:39:INFO: {'loss': 0.007274414117323431, 'learning_rate': 1.021266939527356e-06, 'epoch': 15, 'step': 15200}
2024-09-20 12:23:03:INFO: ***** Running Dev *****
2024-09-20 12:23:03:INFO:   Num examples = 463
2024-09-20 12:23:03:INFO:   Batch size = 16
2024-09-20 12:23:11:INFO: {'acc': 0.9752294816414687, 'p': 0.9716088328075709, 'r': 0.969315499606609, 'f1': 0.9704608113430484, 'epoch': 15, 'step': 15296}
2024-09-20 12:23:11:INFO: ***** Running Test *****
2024-09-20 12:23:11:INFO:   Num examples = 477
2024-09-20 12:23:11:INFO:   Batch size = 16
2024-09-20 12:23:20:INFO: {'acc': 0.9701631992026909, 'p': 0.9727740986019132, 'r': 0.9635568513119533, 'f1': 0.9681435371658733, 'epoch': 15, 'step': 15296}
2024-09-20 12:23:21:INFO: {'loss': 0.01526129298551723, 'learning_rate': 9.71562478981886e-07, 'epoch': 16, 'step': 15300}
2024-09-20 12:23:45:INFO: {'loss': 0.01068174903846966, 'learning_rate': 9.229675130085919e-07, 'epoch': 16, 'step': 15400}
2024-09-20 12:24:10:INFO: {'loss': 0.0010105475166028554, 'learning_rate': 8.754954254196096e-07, 'epoch': 16, 'step': 15500}
2024-09-20 12:24:35:INFO: {'loss': 0.006266831790242122, 'learning_rate': 8.2915929076884e-07, 'epoch': 16, 'step': 15600}
2024-09-20 12:25:00:INFO: {'loss': 0.00785410357354749, 'learning_rate': 7.839718707510153e-07, 'epoch': 16, 'step': 15700}
2024-09-20 12:25:24:INFO: {'loss': 0.001596258400447823, 'learning_rate': 7.399456106869296e-07, 'epoch': 16, 'step': 15800}
2024-09-20 12:25:49:INFO: {'loss': 0.0013797657165878262, 'learning_rate': 6.97092636095798e-07, 'epoch': 16, 'step': 15900}
2024-09-20 12:26:14:INFO: {'loss': 0.0021992797626148785, 'learning_rate': 6.554247493557048e-07, 'epoch': 16, 'step': 16000}
2024-09-20 12:26:39:INFO: {'loss': 0.0033935484588960207, 'learning_rate': 6.149534264530433e-07, 'epoch': 16, 'step': 16100}
2024-09-20 12:27:04:INFO: {'loss': 0.0013327154706780674, 'learning_rate': 5.756898138218448e-07, 'epoch': 16, 'step': 16200}
2024-09-20 12:27:17:INFO: ***** Running Dev *****
2024-09-20 12:27:17:INFO:   Num examples = 463
2024-09-20 12:27:17:INFO:   Batch size = 16
2024-09-20 12:27:25:INFO: {'acc': 0.9761069114470843, 'p': 0.970102281667978, 'r': 0.970102281667978, 'f1': 0.970102281667978, 'epoch': 16, 'step': 16252}
2024-09-20 12:27:25:INFO: ***** Running Test *****
2024-09-20 12:27:25:INFO:   Num examples = 477
2024-09-20 12:27:25:INFO:   Batch size = 16
2024-09-20 12:27:34:INFO: {'acc': 0.9725302105394295, 'p': 0.9692757863935626, 'r': 0.9657434402332361, 'f1': 0.9675063891931361, 'epoch': 16, 'step': 16252}
2024-09-20 12:27:46:INFO: {'loss': 0.0070891814206265735, 'learning_rate': 5.376447252738848e-07, 'epoch': 17, 'step': 16300}
2024-09-20 12:28:11:INFO: {'loss': 0.0063146626514321725, 'learning_rate': 5.008286390203876e-07, 'epoch': 17, 'step': 16400}
2024-09-20 12:28:35:INFO: {'loss': 0.006749746044829408, 'learning_rate': 4.6525169478616073e-07, 'epoch': 17, 'step': 16500}
2024-09-20 12:29:00:INFO: {'loss': 0.004424726685945188, 'learning_rate': 4.309236910169562e-07, 'epoch': 17, 'step': 16600}
2024-09-20 12:29:25:INFO: {'loss': 0.0018212143875121001, 'learning_rate': 3.9785408218082964e-07, 'epoch': 17, 'step': 16700}
2024-09-20 12:29:50:INFO: {'loss': 0.002855102848475326, 'learning_rate': 3.6605197616423116e-07, 'epoch': 17, 'step': 16800}
2024-09-20 12:30:14:INFO: {'loss': 0.0013501921975375808, 'learning_rate': 3.355261317635472e-07, 'epoch': 17, 'step': 16900}
2024-09-20 12:30:39:INFO: {'loss': 0.01431308665702545, 'learning_rate': 3.062849562727982e-07, 'epoch': 17, 'step': 17000}
2024-09-20 12:31:04:INFO: {'loss': 0.001636722182847734, 'learning_rate': 2.7833650316813123e-07, 'epoch': 17, 'step': 17100}
2024-09-20 12:31:29:INFO: {'loss': 0.004242516292295022, 'learning_rate': 2.51688469889772e-07, 'epoch': 17, 'step': 17200}
2024-09-20 12:31:31:INFO: ***** Running Dev *****
2024-09-20 12:31:31:INFO:   Num examples = 463
2024-09-20 12:31:31:INFO:   Batch size = 16
2024-09-20 12:31:39:INFO: {'acc': 0.9763093952483801, 'p': 0.973186119873817, 'r': 0.970889063729347, 'f1': 0.9720362347380859, 'epoch': 17, 'step': 17208}
2024-09-20 12:31:39:INFO: ***** Running Test *****
2024-09-20 12:31:39:INFO:   Num examples = 477
2024-09-20 12:31:39:INFO:   Batch size = 16
2024-09-20 12:31:48:INFO: {'acc': 0.971907312819235, 'p': 0.9692307692307692, 'r': 0.9642857142857143, 'f1': 0.9667519181585678, 'epoch': 17, 'step': 17208}
2024-09-20 12:32:11:INFO: {'loss': 0.004397713366097377, 'learning_rate': 2.263481957220276e-07, 'epoch': 18, 'step': 17300}
2024-09-20 12:32:35:INFO: {'loss': 0.001040964647409055, 'learning_rate': 2.0232265977193465e-07, 'epoch': 18, 'step': 17400}
2024-09-20 12:33:00:INFO: {'loss': 0.0012668064499780484, 'learning_rate': 1.7961847904710173e-07, 'epoch': 18, 'step': 17500}
2024-09-20 12:33:25:INFO: {'loss': 0.0011295823106911484, 'learning_rate': 1.5824190663328521e-07, 'epoch': 18, 'step': 17600}
2024-09-20 12:33:50:INFO: {'loss': 0.0057957676294972775, 'learning_rate': 1.3819882997218981e-07, 'epoch': 18, 'step': 17700}
2024-09-20 12:34:14:INFO: {'loss': 0.0024060133039665744, 'learning_rate': 1.1949476923997394e-07, 'epoch': 18, 'step': 17800}
2024-09-20 12:34:39:INFO: {'loss': 0.012128557059359082, 'learning_rate': 1.0213487582691139e-07, 'epoch': 18, 'step': 17900}
2024-09-20 12:35:04:INFO: {'loss': 0.004856444553572601, 'learning_rate': 8.612393091861349e-08, 'epoch': 18, 'step': 18000}
2024-09-20 12:35:29:INFO: {'loss': 0.010873701267621527, 'learning_rate': 7.146634417922016e-08, 'epoch': 18, 'step': 18100}
2024-09-20 12:35:45:INFO: ***** Running Dev *****
2024-09-20 12:35:45:INFO:   Num examples = 463
2024-09-20 12:35:45:INFO:   Batch size = 16
2024-09-20 12:35:53:INFO: {'acc': 0.9765118790496761, 'p': 0.972397476340694, 'r': 0.970102281667978, 'f1': 0.9712485230405671, 'epoch': 18, 'step': 18164}
2024-09-20 12:35:53:INFO: ***** Running Test *****
2024-09-20 12:35:53:INFO:   Num examples = 477
2024-09-20 12:35:53:INFO:   Batch size = 16
2024-09-20 12:36:02:INFO: {'acc': 0.9722187616793323, 'p': 0.9692532942898975, 'r': 0.9650145772594753, 'f1': 0.9671292914536157, 'epoch': 18, 'step': 18164}
2024-09-20 12:36:11:INFO: {'loss': 0.004156079800386578, 'learning_rate': 5.816615253690539e-08, 'epoch': 19, 'step': 18200}
2024-09-20 12:36:36:INFO: {'loss': 0.0021376217395800267, 'learning_rate': 4.622701907204652e-08, 'epoch': 19, 'step': 18300}
2024-09-20 12:37:00:INFO: {'loss': 0.003010642222975548, 'learning_rate': 3.565223200835577e-08, 'epoch': 19, 'step': 18400}
2024-09-20 12:37:25:INFO: {'loss': 0.0011096702771328636, 'learning_rate': 2.644470380724906e-08, 'epoch': 19, 'step': 18500}
2024-09-20 12:37:50:INFO: {'loss': 0.0011802662221930404, 'learning_rate': 1.8606970365710465e-08, 'epoch': 19, 'step': 18600}
2024-09-20 12:38:15:INFO: {'loss': 0.007625439961605025, 'learning_rate': 1.214119031786809e-08, 'epoch': 19, 'step': 18700}
2024-09-20 12:38:39:INFO: {'loss': 0.0022330752794960064, 'learning_rate': 7.049144440469669e-09, 'epoch': 19, 'step': 18800}
2024-09-20 12:39:04:INFO: {'loss': 0.001481736339899271, 'learning_rate': 3.332235162429864e-09, 'epoch': 19, 'step': 18900}
2024-09-20 12:39:29:INFO: {'loss': 0.0035112357486559633, 'learning_rate': 9.914861785803587e-10, 'epoch': 19, 'step': 19000}
2024-09-20 12:39:54:INFO: {'loss': 0.005195119236020673, 'learning_rate': 2.7542167727601098e-11, 'epoch': 19, 'step': 19100}
2024-09-20 12:39:59:INFO: ***** Running Dev *****
2024-09-20 12:39:59:INFO:   Num examples = 463
2024-09-20 12:39:59:INFO:   Batch size = 16
2024-09-20 12:40:07:INFO: {'acc': 0.9765118790496761, 'p': 0.972397476340694, 'r': 0.970102281667978, 'f1': 0.9712485230405671, 'epoch': 19, 'step': 19120}
2024-09-20 12:40:07:INFO: ***** Running Test *****
2024-09-20 12:40:07:INFO:   Num examples = 477
2024-09-20 12:40:07:INFO:   Batch size = 16
2024-09-20 12:40:16:INFO: {'acc': 0.9722187616793323, 'p': 0.9692532942898975, 'r': 0.9650145772594753, 'f1': 0.9671292914536157, 'epoch': 19, 'step': 19120}
2024-09-20 12:40:16:INFO: 

Training completed. Do not forget to share your model on huggingface.co/models =)


2024-09-20 12:40:16:INFO: *** Dev Evaluate ***
2024-09-20 12:40:16:INFO: ***** Running dev *****
2024-09-20 12:40:16:INFO:   Num examples = 463
2024-09-20 12:40:16:INFO:   Batch size = 16
2024-09-20 12:40:24:INFO: Dev Result: acc: 0.9765, p: 0.9724, r: 0.9701, f1: 0.9712

2024-09-20 12:40:24:INFO: *** Test Evaluate ***
2024-09-20 12:40:25:INFO: ***** Running test *****
2024-09-20 12:40:25:INFO:   Num examples = 477
2024-09-20 12:40:25:INFO:   Batch size = 16
2024-09-20 12:40:34:INFO: Test Result: acc: 0.9722, p: 0.9693, r: 0.9650, f1: 0.9671

