2024-08-09 11:11:58:INFO: Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True, 16-bits training: False
2024-08-09 11:11:58:INFO: Training/evaluation parameters Namespace(T_mult=1, adam_epsilon=1e-08, bigram_min_freq=1, char_min_freq=1, config_name='data/berts/bert/config.json', data_dir='data/dataset/NER/resume', dataset='resume', decay_rate=0.999, decay_steps=200, default_label='O', device=device(type='cuda', index=0), do_eval=True, do_predict=True, do_shuffle=True, do_train=True, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, label='all', label_file='data/dataset/NER/resume/labels.txt', label_num=28, lattice=1, lattice_min_freq=1, learning_rate=1e-05, lexicon_name='yj', local_rank=0, logging_dir='data/resume/log', logging_steps=100, max_grad_norm=1.0, max_scan_num=1000, max_seq_length=256, max_steps=-1, max_word_num=5, mid_data_dir='data/dataset/NER/resume/mid_data', mid_label_file='data/dataset/NER/resume/mid_data/labels.json', model_name_or_path='data/berts/bert/pytorch_model.bin', model_type='WCBertCRF_Token', n_gpu=1, no_cuda=False, nodes=2, num_tags=4, num_train_epochs=20, number_normalized=0, only_lexicon_in_train=False, only_train_min_freq=True, output_dir='data/result/NER/resume/lebertcrf', overwrite_cache=True, per_gpu_eval_batch_size=16, per_gpu_train_batch_size=4, rewarm_epoch_num=2, save_steps=600, save_total_limit=50, saved_embedding_dir='data/dataset/NER/resume', scheduler='CAWR', seed=106524, sgd_momentum=0.9, train_clip=False, vocab_file='data/berts/bert/vocab.txt', warmup_steps=190, weight_decay=0.0, word_embed_dim=200, word_embedding='data/embedding/word_embedding.txt', word_min_freq=1, word_vocab_file='data/vocab/tencent_vocab.txt')
2024-08-09 11:12:06:INFO: ***** Running training *****
2024-08-09 11:12:06:INFO:   Num examples = 3821
2024-08-09 11:12:06:INFO:   Num Epochs = 20
2024-08-09 11:12:06:INFO:   Instantaneous batch size per device = 4
2024-08-09 11:12:06:INFO:   Total train batch size (w. parallel, distributed & accumulation) = 4
2024-08-09 11:12:06:INFO:   Gradient Accumulation steps = 1
2024-08-09 11:12:06:INFO:   Total optimization steps = 19120
2024-08-09 11:12:56:INFO: {'loss': 365.92111602783206, 'learning_rate': 5.263157894736842e-06, 'epoch': 0, 'step': 100}
2024-08-09 11:13:37:INFO: {'loss': 91.40441650390625, 'learning_rate': 9.999993114453328e-06, 'epoch': 0, 'step': 200}
2024-08-09 11:14:17:INFO: {'loss': 36.69436340332031, 'learning_rate': 9.999166871799133e-06, 'epoch': 0, 'step': 300}
2024-08-09 11:14:57:INFO: {'loss': 36.12123474121094, 'learning_rate': 9.996963780557683e-06, 'epoch': 0, 'step': 400}
2024-08-09 11:15:37:INFO: {'loss': 18.277159423828124, 'learning_rate': 9.993384447494693e-06, 'epoch': 0, 'step': 500}
2024-08-09 11:16:17:INFO: {'loss': 25.561648864746093, 'learning_rate': 9.988429858414358e-06, 'epoch': 0, 'step': 600}
2024-08-09 11:16:57:INFO: {'loss': 20.211489868164062, 'learning_rate': 9.982101377887845e-06, 'epoch': 0, 'step': 700}
2024-08-09 11:17:37:INFO: {'loss': 26.098663330078125, 'learning_rate': 9.974400748877469e-06, 'epoch': 0, 'step': 800}
2024-08-09 11:18:17:INFO: {'loss': 17.148860473632812, 'learning_rate': 9.96533009225666e-06, 'epoch': 0, 'step': 900}
2024-08-09 11:18:39:INFO: ***** Running Dev *****
2024-08-09 11:18:39:INFO:   Num examples = 463
2024-08-09 11:18:39:INFO:   Batch size = 16
2024-08-09 11:18:44:INFO: {'acc': 0.9716342692584593, 'p': 0.9109545163356823, 'r': 0.9498997995991983, 'f1': 0.9300196206671026, 'epoch': 0, 'step': 956}
2024-08-09 11:18:44:INFO: ***** Running Test *****
2024-08-09 11:18:44:INFO:   Num examples = 477
2024-08-09 11:18:44:INFO:   Batch size = 16
2024-08-09 11:18:49:INFO: {'acc': 0.9667549668874172, 'p': 0.9178001182732111, 'r': 0.9521472392638037, 'f1': 0.9346582354712435, 'epoch': 0, 'step': 956}
2024-08-09 11:19:06:INFO: {'loss': 16.178377075195314, 'learning_rate': 9.954891906225833e-06, 'epoch': 1, 'step': 1000}
2024-08-09 11:19:46:INFO: {'loss': 14.874093627929687, 'learning_rate': 9.943089065624343e-06, 'epoch': 1, 'step': 1100}
2024-08-09 11:20:26:INFO: {'loss': 18.45203369140625, 'learning_rate': 9.929924821138723e-06, 'epoch': 1, 'step': 1200}
2024-08-09 11:21:05:INFO: {'loss': 18.239749145507812, 'learning_rate': 9.915402798407383e-06, 'epoch': 1, 'step': 1300}
2024-08-09 11:21:45:INFO: {'loss': 16.01787353515625, 'learning_rate': 9.899526997022054e-06, 'epoch': 1, 'step': 1400}
2024-08-09 11:22:26:INFO: {'loss': 10.949556884765625, 'learning_rate': 9.882301789426234e-06, 'epoch': 1, 'step': 1500}
2024-08-09 11:23:05:INFO: {'loss': 20.161729736328127, 'learning_rate': 9.863731919710964e-06, 'epoch': 1, 'step': 1600}
2024-08-09 11:23:45:INFO: {'loss': 12.933132934570313, 'learning_rate': 9.843822502308213e-06, 'epoch': 1, 'step': 1700}
2024-08-09 11:24:24:INFO: {'loss': 16.842922973632813, 'learning_rate': 9.822579020582297e-06, 'epoch': 1, 'step': 1800}
2024-08-09 11:25:03:INFO: {'loss': 17.006387939453123, 'learning_rate': 9.800007325319666e-06, 'epoch': 1, 'step': 1900}
2024-08-09 11:25:08:INFO: ***** Running Dev *****
2024-08-09 11:25:08:INFO:   Num examples = 463
2024-08-09 11:25:08:INFO:   Batch size = 16
2024-08-09 11:25:13:INFO: {'acc': 0.9773218142548596, 'p': 0.9374185136897001, 'r': 0.9605878423513694, 'f1': 0.9488617617947872, 'epoch': 1, 'step': 1912}
2024-08-09 11:25:13:INFO: ***** Running Test *****
2024-08-09 11:25:13:INFO:   Num examples = 477
2024-08-09 11:25:13:INFO:   Batch size = 16
2024-08-09 11:25:18:INFO: {'acc': 0.97, 'p': 0.9325775656324582, 'r': 0.9588957055214724, 'f1': 0.9455535390199636, 'epoch': 1, 'step': 1912}
2024-08-09 11:25:53:INFO: {'loss': 13.863749389648438, 'learning_rate': 9.776113633117514e-06, 'epoch': 2, 'step': 2000}
2024-08-09 11:26:32:INFO: {'loss': 9.07900146484375, 'learning_rate': 9.750904524671623e-06, 'epoch': 2, 'step': 2100}
2024-08-09 11:27:12:INFO: {'loss': 16.112912902832033, 'learning_rate': 9.72438694296394e-06, 'epoch': 2, 'step': 2200}
2024-08-09 11:27:51:INFO: {'loss': 9.83029541015625, 'learning_rate': 9.696568191350373e-06, 'epoch': 2, 'step': 2300}
2024-08-09 11:28:30:INFO: {'loss': 7.9478607177734375, 'learning_rate': 9.667455931549336e-06, 'epoch': 2, 'step': 2400}
2024-08-09 11:29:09:INFO: {'loss': 13.589475708007813, 'learning_rate': 9.637058181531583e-06, 'epoch': 2, 'step': 2500}
2024-08-09 11:29:49:INFO: {'loss': 9.664049682617188, 'learning_rate': 9.605383313311937e-06, 'epoch': 2, 'step': 2600}
2024-08-09 11:30:28:INFO: {'loss': 13.585140380859375, 'learning_rate': 9.572440050643515e-06, 'epoch': 2, 'step': 2700}
2024-08-09 11:31:08:INFO: {'loss': 18.72195983886719, 'learning_rate': 9.538237466615057e-06, 'epoch': 2, 'step': 2800}
2024-08-09 11:31:34:INFO: ***** Running Dev *****
2024-08-09 11:31:34:INFO:   Num examples = 463
2024-08-09 11:31:34:INFO:   Batch size = 16
2024-08-09 11:31:39:INFO: {'acc': 0.9791936645068394, 'p': 0.9419439008480104, 'r': 0.9645958583834335, 'f1': 0.9531353135313532, 'epoch': 2, 'step': 2868}
2024-08-09 11:31:39:INFO: ***** Running Test *****
2024-08-09 11:31:39:INFO:   Num examples = 477
2024-08-09 11:31:39:INFO:   Batch size = 16
2024-08-09 11:31:45:INFO: {'acc': 0.9688079470198675, 'p': 0.9301075268817204, 'r': 0.9552147239263804, 'f1': 0.9424939467312349, 'epoch': 2, 'step': 2868}
2024-08-09 11:31:57:INFO: {'loss': 12.6412646484375, 'learning_rate': 9.502784981152066e-06, 'epoch': 3, 'step': 2900}
2024-08-09 11:32:36:INFO: {'loss': 9.690755004882812, 'learning_rate': 9.466092358422405e-06, 'epoch': 3, 'step': 3000}
2024-08-09 11:33:16:INFO: {'loss': 6.51753662109375, 'learning_rate': 9.4281697041471e-06, 'epoch': 3, 'step': 3100}
2024-08-09 11:33:55:INFO: {'loss': 9.21365234375, 'learning_rate': 9.389027462817066e-06, 'epoch': 3, 'step': 3200}
2024-08-09 11:34:35:INFO: {'loss': 8.321302490234375, 'learning_rate': 9.348676414816526e-06, 'epoch': 3, 'step': 3300}
2024-08-09 11:35:14:INFO: {'loss': 8.812908325195313, 'learning_rate': 9.307127673453928e-06, 'epoch': 3, 'step': 3400}
2024-08-09 11:35:53:INFO: {'loss': 8.52606689453125, 'learning_rate': 9.264392681901166e-06, 'epoch': 3, 'step': 3500}
2024-08-09 11:36:33:INFO: {'loss': 5.894466552734375, 'learning_rate': 9.220483210041958e-06, 'epoch': 3, 'step': 3600}
2024-08-09 11:37:12:INFO: {'loss': 8.955642700195312, 'learning_rate': 9.175411351230221e-06, 'epoch': 3, 'step': 3700}
2024-08-09 11:37:52:INFO: {'loss': 8.270629272460937, 'learning_rate': 9.129189518959393e-06, 'epoch': 3, 'step': 3800}
2024-08-09 11:38:01:INFO: ***** Running Dev *****
2024-08-09 11:38:01:INFO:   Num examples = 463
2024-08-09 11:38:01:INFO:   Batch size = 16
2024-08-09 11:38:06:INFO: {'acc': 0.9769618430525558, 'p': 0.9410222804718218, 'r': 0.9592518370073481, 'f1': 0.9500496195831954, 'epoch': 3, 'step': 3824}
2024-08-09 11:38:06:INFO: ***** Running Test *****
2024-08-09 11:38:06:INFO:   Num examples = 477
2024-08-09 11:38:06:INFO:   Batch size = 16
2024-08-09 11:38:11:INFO: {'acc': 0.9697350993377484, 'p': 0.9446782922429344, 'r': 0.9638036809815951, 'f1': 0.9541451563923473, 'epoch': 3, 'step': 3824}
2024-08-09 11:38:41:INFO: {'loss': 4.542836303710938, 'learning_rate': 9.081830443443542e-06, 'epoch': 4, 'step': 3900}
2024-08-09 11:39:21:INFO: {'loss': 10.646615600585937, 'learning_rate': 9.033347168111282e-06, 'epoch': 4, 'step': 4000}
2024-08-09 11:40:00:INFO: {'loss': 12.4988623046875, 'learning_rate': 8.983753046013403e-06, 'epoch': 4, 'step': 4100}
2024-08-09 11:40:40:INFO: {'loss': 4.4053173828125, 'learning_rate': 8.933061736145236e-06, 'epoch': 4, 'step': 4200}
2024-08-09 11:41:19:INFO: {'loss': 9.946529541015625, 'learning_rate': 8.881287199684743e-06, 'epoch': 4, 'step': 4300}
2024-08-09 11:41:58:INFO: {'loss': 5.745447387695313, 'learning_rate': 8.828443696147403e-06, 'epoch': 4, 'step': 4400}
2024-08-09 11:42:38:INFO: {'loss': 8.699149169921874, 'learning_rate': 8.774545779458912e-06, 'epoch': 4, 'step': 4500}
2024-08-09 11:43:17:INFO: {'loss': 9.043126220703124, 'learning_rate': 8.719608293946801e-06, 'epoch': 4, 'step': 4600}
2024-08-09 11:43:56:INFO: {'loss': 7.733436889648438, 'learning_rate': 8.663646370252093e-06, 'epoch': 4, 'step': 4700}
2024-08-09 11:44:28:INFO: ***** Running Dev *****
2024-08-09 11:44:28:INFO:   Num examples = 463
2024-08-09 11:44:28:INFO:   Batch size = 16
2024-08-09 11:44:33:INFO: {'acc': 0.9756659467242621, 'p': 0.9423328964613368, 'r': 0.9605878423513694, 'f1': 0.951372808468409, 'epoch': 4, 'step': 4780}
2024-08-09 11:44:33:INFO: ***** Running Test *****
2024-08-09 11:44:33:INFO:   Num examples = 477
2024-08-09 11:44:33:INFO:   Batch size = 16
2024-08-09 11:44:38:INFO: {'acc': 0.96841059602649, 'p': 0.9331742243436754, 'r': 0.9595092024539877, 'f1': 0.9461584996975196, 'epoch': 4, 'step': 4780}
2024-08-09 11:44:46:INFO: {'loss': 4.3742529296875, 'learning_rate': 8.606675421162064e-06, 'epoch': 5, 'step': 4800}
2024-08-09 11:45:25:INFO: {'loss': 2.87629638671875, 'learning_rate': 8.54871113736534e-06, 'epoch': 5, 'step': 4900}
2024-08-09 11:46:05:INFO: {'loss': 1.5694561767578126, 'learning_rate': 8.48976948313043e-06, 'epoch': 5, 'step': 5000}
2024-08-09 11:46:44:INFO: {'loss': 4.950205078125, 'learning_rate': 8.429866691908916e-06, 'epoch': 5, 'step': 5100}
2024-08-09 11:47:23:INFO: {'loss': 1.805643310546875, 'learning_rate': 8.369019261864506e-06, 'epoch': 5, 'step': 5200}
2024-08-09 11:48:03:INFO: {'loss': 2.5844921875, 'learning_rate': 8.30724395132919e-06, 'epoch': 5, 'step': 5300}
2024-08-09 11:48:42:INFO: {'loss': 4.504551391601563, 'learning_rate': 8.24455777418772e-06, 'epoch': 5, 'step': 5400}
2024-08-09 11:49:22:INFO: {'loss': 8.517362060546875, 'learning_rate': 8.18097799519174e-06, 'epoch': 5, 'step': 5500}
2024-08-09 11:50:01:INFO: {'loss': 6.073215942382813, 'learning_rate': 8.116522125204783e-06, 'epoch': 5, 'step': 5600}
2024-08-09 11:50:40:INFO: {'loss': 11.90777587890625, 'learning_rate': 8.05120791637952e-06, 'epoch': 5, 'step': 5700}
2024-08-09 11:50:54:INFO: ***** Running Dev *****
2024-08-09 11:50:54:INFO:   Num examples = 463
2024-08-09 11:50:54:INFO:   Batch size = 16
2024-08-09 11:51:00:INFO: {'acc': 0.9795536357091432, 'p': 0.9431000654022237, 'r': 0.9632598530394122, 'f1': 0.9530733641771315, 'epoch': 5, 'step': 5736}
2024-08-09 11:51:00:INFO: ***** Running Test *****
2024-08-09 11:51:00:INFO:   Num examples = 477
2024-08-09 11:51:00:INFO:   Batch size = 16
2024-08-09 11:51:05:INFO: {'acc': 0.9690728476821192, 'p': 0.9405762304921969, 'r': 0.9613496932515337, 'f1': 0.9508495145631067, 'epoch': 5, 'step': 5736}
2024-08-09 11:51:30:INFO: {'loss': 4.026257934570313, 'learning_rate': 7.985053357268533e-06, 'epoch': 6, 'step': 5800}
2024-08-09 11:52:09:INFO: {'loss': 4.0243505859375, 'learning_rate': 7.918076667869996e-06, 'epoch': 6, 'step': 5900}
2024-08-09 11:52:49:INFO: {'loss': 2.3398431396484374, 'learning_rate': 7.850296294609586e-06, 'epoch': 6, 'step': 6000}
2024-08-09 11:53:28:INFO: {'loss': 5.529580078125, 'learning_rate': 7.78173090526007e-06, 'epoch': 6, 'step': 6100}
2024-08-09 11:54:08:INFO: {'loss': 2.8790875244140626, 'learning_rate': 7.712399383799896e-06, 'epoch': 6, 'step': 6200}
2024-08-09 11:54:47:INFO: {'loss': 1.352802734375, 'learning_rate': 7.642320825212248e-06, 'epoch': 6, 'step': 6300}
2024-08-09 11:55:26:INFO: {'loss': 5.992181396484375, 'learning_rate': 7.571514530226004e-06, 'epoch': 6, 'step': 6400}
2024-08-09 11:56:05:INFO: {'loss': 5.089510498046875, 'learning_rate': 7.500000000000001e-06, 'epoch': 6, 'step': 6500}
2024-08-09 11:56:45:INFO: {'loss': 4.79304931640625, 'learning_rate': 7.4277969307521135e-06, 'epoch': 6, 'step': 6600}
2024-08-09 11:57:21:INFO: ***** Running Dev *****
2024-08-09 11:57:21:INFO:   Num examples = 463
2024-08-09 11:57:21:INFO:   Batch size = 16
2024-08-09 11:57:26:INFO: {'acc': 0.9773218142548596, 'p': 0.9384010484927916, 'r': 0.9565798263193053, 'f1': 0.9474032418127687, 'epoch': 6, 'step': 6692}
2024-08-09 11:57:26:INFO: ***** Running Test *****
2024-08-09 11:57:26:INFO:   Num examples = 477
2024-08-09 11:57:26:INFO:   Batch size = 16
2024-08-09 11:57:31:INFO: {'acc': 0.9695364238410596, 'p': 0.9428055388320289, 'r': 0.9607361963190184, 'f1': 0.951686417502279, 'epoch': 6, 'step': 6692}
2024-08-09 11:57:34:INFO: {'loss': 3.801737060546875, 'learning_rate': 7.354925208334615e-06, 'epoch': 7, 'step': 6700}
2024-08-09 11:58:14:INFO: {'loss': 2.04393310546875, 'learning_rate': 7.2814049027572945e-06, 'epoch': 7, 'step': 6800}
2024-08-09 11:58:53:INFO: {'loss': 2.1758575439453125, 'learning_rate': 7.207256262659868e-06, 'epoch': 7, 'step': 6900}
2024-08-09 11:59:32:INFO: {'loss': 1.889083251953125, 'learning_rate': 7.132499709735187e-06, 'epoch': 7, 'step': 7000}
2024-08-09 12:00:12:INFO: {'loss': 0.993292236328125, 'learning_rate': 7.057155833104783e-06, 'epoch': 7, 'step': 7100}
2024-08-09 12:00:51:INFO: {'loss': 7.812337646484375, 'learning_rate': 6.981245383648304e-06, 'epoch': 7, 'step': 7200}
2024-08-09 12:01:30:INFO: {'loss': 2.236793212890625, 'learning_rate': 6.904789268288399e-06, 'epoch': 7, 'step': 7300}
2024-08-09 12:02:10:INFO: {'loss': 1.3395379638671876, 'learning_rate': 6.82780854423262e-06, 'epoch': 7, 'step': 7400}
2024-08-09 12:02:49:INFO: {'loss': 2.0737860107421877, 'learning_rate': 6.750324413173948e-06, 'epoch': 7, 'step': 7500}
2024-08-09 12:03:28:INFO: {'loss': 6.049472045898438, 'learning_rate': 6.672358215451506e-06, 'epoch': 7, 'step': 7600}
2024-08-09 12:03:47:INFO: ***** Running Dev *****
2024-08-09 12:03:47:INFO:   Num examples = 463
2024-08-09 12:03:47:INFO:   Batch size = 16
2024-08-09 12:03:52:INFO: {'acc': 0.9755219582433405, 'p': 0.9444081098757358, 'r': 0.9645958583834335, 'f1': 0.9543952412425644, 'epoch': 7, 'step': 7648}
2024-08-09 12:03:52:INFO: ***** Running Test *****
2024-08-09 12:03:52:INFO:   Num examples = 477
2024-08-09 12:03:52:INFO:   Batch size = 16
2024-08-09 12:03:58:INFO: {'acc': 0.9703973509933775, 'p': 0.9424805272618334, 'r': 0.9650306748466257, 'f1': 0.9536223097908456, 'epoch': 7, 'step': 7648}
2024-08-09 12:04:18:INFO: {'loss': 1.0551565551757813, 'learning_rate': 6.593931424173102e-06, 'epoch': 8, 'step': 7700}
2024-08-09 12:04:57:INFO: {'loss': 0.46435302734375, 'learning_rate': 6.515065639301199e-06, 'epoch': 8, 'step': 7800}
2024-08-09 12:05:36:INFO: {'loss': 2.3284808349609376, 'learning_rate': 6.435782581703944e-06, 'epoch': 8, 'step': 7900}
2024-08-09 12:06:16:INFO: {'loss': 0.66280029296875, 'learning_rate': 6.356104087172916e-06, 'epoch': 8, 'step': 8000}
2024-08-09 12:06:55:INFO: {'loss': 0.7289764404296875, 'learning_rate': 6.276052100409185e-06, 'epoch': 8, 'step': 8100}
2024-08-09 12:07:34:INFO: {'loss': 1.9853643798828124, 'learning_rate': 6.195648668979417e-06, 'epoch': 8, 'step': 8200}
2024-08-09 12:08:13:INFO: {'loss': 0.432939453125, 'learning_rate': 6.11491593724363e-06, 'epoch': 8, 'step': 8300}
2024-08-09 12:08:53:INFO: {'loss': 2.6079937744140627, 'learning_rate': 6.033876140256276e-06, 'epoch': 8, 'step': 8400}
2024-08-09 12:09:32:INFO: {'loss': 3.6210089111328125, 'learning_rate': 5.952551597642377e-06, 'epoch': 8, 'step': 8500}
2024-08-09 12:10:11:INFO: {'loss': 2.7888311767578124, 'learning_rate': 5.870964707450348e-06, 'epoch': 8, 'step': 8600}
2024-08-09 12:10:13:INFO: ***** Running Dev *****
2024-08-09 12:10:13:INFO:   Num examples = 463
2024-08-09 12:10:13:INFO:   Batch size = 16
2024-08-09 12:10:18:INFO: {'acc': 0.9756659467242621, 'p': 0.9479921000658328, 'r': 0.9619238476953907, 'f1': 0.9549071618037135, 'epoch': 8, 'step': 8604}
2024-08-09 12:10:18:INFO: ***** Running Test *****
2024-08-09 12:10:18:INFO:   Num examples = 477
2024-08-09 12:10:18:INFO:   Batch size = 16
2024-08-09 12:10:23:INFO: {'acc': 0.9695364238410596, 'p': 0.9474002418379686, 'r': 0.9613496932515337, 'f1': 0.9543239951278928, 'epoch': 8, 'step': 8604}
2024-08-09 12:11:01:INFO: {'loss': 0.8775067138671875, 'learning_rate': 5.789137939983211e-06, 'epoch': 9, 'step': 8700}
2024-08-09 12:11:40:INFO: {'loss': 2.39372802734375, 'learning_rate': 5.707093831609945e-06, 'epoch': 9, 'step': 8800}
2024-08-09 12:12:20:INFO: {'loss': 1.999981689453125, 'learning_rate': 5.6248549785586005e-06, 'epoch': 9, 'step': 8900}
2024-08-09 12:12:59:INFO: {'loss': 1.856534423828125, 'learning_rate': 5.542444030692954e-06, 'epoch': 9, 'step': 9000}
2024-08-09 12:13:38:INFO: {'loss': 3.67712646484375, 'learning_rate': 5.459883685274378e-06, 'epoch': 9, 'step': 9100}
2024-08-09 12:14:17:INFO: {'loss': 1.3963238525390624, 'learning_rate': 5.377196680710668e-06, 'epoch': 9, 'step': 9200}
2024-08-09 12:14:57:INFO: {'loss': 1.28910400390625, 'learning_rate': 5.2944057902935195e-06, 'epoch': 9, 'step': 9300}
2024-08-09 12:15:36:INFO: {'loss': 1.9438623046875, 'learning_rate': 5.211533815926417e-06, 'epoch': 9, 'step': 9400}
2024-08-09 12:16:15:INFO: {'loss': 0.78453125, 'learning_rate': 5.12860358184463e-06, 'epoch': 9, 'step': 9500}
2024-08-09 12:16:38:INFO: ***** Running Dev *****
2024-08-09 12:16:38:INFO:   Num examples = 463
2024-08-09 12:16:38:INFO:   Batch size = 16
2024-08-09 12:16:44:INFO: {'acc': 0.9769618430525558, 'p': 0.9508519003931848, 'r': 0.9692718770875084, 'f1': 0.9599735362222958, 'epoch': 9, 'step': 9560}
2024-08-09 12:16:44:INFO: ***** Running Test *****
2024-08-09 12:16:44:INFO:   Num examples = 477
2024-08-09 12:16:44:INFO:   Batch size = 16
2024-08-09 12:16:49:INFO: {'acc': 0.9687417218543046, 'p': 0.9417767106842737, 'r': 0.9625766871165644, 'f1': 0.9520631067961166, 'epoch': 9, 'step': 9560}
2024-08-09 12:17:05:INFO: {'loss': 0.9221353149414062, 'learning_rate': 5.04563792832906e-06, 'epoch': 10, 'step': 9600}
2024-08-09 12:17:44:INFO: {'loss': 0.9877130126953125, 'learning_rate': 4.962659705415677e-06, 'epoch': 10, 'step': 9700}
2024-08-09 12:18:23:INFO: {'loss': 3.662109375e-05, 'learning_rate': 4.879691766602261e-06, 'epoch': 10, 'step': 9800}
2024-08-09 12:19:02:INFO: {'loss': 0.7967462158203125, 'learning_rate': 4.79675696255418e-06, 'epoch': 10, 'step': 9900}
2024-08-09 12:19:42:INFO: {'loss': 1.4774774169921876, 'learning_rate': 4.7138781348109845e-06, 'epoch': 10, 'step': 10000}
2024-08-09 12:20:21:INFO: {'loss': 0.3587640380859375, 'learning_rate': 4.631078109495468e-06, 'epoch': 10, 'step': 10100}
2024-08-09 12:21:00:INFO: {'loss': 1.17696533203125, 'learning_rate': 4.548379691027005e-06, 'epoch': 10, 'step': 10200}
2024-08-09 12:21:40:INFO: {'loss': 1.5789959716796875, 'learning_rate': 4.465805655840864e-06, 'epoch': 10, 'step': 10300}
2024-08-09 12:22:19:INFO: {'loss': 0.2559527587890625, 'learning_rate': 4.383378746115215e-06, 'epoch': 10, 'step': 10400}
2024-08-09 12:22:58:INFO: {'loss': 2.0136297607421874, 'learning_rate': 4.301121663507571e-06, 'epoch': 10, 'step': 10500}
2024-08-09 12:23:05:INFO: ***** Running Dev *****
2024-08-09 12:23:05:INFO:   Num examples = 463
2024-08-09 12:23:05:INFO:   Batch size = 16
2024-08-09 12:23:10:INFO: {'acc': 0.9802015838732901, 'p': 0.9457516339869281, 'r': 0.9665998663994656, 'f1': 0.9560621076973901, 'epoch': 10, 'step': 10516}
2024-08-09 12:23:10:INFO: ***** Running Test *****
2024-08-09 12:23:10:INFO:   Num examples = 477
2024-08-09 12:23:10:INFO:   Batch size = 16
2024-08-09 12:23:15:INFO: {'acc': 0.9658278145695364, 'p': 0.9353293413173652, 'r': 0.9582822085889571, 'f1': 0.9466666666666667, 'epoch': 10, 'step': 10516}
2024-08-09 12:23:48:INFO: {'loss': 0.534490966796875, 'learning_rate': 4.219057062902417e-06, 'epoch': 11, 'step': 10600}
2024-08-09 12:24:28:INFO: {'loss': 0.3434637451171875, 'learning_rate': 4.1372075461716885e-06, 'epoch': 11, 'step': 10700}
2024-08-09 12:25:07:INFO: {'loss': 1.4393017578125, 'learning_rate': 4.055595655949856e-06, 'epoch': 11, 'step': 10800}
2024-08-09 12:25:46:INFO: {'loss': 1.2995001220703124, 'learning_rate': 3.974243869425348e-06, 'epoch': 11, 'step': 10900}
2024-08-09 12:26:26:INFO: {'loss': 0.43581298828125, 'learning_rate': 3.893174592149976e-06, 'epoch': 11, 'step': 11000}
2024-08-09 12:27:05:INFO: {'loss': 0.279141845703125, 'learning_rate': 3.812410151868092e-06, 'epoch': 11, 'step': 11100}
2024-08-09 12:27:44:INFO: {'loss': 1.3051739501953126, 'learning_rate': 3.731972792367179e-06, 'epoch': 11, 'step': 11200}
2024-08-09 12:28:24:INFO: {'loss': 1.058984375, 'learning_rate': 3.6518846673515717e-06, 'epoch': 11, 'step': 11300}
2024-08-09 12:29:03:INFO: {'loss': 2.4124322509765626, 'learning_rate': 3.572167834340977e-06, 'epoch': 11, 'step': 11400}
2024-08-09 12:29:31:INFO: ***** Running Dev *****
2024-08-09 12:29:31:INFO:   Num examples = 463
2024-08-09 12:29:31:INFO:   Batch size = 16
2024-08-09 12:29:37:INFO: {'acc': 0.977825773938085, 'p': 0.945645055664702, 'r': 0.9645958583834335, 'f1': 0.955026455026455, 'epoch': 11, 'step': 11472}
2024-08-09 12:29:37:INFO: ***** Running Test *****
2024-08-09 12:29:37:INFO:   Num examples = 477
2024-08-09 12:29:37:INFO:   Batch size = 16
2024-08-09 12:29:42:INFO: {'acc': 0.968476821192053, 'p': 0.9434075857916917, 'r': 0.9613496932515337, 'f1': 0.9522941355211182, 'epoch': 11, 'step': 11472}
2024-08-09 12:29:53:INFO: {'loss': 1.6303973388671875, 'learning_rate': 3.4928442485954826e-06, 'epoch': 12, 'step': 11500}
2024-08-09 12:30:32:INFO: {'loss': 0.3286859130859375, 'learning_rate': 3.413935757068748e-06, 'epoch': 12, 'step': 11600}
2024-08-09 12:31:12:INFO: {'loss': 0.6422467041015625, 'learning_rate': 3.335464092391003e-06, 'epoch': 12, 'step': 11700}
2024-08-09 12:31:51:INFO: {'loss': 0.00427001953125, 'learning_rate': 3.2574508668835426e-06, 'epoch': 12, 'step': 11800}
2024-08-09 12:32:31:INFO: {'loss': 0.0450396728515625, 'learning_rate': 3.1799175666063615e-06, 'epoch': 12, 'step': 11900}
2024-08-09 12:33:10:INFO: {'loss': 0.0047845458984375, 'learning_rate': 3.102885545440556e-06, 'epoch': 12, 'step': 12000}
2024-08-09 12:33:50:INFO: {'loss': 0.124490966796875, 'learning_rate': 3.026376019207126e-06, 'epoch': 12, 'step': 12100}
2024-08-09 12:34:29:INFO: {'loss': 2.124993896484375, 'learning_rate': 2.950410059823816e-06, 'epoch': 12, 'step': 12200}
2024-08-09 12:35:09:INFO: {'loss': 0.0059698486328125, 'learning_rate': 2.8750085895015758e-06, 'epoch': 12, 'step': 12300}
2024-08-09 12:35:48:INFO: {'loss': 1.4341241455078124, 'learning_rate': 2.8001923749822524e-06, 'epoch': 12, 'step': 12400}
2024-08-09 12:35:59:INFO: ***** Running Dev *****
2024-08-09 12:35:59:INFO:   Num examples = 463
2024-08-09 12:35:59:INFO:   Batch size = 16
2024-08-09 12:36:04:INFO: {'acc': 0.9784737221022318, 'p': 0.9433224755700326, 'r': 0.9672678690714763, 'f1': 0.9551451187335092, 'epoch': 12, 'step': 12428}
2024-08-09 12:36:04:INFO: ***** Running Test *****
2024-08-09 12:36:04:INFO:   Num examples = 477
2024-08-09 12:36:04:INFO:   Batch size = 16
2024-08-09 12:36:09:INFO: {'acc': 0.9678145695364239, 'p': 0.9315883402736467, 'r': 0.9607361963190184, 'f1': 0.9459377831470854, 'epoch': 12, 'step': 12428}
2024-08-09 12:36:37:INFO: {'loss': 0.20131103515625, 'learning_rate': 2.7259820218191123e-06, 'epoch': 13, 'step': 12500}
2024-08-09 12:37:17:INFO: {'loss': 0.60386474609375, 'learning_rate': 2.6523979687017516e-06, 'epoch': 13, 'step': 12600}
2024-08-09 12:37:56:INFO: {'loss': 0.95197265625, 'learning_rate': 2.579460481826947e-06, 'epoch': 13, 'step': 12700}
2024-08-09 12:38:36:INFO: {'loss': 0.2576641845703125, 'learning_rate': 2.5071896493170533e-06, 'epoch': 13, 'step': 12800}
2024-08-09 12:39:15:INFO: {'loss': 0.019163818359375, 'learning_rate': 2.4356053756873987e-06, 'epoch': 13, 'step': 12900}
2024-08-09 12:39:55:INFO: {'loss': 0.5755194091796875, 'learning_rate': 2.3647273763642853e-06, 'epoch': 13, 'step': 13000}
2024-08-09 12:40:34:INFO: {'loss': 0.492301025390625, 'learning_rate': 2.2945751722550384e-06, 'epoch': 13, 'step': 13100}
2024-08-09 12:41:13:INFO: {'loss': 0.34953369140625, 'learning_rate': 2.2251680843716617e-06, 'epoch': 13, 'step': 13200}
2024-08-09 12:41:53:INFO: {'loss': 0.31959716796875, 'learning_rate': 2.1565252285095158e-06, 'epoch': 13, 'step': 13300}
2024-08-09 12:42:26:INFO: ***** Running Dev *****
2024-08-09 12:42:26:INFO:   Num examples = 463
2024-08-09 12:42:26:INFO:   Batch size = 16
2024-08-09 12:42:31:INFO: {'acc': 0.9803455723542117, 'p': 0.9539473684210527, 'r': 0.9686038744154977, 'f1': 0.9612197547232351, 'epoch': 13, 'step': 13384}
2024-08-09 12:42:31:INFO: ***** Running Test *****
2024-08-09 12:42:31:INFO:   Num examples = 477
2024-08-09 12:42:31:INFO:   Batch size = 16
2024-08-09 12:42:36:INFO: {'acc': 0.9694039735099338, 'p': 0.944544906570223, 'r': 0.9613496932515337, 'f1': 0.952873213742779, 'epoch': 13, 'step': 13384}
2024-08-09 12:42:42:INFO: {'loss': 0.03819122314453125, 'learning_rate': 2.088665509982534e-06, 'epoch': 14, 'step': 13400}
2024-08-09 12:43:22:INFO: {'loss': 0.5117620849609374, 'learning_rate': 2.0216076184164045e-06, 'epoch': 14, 'step': 13500}
2024-08-09 12:44:01:INFO: {'loss': 0.90201416015625, 'learning_rate': 1.955370022601157e-06, 'epoch': 14, 'step': 13600}
2024-08-09 12:44:40:INFO: {'loss': 0.69679931640625, 'learning_rate': 1.8899709654045607e-06, 'epoch': 14, 'step': 13700}
2024-08-09 12:45:19:INFO: {'loss': 0.472198486328125, 'learning_rate': 1.8254284587477683e-06, 'epoch': 14, 'step': 13800}
2024-08-09 12:45:59:INFO: {'loss': 0.122564697265625, 'learning_rate': 1.7617602786445403e-06, 'epoch': 14, 'step': 13900}
2024-08-09 12:46:38:INFO: {'loss': 0.310286865234375, 'learning_rate': 1.698983960305458e-06, 'epoch': 14, 'step': 14000}
2024-08-09 12:47:17:INFO: {'loss': 0.6031585693359375, 'learning_rate': 1.637116793308453e-06, 'epoch': 14, 'step': 14100}
2024-08-09 12:47:57:INFO: {'loss': 0.3123077392578125, 'learning_rate': 1.5761758168369863e-06, 'epoch': 14, 'step': 14200}
2024-08-09 12:48:36:INFO: {'loss': 0.1265081787109375, 'learning_rate': 1.5161778149871874e-06, 'epoch': 14, 'step': 14300}
2024-08-09 12:48:52:INFO: ***** Running Dev *****
2024-08-09 12:48:52:INFO:   Num examples = 463
2024-08-09 12:48:52:INFO:   Batch size = 16
2024-08-09 12:48:57:INFO: {'acc': 0.979049676025918, 'p': 0.9513797634691196, 'r': 0.9672678690714763, 'f1': 0.9592580324610799, 'epoch': 14, 'step': 14340}
2024-08-09 12:48:57:INFO: ***** Running Test *****
2024-08-09 12:48:57:INFO:   Num examples = 477
2024-08-09 12:48:57:INFO:   Batch size = 16
2024-08-09 12:49:02:INFO: {'acc': 0.9686754966887418, 'p': 0.9451807228915663, 'r': 0.9625766871165644, 'f1': 0.9537993920972645, 'epoch': 14, 'step': 14340}
2024-08-09 12:49:26:INFO: {'loss': 0.23859771728515625, 'learning_rate': 1.457139312145262e-06, 'epoch': 15, 'step': 14400}
2024-08-09 12:50:05:INFO: {'loss': 0.062882080078125, 'learning_rate': 1.39907656843641e-06, 'epoch': 15, 'step': 14500}
2024-08-09 12:50:44:INFO: {'loss': 0.4905010986328125, 'learning_rate': 1.3420055752465362e-06, 'epoch': 15, 'step': 14600}
2024-08-09 12:51:24:INFO: {'loss': 0.163892822265625, 'learning_rate': 1.285942050817971e-06, 'epoch': 15, 'step': 14700}
2024-08-09 12:52:03:INFO: {'loss': 0.5994964599609375, 'learning_rate': 1.2309014359204251e-06, 'epoch': 15, 'step': 14800}
2024-08-09 12:52:43:INFO: {'loss': 0.0115850830078125, 'learning_rate': 1.1768988895983574e-06, 'epoch': 15, 'step': 14900}
2024-08-09 12:53:22:INFO: {'loss': 0.0758770751953125, 'learning_rate': 1.123949284995935e-06, 'epoch': 15, 'step': 15000}
2024-08-09 12:54:02:INFO: {'loss': 0.4069647216796875, 'learning_rate': 1.0720672052607417e-06, 'epoch': 15, 'step': 15100}
2024-08-09 12:54:41:INFO: {'loss': 0.9991650390625, 'learning_rate': 1.021266939527356e-06, 'epoch': 15, 'step': 15200}
2024-08-09 12:55:19:INFO: ***** Running Dev *****
2024-08-09 12:55:19:INFO:   Num examples = 463
2024-08-09 12:55:19:INFO:   Batch size = 16
2024-08-09 12:55:24:INFO: {'acc': 0.9791216702663786, 'p': 0.949475065616798, 'r': 0.9665998663994656, 'f1': 0.9579609400860642, 'epoch': 15, 'step': 15296}
2024-08-09 12:55:24:INFO: ***** Running Test *****
2024-08-09 12:55:24:INFO:   Num examples = 477
2024-08-09 12:55:24:INFO:   Batch size = 16
2024-08-09 12:55:29:INFO: {'acc': 0.9688741721854305, 'p': 0.9451807228915663, 'r': 0.9625766871165644, 'f1': 0.9537993920972645, 'epoch': 15, 'step': 15296}
2024-08-09 12:55:31:INFO: {'loss': 0.22917236328125, 'learning_rate': 9.71562478981886e-07, 'epoch': 16, 'step': 15300}
2024-08-09 12:56:10:INFO: {'loss': 0.8488629150390625, 'learning_rate': 9.229675130085919e-07, 'epoch': 16, 'step': 15400}
2024-08-09 12:56:49:INFO: {'loss': 0.11845458984375, 'learning_rate': 8.754954254196096e-07, 'epoch': 16, 'step': 15500}
2024-08-09 12:57:29:INFO: {'loss': 0.033677978515625, 'learning_rate': 8.2915929076884e-07, 'epoch': 16, 'step': 15600}
2024-08-09 12:58:08:INFO: {'loss': 0.1380987548828125, 'learning_rate': 7.839718707510153e-07, 'epoch': 16, 'step': 15700}
2024-08-09 12:58:48:INFO: {'loss': 0.0793438720703125, 'learning_rate': 7.399456106869296e-07, 'epoch': 16, 'step': 15800}
2024-08-09 12:59:27:INFO: {'loss': 0.00857177734375, 'learning_rate': 6.97092636095798e-07, 'epoch': 16, 'step': 15900}
2024-08-09 13:00:07:INFO: {'loss': 0.0001287841796875, 'learning_rate': 6.554247493557048e-07, 'epoch': 16, 'step': 16000}
2024-08-09 13:00:46:INFO: {'loss': 0.3175372314453125, 'learning_rate': 6.149534264530433e-07, 'epoch': 16, 'step': 16100}
2024-08-09 13:01:26:INFO: {'loss': 0.0022674560546875, 'learning_rate': 5.756898138218448e-07, 'epoch': 16, 'step': 16200}
2024-08-09 13:01:46:INFO: ***** Running Dev *****
2024-08-09 13:01:46:INFO:   Num examples = 463
2024-08-09 13:01:46:INFO:   Batch size = 16
2024-08-09 13:01:51:INFO: {'acc': 0.9797696184305256, 'p': 0.9533201840894149, 'r': 0.9686038744154977, 'f1': 0.9609012591119946, 'epoch': 16, 'step': 16252}
2024-08-09 13:01:51:INFO: ***** Running Test *****
2024-08-09 13:01:51:INFO:   Num examples = 477
2024-08-09 13:01:51:INFO:   Batch size = 16
2024-08-09 13:01:57:INFO: {'acc': 0.9676158940397351, 'p': 0.9394121175764847, 'r': 0.9607361963190184, 'f1': 0.9499545040946316, 'epoch': 16, 'step': 16252}
2024-08-09 13:02:15:INFO: {'loss': 0.00032440185546875, 'learning_rate': 5.376447252738848e-07, 'epoch': 17, 'step': 16300}
2024-08-09 13:02:55:INFO: {'loss': 0.579219970703125, 'learning_rate': 5.008286390203876e-07, 'epoch': 17, 'step': 16400}
2024-08-09 13:03:34:INFO: {'loss': 0.0872119140625, 'learning_rate': 4.6525169478616073e-07, 'epoch': 17, 'step': 16500}
2024-08-09 13:04:14:INFO: {'loss': 0.01258544921875, 'learning_rate': 4.309236910169562e-07, 'epoch': 17, 'step': 16600}
2024-08-09 13:04:53:INFO: {'loss': 0.1789263916015625, 'learning_rate': 3.9785408218082964e-07, 'epoch': 17, 'step': 16700}
2024-08-09 13:05:32:INFO: {'loss': 0.0082147216796875, 'learning_rate': 3.6605197616423116e-07, 'epoch': 17, 'step': 16800}
2024-08-09 13:06:11:INFO: {'loss': 0.0726397705078125, 'learning_rate': 3.355261317635472e-07, 'epoch': 17, 'step': 16900}
2024-08-09 13:06:51:INFO: {'loss': 0.1070513916015625, 'learning_rate': 3.062849562727982e-07, 'epoch': 17, 'step': 17000}
2024-08-09 13:07:30:INFO: {'loss': 0.2368243408203125, 'learning_rate': 2.7833650316813123e-07, 'epoch': 17, 'step': 17100}
2024-08-09 13:08:10:INFO: {'loss': 0.0566119384765625, 'learning_rate': 2.51688469889772e-07, 'epoch': 17, 'step': 17200}
2024-08-09 13:08:13:INFO: ***** Running Dev *****
2024-08-09 13:08:13:INFO:   Num examples = 463
2024-08-09 13:08:13:INFO:   Batch size = 16
2024-08-09 13:08:18:INFO: {'acc': 0.9797696184305256, 'p': 0.9526938239159002, 'r': 0.9686038744154977, 'f1': 0.9605829744948658, 'epoch': 17, 'step': 17208}
2024-08-09 13:08:18:INFO: ***** Running Test *****
2024-08-09 13:08:18:INFO:   Num examples = 477
2024-08-09 13:08:18:INFO:   Batch size = 16
2024-08-09 13:08:23:INFO: {'acc': 0.9676158940397351, 'p': 0.945750452079566, 'r': 0.9625766871165644, 'f1': 0.9540893888719975, 'epoch': 17, 'step': 17208}
2024-08-09 13:08:59:INFO: {'loss': 0.010084228515625, 'learning_rate': 2.263481957220276e-07, 'epoch': 18, 'step': 17300}
2024-08-09 13:09:39:INFO: {'loss': 0.08435302734375, 'learning_rate': 2.0232265977193465e-07, 'epoch': 18, 'step': 17400}
2024-08-09 13:10:18:INFO: {'loss': 0.1584234619140625, 'learning_rate': 1.7961847904710173e-07, 'epoch': 18, 'step': 17500}
2024-08-09 13:10:58:INFO: {'loss': 0.0015069580078125, 'learning_rate': 1.5824190663328521e-07, 'epoch': 18, 'step': 17600}
2024-08-09 13:11:37:INFO: {'loss': 0.063773193359375, 'learning_rate': 1.3819882997218981e-07, 'epoch': 18, 'step': 17700}
2024-08-09 13:12:17:INFO: {'loss': 0.068702392578125, 'learning_rate': 1.1949476923997394e-07, 'epoch': 18, 'step': 17800}
2024-08-09 13:12:56:INFO: {'loss': 0.0093646240234375, 'learning_rate': 1.0213487582691139e-07, 'epoch': 18, 'step': 17900}
2024-08-09 13:13:36:INFO: {'loss': 0.6688616943359375, 'learning_rate': 8.612393091861349e-08, 'epoch': 18, 'step': 18000}
2024-08-09 13:14:15:INFO: {'loss': 0.000235595703125, 'learning_rate': 7.146634417922016e-08, 'epoch': 18, 'step': 18100}
2024-08-09 13:14:40:INFO: ***** Running Dev *****
2024-08-09 13:14:40:INFO:   Num examples = 463
2024-08-09 13:14:40:INFO:   Batch size = 16
2024-08-09 13:14:45:INFO: {'acc': 0.9798416126709864, 'p': 0.9526938239159002, 'r': 0.9686038744154977, 'f1': 0.9605829744948658, 'epoch': 18, 'step': 18164}
2024-08-09 13:14:45:INFO: ***** Running Test *****
2024-08-09 13:14:45:INFO:   Num examples = 477
2024-08-09 13:14:45:INFO:   Batch size = 16
2024-08-09 13:14:51:INFO: {'acc': 0.967682119205298, 'p': 0.9423076923076923, 'r': 0.9619631901840491, 'f1': 0.9520340012143291, 'epoch': 18, 'step': 18164}
2024-08-09 13:15:05:INFO: {'loss': 0.6082418823242187, 'learning_rate': 5.816615253690539e-08, 'epoch': 19, 'step': 18200}
2024-08-09 13:15:44:INFO: {'loss': 3.0517578125e-05, 'learning_rate': 4.622701907204652e-08, 'epoch': 19, 'step': 18300}
2024-08-09 13:16:23:INFO: {'loss': 6.34765625e-05, 'learning_rate': 3.565223200835577e-08, 'epoch': 19, 'step': 18400}
2024-08-09 13:17:03:INFO: {'loss': 0.071328125, 'learning_rate': 2.644470380724906e-08, 'epoch': 19, 'step': 18500}
2024-08-09 13:17:42:INFO: {'loss': 0.01880126953125, 'learning_rate': 1.8606970365710465e-08, 'epoch': 19, 'step': 18600}
2024-08-09 13:18:22:INFO: {'loss': 0.0687408447265625, 'learning_rate': 1.214119031786809e-08, 'epoch': 19, 'step': 18700}
2024-08-09 13:19:01:INFO: {'loss': 0.0050115966796875, 'learning_rate': 7.049144440469669e-09, 'epoch': 19, 'step': 18800}
2024-08-09 13:19:40:INFO: {'loss': 0.0069866943359375, 'learning_rate': 3.332235162429864e-09, 'epoch': 19, 'step': 18900}
2024-08-09 13:20:20:INFO: {'loss': 4.21142578125e-05, 'learning_rate': 9.914861785803587e-10, 'epoch': 19, 'step': 19000}
2024-08-09 13:20:59:INFO: {'loss': 0.0001031494140625, 'learning_rate': 2.7542167727601098e-11, 'epoch': 19, 'step': 19100}
2024-08-09 13:21:07:INFO: ***** Running Dev *****
2024-08-09 13:21:07:INFO:   Num examples = 463
2024-08-09 13:21:07:INFO:   Batch size = 16
2024-08-09 13:21:12:INFO: {'acc': 0.9798416126709864, 'p': 0.9526938239159002, 'r': 0.9686038744154977, 'f1': 0.9605829744948658, 'epoch': 19, 'step': 19120}
2024-08-09 13:21:12:INFO: ***** Running Test *****
2024-08-09 13:21:12:INFO:   Num examples = 477
2024-08-09 13:21:12:INFO:   Batch size = 16
2024-08-09 13:21:17:INFO: {'acc': 0.9677483443708609, 'p': 0.9446116797110174, 'r': 0.9625766871165644, 'f1': 0.9535095715587968, 'epoch': 19, 'step': 19120}
2024-08-09 13:21:17:INFO: 

Training completed. Do not forget to share your model on huggingface.co/models =)


2024-08-09 13:21:17:INFO: *** Dev Evaluate ***
2024-08-09 13:21:17:INFO: ***** Running dev *****
2024-08-09 13:21:17:INFO:   Num examples = 463
2024-08-09 13:21:17:INFO:   Batch size = 16
2024-08-09 13:21:22:INFO: Dev Result: acc: 0.9798, p: 0.9527, r: 0.9686, f1: 0.9606

2024-08-09 13:21:22:INFO: *** Test Evaluate ***
2024-08-09 13:21:22:INFO: ***** Running test *****
2024-08-09 13:21:22:INFO:   Num examples = 477
2024-08-09 13:21:22:INFO:   Batch size = 16
2024-08-09 13:21:27:INFO: Test Result: acc: 0.9677, p: 0.9446, r: 0.9626, f1: 0.9535

