2024-08-06 10:26:42:INFO: Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True, 16-bits training: False
2024-08-06 10:26:42:INFO: Training/evaluation parameters Namespace(T_mult=1, adam_epsilon=1e-08, bigram_min_freq=1, char_min_freq=1, config_name='data/berts/bert/config.json', data_dir='data/dataset/NER/resume', dataset='resume', decay_rate=0.999, decay_steps=200, default_label='O', device=device(type='cuda', index=0), do_eval=True, do_predict=True, do_shuffle=True, do_train=True, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, label='all', label_file='data/dataset/NER/resume/labels.txt', label_num=28, lattice=1, lattice_min_freq=1, learning_rate=1e-05, lexicon_name='yj', local_rank=0, logging_dir='data/resume/log', logging_steps=100, max_grad_norm=1.0, max_scan_num=1000, max_seq_length=256, max_steps=-1, max_word_num=5, mid_data_dir='data/dataset/NER/resume/mid_data', mid_label_file='data/dataset/NER/resume/mid_data/labels.json', model_name_or_path='data/berts/bert/pytorch_model.bin', model_type='WCBertCRF_Token', n_gpu=1, no_cuda=False, nodes=2, num_tags=4, num_train_epochs=20, number_normalized=0, only_lexicon_in_train=False, only_train_min_freq=True, output_dir='data/result/NER/resume/lebertcrf', overwrite_cache=True, per_gpu_eval_batch_size=16, per_gpu_train_batch_size=4, rewarm_epoch_num=2, save_steps=600, save_total_limit=50, saved_embedding_dir='data/dataset/NER/resume', scheduler='CAWR', seed=106524, sgd_momentum=0.9, train_clip=False, vocab_file='data/berts/bert/vocab.txt', warmup_steps=190, weight_decay=0.0, word_embed_dim=200, word_embedding='data/embedding/word_embedding.txt', word_min_freq=1, word_vocab_file='data/vocab/tencent_vocab.txt')
2024-08-06 10:26:50:INFO: ***** Running training *****
2024-08-06 10:26:50:INFO:   Num examples = 3821
2024-08-06 10:26:50:INFO:   Num Epochs = 20
2024-08-06 10:26:50:INFO:   Instantaneous batch size per device = 4
2024-08-06 10:26:50:INFO:   Total train batch size (w. parallel, distributed & accumulation) = 4
2024-08-06 10:26:50:INFO:   Gradient Accumulation steps = 1
2024-08-06 10:26:50:INFO:   Total optimization steps = 19120
2024-08-06 10:27:34:INFO: {'loss': 365.89981979370117, 'learning_rate': 5.263157894736842e-06, 'epoch': 0, 'step': 100}
2024-08-06 10:28:14:INFO: {'loss': 89.64026397705078, 'learning_rate': 9.999993114453328e-06, 'epoch': 0, 'step': 200}
2024-08-06 10:28:54:INFO: {'loss': 35.83509643554687, 'learning_rate': 9.999166871799133e-06, 'epoch': 0, 'step': 300}
2024-08-06 10:29:34:INFO: {'loss': 23.182571716308594, 'learning_rate': 9.996963780557683e-06, 'epoch': 0, 'step': 400}
2024-08-06 10:30:14:INFO: {'loss': 17.513956909179687, 'learning_rate': 9.993384447494693e-06, 'epoch': 0, 'step': 500}
2024-08-06 10:30:53:INFO: {'loss': 26.506810302734376, 'learning_rate': 9.988429858414358e-06, 'epoch': 0, 'step': 600}
2024-08-06 10:31:34:INFO: {'loss': 19.87498229980469, 'learning_rate': 9.982101377887845e-06, 'epoch': 0, 'step': 700}
2024-08-06 10:32:15:INFO: {'loss': 25.644281005859376, 'learning_rate': 9.974400748877469e-06, 'epoch': 0, 'step': 800}
2024-08-06 10:32:55:INFO: {'loss': 17.367296752929686, 'learning_rate': 9.96533009225666e-06, 'epoch': 0, 'step': 900}
2024-08-06 10:33:18:INFO: ***** Running Dev *****
2024-08-06 10:33:18:INFO:   Num examples = 463
2024-08-06 10:33:18:INFO:   Batch size = 16
2024-08-06 10:33:23:INFO: {'acc': 0.9719222462203023, 'p': 0.920881971465629, 'r': 0.948563794255177, 'f1': 0.9345179335307666, 'epoch': 0, 'step': 956}
2024-08-06 10:33:23:INFO: ***** Running Test *****
2024-08-06 10:33:23:INFO:   Num examples = 477
2024-08-06 10:33:23:INFO:   Batch size = 16
2024-08-06 10:33:28:INFO: {'acc': 0.9682781456953642, 'p': 0.909952606635071, 'r': 0.9423312883435583, 'f1': 0.9258589511754068, 'epoch': 0, 'step': 956}
2024-08-06 10:33:46:INFO: {'loss': 17.54286315917969, 'learning_rate': 9.954891906225833e-06, 'epoch': 1, 'step': 1000}
2024-08-06 10:34:27:INFO: {'loss': 14.193528442382812, 'learning_rate': 9.943089065624343e-06, 'epoch': 1, 'step': 1100}
2024-08-06 10:35:10:INFO: {'loss': 18.38036865234375, 'learning_rate': 9.929924821138723e-06, 'epoch': 1, 'step': 1200}
2024-08-06 10:35:50:INFO: {'loss': 19.430560302734374, 'learning_rate': 9.915402798407383e-06, 'epoch': 1, 'step': 1300}
2024-08-06 10:36:31:INFO: {'loss': 18.602276611328126, 'learning_rate': 9.899526997022054e-06, 'epoch': 1, 'step': 1400}
2024-08-06 10:37:12:INFO: {'loss': 12.13679443359375, 'learning_rate': 9.882301789426234e-06, 'epoch': 1, 'step': 1500}
2024-08-06 10:37:53:INFO: {'loss': 19.38635437011719, 'learning_rate': 9.863731919710964e-06, 'epoch': 1, 'step': 1600}
2024-08-06 10:38:34:INFO: {'loss': 13.406412353515625, 'learning_rate': 9.843822502308213e-06, 'epoch': 1, 'step': 1700}
2024-08-06 10:39:14:INFO: {'loss': 16.287415771484376, 'learning_rate': 9.822579020582297e-06, 'epoch': 1, 'step': 1800}
2024-08-06 10:39:55:INFO: {'loss': 17.46229797363281, 'learning_rate': 9.800007325319666e-06, 'epoch': 1, 'step': 1900}
2024-08-06 10:40:00:INFO: ***** Running Dev *****
2024-08-06 10:40:00:INFO:   Num examples = 463
2024-08-06 10:40:00:INFO:   Batch size = 16
2024-08-06 10:40:05:INFO: {'acc': 0.9781857451403888, 'p': 0.9430628272251309, 'r': 0.9625918503674015, 'f1': 0.9527272727272726, 'epoch': 1, 'step': 1912}
2024-08-06 10:40:05:INFO: ***** Running Test *****
2024-08-06 10:40:05:INFO:   Num examples = 477
2024-08-06 10:40:05:INFO:   Batch size = 16
2024-08-06 10:40:10:INFO: {'acc': 0.9705298013245033, 'p': 0.9354066985645934, 'r': 0.9595092024539877, 'f1': 0.9473046638400968, 'epoch': 1, 'step': 1912}
2024-08-06 10:40:46:INFO: {'loss': 14.288929443359375, 'learning_rate': 9.776113633117514e-06, 'epoch': 2, 'step': 2000}
2024-08-06 10:41:26:INFO: {'loss': 8.543142700195313, 'learning_rate': 9.750904524671623e-06, 'epoch': 2, 'step': 2100}
2024-08-06 10:42:06:INFO: {'loss': 15.785248413085938, 'learning_rate': 9.72438694296394e-06, 'epoch': 2, 'step': 2200}
2024-08-06 10:42:46:INFO: {'loss': 9.2848046875, 'learning_rate': 9.696568191350373e-06, 'epoch': 2, 'step': 2300}
2024-08-06 10:43:25:INFO: {'loss': 8.689542846679688, 'learning_rate': 9.667455931549336e-06, 'epoch': 2, 'step': 2400}
2024-08-06 10:44:05:INFO: {'loss': 12.82364990234375, 'learning_rate': 9.637058181531583e-06, 'epoch': 2, 'step': 2500}
2024-08-06 10:44:45:INFO: {'loss': 9.155238037109376, 'learning_rate': 9.605383313311937e-06, 'epoch': 2, 'step': 2600}
2024-08-06 10:45:24:INFO: {'loss': 13.081197509765625, 'learning_rate': 9.572440050643515e-06, 'epoch': 2, 'step': 2700}
2024-08-06 10:46:04:INFO: {'loss': 19.905094604492188, 'learning_rate': 9.538237466615057e-06, 'epoch': 2, 'step': 2800}
2024-08-06 10:46:31:INFO: ***** Running Dev *****
2024-08-06 10:46:31:INFO:   Num examples = 463
2024-08-06 10:46:31:INFO:   Batch size = 16
2024-08-06 10:46:36:INFO: {'acc': 0.9792656587473002, 'p': 0.9344581440622972, 'r': 0.9619238476953907, 'f1': 0.9479921000658329, 'epoch': 2, 'step': 2868}
2024-08-06 10:46:36:INFO: ***** Running Test *****
2024-08-06 10:46:36:INFO:   Num examples = 477
2024-08-06 10:46:36:INFO:   Batch size = 16
2024-08-06 10:46:41:INFO: {'acc': 0.9685430463576159, 'p': 0.9331742243436754, 'r': 0.9595092024539877, 'f1': 0.9461584996975196, 'epoch': 2, 'step': 2868}
2024-08-06 10:46:54:INFO: {'loss': 10.900408325195313, 'learning_rate': 9.502784981152066e-06, 'epoch': 3, 'step': 2900}
2024-08-06 10:47:34:INFO: {'loss': 9.6018359375, 'learning_rate': 9.466092358422405e-06, 'epoch': 3, 'step': 3000}
2024-08-06 10:48:14:INFO: {'loss': 9.2450048828125, 'learning_rate': 9.4281697041471e-06, 'epoch': 3, 'step': 3100}
2024-08-06 10:48:54:INFO: {'loss': 8.8055419921875, 'learning_rate': 9.389027462817066e-06, 'epoch': 3, 'step': 3200}
2024-08-06 10:49:34:INFO: {'loss': 8.810593872070312, 'learning_rate': 9.348676414816526e-06, 'epoch': 3, 'step': 3300}
2024-08-06 10:50:13:INFO: {'loss': 7.54633544921875, 'learning_rate': 9.307127673453928e-06, 'epoch': 3, 'step': 3400}
2024-08-06 10:50:53:INFO: {'loss': 8.421952514648437, 'learning_rate': 9.264392681901166e-06, 'epoch': 3, 'step': 3500}
2024-08-06 10:51:33:INFO: {'loss': 6.357489013671875, 'learning_rate': 9.220483210041958e-06, 'epoch': 3, 'step': 3600}
2024-08-06 10:52:13:INFO: {'loss': 10.6265576171875, 'learning_rate': 9.175411351230221e-06, 'epoch': 3, 'step': 3700}
2024-08-06 10:52:52:INFO: {'loss': 9.523660278320312, 'learning_rate': 9.129189518959393e-06, 'epoch': 3, 'step': 3800}
2024-08-06 10:53:02:INFO: ***** Running Dev *****
2024-08-06 10:53:02:INFO:   Num examples = 463
2024-08-06 10:53:02:INFO:   Batch size = 16
2024-08-06 10:53:07:INFO: {'acc': 0.9783297336213103, 'p': 0.9444444444444444, 'r': 0.9652638610554443, 'f1': 0.9547406673273869, 'epoch': 3, 'step': 3824}
2024-08-06 10:53:07:INFO: ***** Running Test *****
2024-08-06 10:53:07:INFO:   Num examples = 477
2024-08-06 10:53:07:INFO:   Batch size = 16
2024-08-06 10:53:12:INFO: {'acc': 0.9692715231788079, 'p': 0.9360430364614465, 'r': 0.9607361963190184, 'f1': 0.9482288828337874, 'epoch': 3, 'step': 3824}
2024-08-06 10:53:42:INFO: {'loss': 3.03656982421875, 'learning_rate': 9.081830443443542e-06, 'epoch': 4, 'step': 3900}
2024-08-06 10:54:22:INFO: {'loss': 9.894580078125, 'learning_rate': 9.033347168111282e-06, 'epoch': 4, 'step': 4000}
2024-08-06 10:55:02:INFO: {'loss': 10.859637451171874, 'learning_rate': 8.983753046013403e-06, 'epoch': 4, 'step': 4100}
2024-08-06 10:55:41:INFO: {'loss': 5.805642700195312, 'learning_rate': 8.933061736145236e-06, 'epoch': 4, 'step': 4200}
2024-08-06 10:56:21:INFO: {'loss': 8.302628784179687, 'learning_rate': 8.881287199684743e-06, 'epoch': 4, 'step': 4300}
2024-08-06 10:57:01:INFO: {'loss': 6.951856079101563, 'learning_rate': 8.828443696147403e-06, 'epoch': 4, 'step': 4400}
2024-08-06 10:57:40:INFO: {'loss': 8.774332275390625, 'learning_rate': 8.774545779458912e-06, 'epoch': 4, 'step': 4500}
2024-08-06 10:58:20:INFO: {'loss': 8.830678100585937, 'learning_rate': 8.719608293946801e-06, 'epoch': 4, 'step': 4600}
2024-08-06 10:59:00:INFO: {'loss': 6.716248168945312, 'learning_rate': 8.663646370252093e-06, 'epoch': 4, 'step': 4700}
2024-08-06 10:59:31:INFO: ***** Running Dev *****
2024-08-06 10:59:31:INFO:   Num examples = 463
2024-08-06 10:59:31:INFO:   Batch size = 16
2024-08-06 10:59:36:INFO: {'acc': 0.9772498200143989, 'p': 0.9459815546772069, 'r': 0.9592518370073481, 'f1': 0.9525704809286899, 'epoch': 4, 'step': 4780}
2024-08-06 10:59:36:INFO: ***** Running Test *****
2024-08-06 10:59:36:INFO:   Num examples = 477
2024-08-06 10:59:36:INFO:   Batch size = 16
2024-08-06 10:59:42:INFO: {'acc': 0.9672847682119206, 'p': 0.9427365883062085, 'r': 0.9595092024539877, 'f1': 0.9510489510489512, 'epoch': 4, 'step': 4780}
2024-08-06 10:59:50:INFO: {'loss': 5.281831359863281, 'learning_rate': 8.606675421162064e-06, 'epoch': 5, 'step': 4800}
2024-08-06 11:00:29:INFO: {'loss': 5.0264794921875, 'learning_rate': 8.54871113736534e-06, 'epoch': 5, 'step': 4900}
2024-08-06 11:01:09:INFO: {'loss': 3.3879449462890623, 'learning_rate': 8.48976948313043e-06, 'epoch': 5, 'step': 5000}
2024-08-06 11:01:49:INFO: {'loss': 4.713350219726562, 'learning_rate': 8.429866691908916e-06, 'epoch': 5, 'step': 5100}
2024-08-06 11:02:28:INFO: {'loss': 1.6812078857421875, 'learning_rate': 8.369019261864506e-06, 'epoch': 5, 'step': 5200}
2024-08-06 11:03:08:INFO: {'loss': 4.323922729492187, 'learning_rate': 8.30724395132919e-06, 'epoch': 5, 'step': 5300}
2024-08-06 11:03:48:INFO: {'loss': 4.676889038085937, 'learning_rate': 8.24455777418772e-06, 'epoch': 5, 'step': 5400}
2024-08-06 11:04:28:INFO: {'loss': 9.490146484375, 'learning_rate': 8.18097799519174e-06, 'epoch': 5, 'step': 5500}
2024-08-06 11:05:08:INFO: {'loss': 6.62328857421875, 'learning_rate': 8.116522125204783e-06, 'epoch': 5, 'step': 5600}
2024-08-06 11:05:48:INFO: {'loss': 10.223032836914063, 'learning_rate': 8.05120791637952e-06, 'epoch': 5, 'step': 5700}
2024-08-06 11:06:02:INFO: ***** Running Dev *****
2024-08-06 11:06:02:INFO:   Num examples = 463
2024-08-06 11:06:02:INFO:   Batch size = 16
2024-08-06 11:06:07:INFO: {'acc': 0.9769618430525558, 'p': 0.9459459459459459, 'r': 0.9585838343353373, 'f1': 0.9522229595222296, 'epoch': 5, 'step': 5736}
2024-08-06 11:06:07:INFO: ***** Running Test *****
2024-08-06 11:06:07:INFO:   Num examples = 477
2024-08-06 11:06:07:INFO:   Batch size = 16
2024-08-06 11:06:12:INFO: {'acc': 0.9701324503311258, 'p': 0.9393393393393393, 'r': 0.9595092024539877, 'f1': 0.9493171471927162, 'epoch': 5, 'step': 5736}
2024-08-06 11:06:38:INFO: {'loss': 2.147505798339844, 'learning_rate': 7.985053357268533e-06, 'epoch': 6, 'step': 5800}
2024-08-06 11:07:17:INFO: {'loss': 3.874658203125, 'learning_rate': 7.918076667869996e-06, 'epoch': 6, 'step': 5900}
2024-08-06 11:07:57:INFO: {'loss': 3.0557452392578126, 'learning_rate': 7.850296294609586e-06, 'epoch': 6, 'step': 6000}
2024-08-06 11:08:37:INFO: {'loss': 3.1371466064453126, 'learning_rate': 7.78173090526007e-06, 'epoch': 6, 'step': 6100}
2024-08-06 11:09:16:INFO: {'loss': 5.702694702148437, 'learning_rate': 7.712399383799896e-06, 'epoch': 6, 'step': 6200}
2024-08-06 11:09:56:INFO: {'loss': 0.6065350341796875, 'learning_rate': 7.642320825212248e-06, 'epoch': 6, 'step': 6300}
2024-08-06 11:10:36:INFO: {'loss': 2.32807861328125, 'learning_rate': 7.571514530226004e-06, 'epoch': 6, 'step': 6400}
2024-08-06 11:11:15:INFO: {'loss': 5.03729736328125, 'learning_rate': 7.500000000000001e-06, 'epoch': 6, 'step': 6500}
2024-08-06 11:11:55:INFO: {'loss': 4.925645141601563, 'learning_rate': 7.4277969307521135e-06, 'epoch': 6, 'step': 6600}
2024-08-06 11:12:31:INFO: ***** Running Dev *****
2024-08-06 11:12:31:INFO:   Num examples = 463
2024-08-06 11:12:31:INFO:   Batch size = 16
2024-08-06 11:12:36:INFO: {'acc': 0.9777537796976242, 'p': 0.9423706614276359, 'r': 0.9612558450233801, 'f1': 0.9517195767195769, 'epoch': 6, 'step': 6692}
2024-08-06 11:12:36:INFO: ***** Running Test *****
2024-08-06 11:12:36:INFO:   Num examples = 477
2024-08-06 11:12:36:INFO:   Batch size = 16
2024-08-06 11:12:42:INFO: {'acc': 0.9689403973509934, 'p': 0.9371633752244165, 'r': 0.9607361963190184, 'f1': 0.9488033929112389, 'epoch': 6, 'step': 6692}
2024-08-06 11:12:45:INFO: {'loss': 5.637244873046875, 'learning_rate': 7.354925208334615e-06, 'epoch': 7, 'step': 6700}
2024-08-06 11:13:25:INFO: {'loss': 2.9239434814453125, 'learning_rate': 7.2814049027572945e-06, 'epoch': 7, 'step': 6800}
2024-08-06 11:14:04:INFO: {'loss': 0.8783758544921875, 'learning_rate': 7.207256262659868e-06, 'epoch': 7, 'step': 6900}
2024-08-06 11:14:44:INFO: {'loss': 2.685772705078125, 'learning_rate': 7.132499709735187e-06, 'epoch': 7, 'step': 7000}
2024-08-06 11:15:24:INFO: {'loss': 0.27340087890625, 'learning_rate': 7.057155833104783e-06, 'epoch': 7, 'step': 7100}
2024-08-06 11:16:04:INFO: {'loss': 7.27263916015625, 'learning_rate': 6.981245383648304e-06, 'epoch': 7, 'step': 7200}
2024-08-06 11:16:43:INFO: {'loss': 2.7973284912109375, 'learning_rate': 6.904789268288399e-06, 'epoch': 7, 'step': 7300}
2024-08-06 11:17:23:INFO: {'loss': 1.25447265625, 'learning_rate': 6.82780854423262e-06, 'epoch': 7, 'step': 7400}
2024-08-06 11:18:03:INFO: {'loss': 1.8961456298828125, 'learning_rate': 6.750324413173948e-06, 'epoch': 7, 'step': 7500}
2024-08-06 11:18:42:INFO: {'loss': 3.4379766845703124, 'learning_rate': 6.672358215451506e-06, 'epoch': 7, 'step': 7600}
2024-08-06 11:19:02:INFO: ***** Running Dev *****
2024-08-06 11:19:02:INFO:   Num examples = 463
2024-08-06 11:19:02:INFO:   Batch size = 16
2024-08-06 11:19:07:INFO: {'acc': 0.9753059755219582, 'p': 0.9448094612352168, 'r': 0.9605878423513694, 'f1': 0.9526333222921497, 'epoch': 7, 'step': 7648}
2024-08-06 11:19:07:INFO: ***** Running Test *****
2024-08-06 11:19:07:INFO:   Num examples = 477
2024-08-06 11:19:07:INFO:   Batch size = 16
2024-08-06 11:19:12:INFO: {'acc': 0.9704635761589404, 'p': 0.9281472684085511, 'r': 0.9588957055214724, 'f1': 0.9432709716354859, 'epoch': 7, 'step': 7648}
2024-08-06 11:19:32:INFO: {'loss': 1.5566799926757813, 'learning_rate': 6.593931424173102e-06, 'epoch': 8, 'step': 7700}
2024-08-06 11:20:12:INFO: {'loss': 0.962474365234375, 'learning_rate': 6.515065639301199e-06, 'epoch': 8, 'step': 7800}
2024-08-06 11:20:52:INFO: {'loss': 2.5871356201171873, 'learning_rate': 6.435782581703944e-06, 'epoch': 8, 'step': 7900}
2024-08-06 11:21:31:INFO: {'loss': 1.506844482421875, 'learning_rate': 6.356104087172916e-06, 'epoch': 8, 'step': 8000}
2024-08-06 11:22:11:INFO: {'loss': 1.7183447265625, 'learning_rate': 6.276052100409185e-06, 'epoch': 8, 'step': 8100}
2024-08-06 11:22:51:INFO: {'loss': 2.37535400390625, 'learning_rate': 6.195648668979417e-06, 'epoch': 8, 'step': 8200}
2024-08-06 11:23:31:INFO: {'loss': 0.974237060546875, 'learning_rate': 6.11491593724363e-06, 'epoch': 8, 'step': 8300}
2024-08-06 11:24:11:INFO: {'loss': 3.036748046875, 'learning_rate': 6.033876140256276e-06, 'epoch': 8, 'step': 8400}
2024-08-06 11:24:51:INFO: {'loss': 3.032286376953125, 'learning_rate': 5.952551597642377e-06, 'epoch': 8, 'step': 8500}
2024-08-06 11:25:30:INFO: {'loss': 1.8041937255859375, 'learning_rate': 5.870964707450348e-06, 'epoch': 8, 'step': 8600}
2024-08-06 11:25:32:INFO: ***** Running Dev *****
2024-08-06 11:25:32:INFO:   Num examples = 463
2024-08-06 11:25:32:INFO:   Batch size = 16
2024-08-06 11:25:37:INFO: {'acc': 0.9784737221022318, 'p': 0.9417539267015707, 'r': 0.9612558450233801, 'f1': 0.951404958677686, 'epoch': 8, 'step': 8604}
2024-08-06 11:25:37:INFO: ***** Running Test *****
2024-08-06 11:25:37:INFO:   Num examples = 477
2024-08-06 11:25:37:INFO:   Batch size = 16
2024-08-06 11:25:42:INFO: {'acc': 0.9702649006622517, 'p': 0.9468919734459867, 'r': 0.9625766871165644, 'f1': 0.9546699117736538, 'epoch': 8, 'step': 8604}
2024-08-06 11:26:20:INFO: {'loss': 2.357976989746094, 'learning_rate': 5.789137939983211e-06, 'epoch': 9, 'step': 8700}
2024-08-06 11:27:00:INFO: {'loss': 1.10883544921875, 'learning_rate': 5.707093831609945e-06, 'epoch': 9, 'step': 8800}
2024-08-06 11:27:40:INFO: {'loss': 0.9677862548828124, 'learning_rate': 5.6248549785586005e-06, 'epoch': 9, 'step': 8900}
2024-08-06 11:28:20:INFO: {'loss': 0.4458245849609375, 'learning_rate': 5.542444030692954e-06, 'epoch': 9, 'step': 9000}
2024-08-06 11:29:00:INFO: {'loss': 1.5818017578125, 'learning_rate': 5.459883685274378e-06, 'epoch': 9, 'step': 9100}
2024-08-06 11:29:39:INFO: {'loss': 0.3011279296875, 'learning_rate': 5.377196680710668e-06, 'epoch': 9, 'step': 9200}
2024-08-06 11:30:19:INFO: {'loss': 3.1030859375, 'learning_rate': 5.2944057902935195e-06, 'epoch': 9, 'step': 9300}
2024-08-06 11:30:59:INFO: {'loss': 1.1187841796875, 'learning_rate': 5.211533815926417e-06, 'epoch': 9, 'step': 9400}
2024-08-06 11:31:38:INFO: {'loss': 1.0476068115234376, 'learning_rate': 5.12860358184463e-06, 'epoch': 9, 'step': 9500}
2024-08-06 11:32:02:INFO: ***** Running Dev *****
2024-08-06 11:32:02:INFO:   Num examples = 463
2024-08-06 11:32:02:INFO:   Batch size = 16
2024-08-06 11:32:07:INFO: {'acc': 0.9763858891288697, 'p': 0.9468154957321077, 'r': 0.9632598530394122, 'f1': 0.9549668874172186, 'epoch': 9, 'step': 9560}
2024-08-06 11:32:07:INFO: ***** Running Test *****
2024-08-06 11:32:07:INFO:   Num examples = 477
2024-08-06 11:32:07:INFO:   Batch size = 16
2024-08-06 11:32:13:INFO: {'acc': 0.9703311258278146, 'p': 0.9417767106842737, 'r': 0.9625766871165644, 'f1': 0.9520631067961166, 'epoch': 9, 'step': 9560}
2024-08-06 11:32:29:INFO: {'loss': 1.4057183837890626, 'learning_rate': 5.04563792832906e-06, 'epoch': 10, 'step': 9600}
2024-08-06 11:33:08:INFO: {'loss': 1.645728759765625, 'learning_rate': 4.962659705415677e-06, 'epoch': 10, 'step': 9700}
2024-08-06 11:33:48:INFO: {'loss': 9.94873046875e-05, 'learning_rate': 4.879691766602261e-06, 'epoch': 10, 'step': 9800}
2024-08-06 11:34:28:INFO: {'loss': 0.206204833984375, 'learning_rate': 4.79675696255418e-06, 'epoch': 10, 'step': 9900}
2024-08-06 11:35:08:INFO: {'loss': 0.9726776123046875, 'learning_rate': 4.7138781348109845e-06, 'epoch': 10, 'step': 10000}
2024-08-06 11:35:47:INFO: {'loss': 0.987147216796875, 'learning_rate': 4.631078109495468e-06, 'epoch': 10, 'step': 10100}
2024-08-06 11:36:27:INFO: {'loss': 1.54343505859375, 'learning_rate': 4.548379691027005e-06, 'epoch': 10, 'step': 10200}
2024-08-06 11:37:07:INFO: {'loss': 0.5425396728515625, 'learning_rate': 4.465805655840864e-06, 'epoch': 10, 'step': 10300}
2024-08-06 11:37:46:INFO: {'loss': 0.3921453857421875, 'learning_rate': 4.383378746115215e-06, 'epoch': 10, 'step': 10400}
2024-08-06 11:38:26:INFO: {'loss': 0.80512451171875, 'learning_rate': 4.301121663507571e-06, 'epoch': 10, 'step': 10500}
2024-08-06 11:38:32:INFO: ***** Running Dev *****
2024-08-06 11:38:32:INFO:   Num examples = 463
2024-08-06 11:38:32:INFO:   Batch size = 16
2024-08-06 11:38:38:INFO: {'acc': 0.9781857451403888, 'p': 0.9444081098757358, 'r': 0.9645958583834335, 'f1': 0.9543952412425644, 'epoch': 10, 'step': 10516}
2024-08-06 11:38:38:INFO: ***** Running Test *****
2024-08-06 11:38:38:INFO:   Num examples = 477
2024-08-06 11:38:38:INFO:   Batch size = 16
2024-08-06 11:38:43:INFO: {'acc': 0.9711258278145696, 'p': 0.93937575030012, 'r': 0.9601226993865031, 'f1': 0.9496359223300971, 'epoch': 10, 'step': 10516}
2024-08-06 11:39:16:INFO: {'loss': 0.00897216796875, 'learning_rate': 4.219057062902417e-06, 'epoch': 11, 'step': 10600}
2024-08-06 11:39:57:INFO: {'loss': 0.22897705078125, 'learning_rate': 4.1372075461716885e-06, 'epoch': 11, 'step': 10700}
2024-08-06 11:40:36:INFO: {'loss': 1.3792901611328126, 'learning_rate': 4.055595655949856e-06, 'epoch': 11, 'step': 10800}
2024-08-06 11:41:16:INFO: {'loss': 0.4466033935546875, 'learning_rate': 3.974243869425348e-06, 'epoch': 11, 'step': 10900}
2024-08-06 11:41:56:INFO: {'loss': 0.1544903564453125, 'learning_rate': 3.893174592149976e-06, 'epoch': 11, 'step': 11000}
2024-08-06 11:42:35:INFO: {'loss': 0.2207012939453125, 'learning_rate': 3.812410151868092e-06, 'epoch': 11, 'step': 11100}
2024-08-06 11:43:15:INFO: {'loss': 0.093114013671875, 'learning_rate': 3.731972792367179e-06, 'epoch': 11, 'step': 11200}
2024-08-06 11:43:55:INFO: {'loss': 0.111007080078125, 'learning_rate': 3.6518846673515717e-06, 'epoch': 11, 'step': 11300}
2024-08-06 11:44:35:INFO: {'loss': 4.744776000976563, 'learning_rate': 3.572167834340977e-06, 'epoch': 11, 'step': 11400}
2024-08-06 11:45:03:INFO: ***** Running Dev *****
2024-08-06 11:45:03:INFO:   Num examples = 463
2024-08-06 11:45:03:INFO:   Batch size = 16
2024-08-06 11:45:08:INFO: {'acc': 0.9751619870410367, 'p': 0.9386022207707381, 'r': 0.9599198396793587, 'f1': 0.9491413474240422, 'epoch': 11, 'step': 11472}
2024-08-06 11:45:08:INFO: ***** Running Test *****
2024-08-06 11:45:08:INFO:   Num examples = 477
2024-08-06 11:45:08:INFO:   Batch size = 16
2024-08-06 11:45:14:INFO: {'acc': 0.9705960264900663, 'p': 0.9330543933054394, 'r': 0.9576687116564417, 'f1': 0.945201332122313, 'epoch': 11, 'step': 11472}
2024-08-06 11:45:25:INFO: {'loss': 1.7147467041015625, 'learning_rate': 3.4928442485954826e-06, 'epoch': 12, 'step': 11500}
2024-08-06 11:46:04:INFO: {'loss': 0.2382244873046875, 'learning_rate': 3.413935757068748e-06, 'epoch': 12, 'step': 11600}
2024-08-06 11:46:44:INFO: {'loss': 0.4534271240234375, 'learning_rate': 3.335464092391003e-06, 'epoch': 12, 'step': 11700}
2024-08-06 11:47:24:INFO: {'loss': 0.1474859619140625, 'learning_rate': 3.2574508668835426e-06, 'epoch': 12, 'step': 11800}
2024-08-06 11:48:04:INFO: {'loss': 0.1045166015625, 'learning_rate': 3.1799175666063615e-06, 'epoch': 12, 'step': 11900}
2024-08-06 11:48:44:INFO: {'loss': 0.40300537109375, 'learning_rate': 3.102885545440556e-06, 'epoch': 12, 'step': 12000}
2024-08-06 11:49:24:INFO: {'loss': 0.5827734375, 'learning_rate': 3.026376019207126e-06, 'epoch': 12, 'step': 12100}
2024-08-06 11:50:03:INFO: {'loss': 1.090048828125, 'learning_rate': 2.950410059823816e-06, 'epoch': 12, 'step': 12200}
2024-08-06 11:50:43:INFO: {'loss': 0.0710516357421875, 'learning_rate': 2.8750085895015758e-06, 'epoch': 12, 'step': 12300}
2024-08-06 11:51:23:INFO: {'loss': 1.7521759033203126, 'learning_rate': 2.8001923749822524e-06, 'epoch': 12, 'step': 12400}
2024-08-06 11:51:34:INFO: ***** Running Dev *****
2024-08-06 11:51:34:INFO:   Num examples = 463
2024-08-06 11:51:34:INFO:   Batch size = 16
2024-08-06 11:51:39:INFO: {'acc': 0.9765298776097913, 'p': 0.939374185136897, 'r': 0.9625918503674015, 'f1': 0.9508413064995052, 'epoch': 12, 'step': 12428}
2024-08-06 11:51:39:INFO: ***** Running Test *****
2024-08-06 11:51:39:INFO:   Num examples = 477
2024-08-06 11:51:39:INFO:   Batch size = 16
2024-08-06 11:51:44:INFO: {'acc': 0.970794701986755, 'p': 0.9355223880597014, 'r': 0.9613496932515337, 'f1': 0.9482602118003026, 'epoch': 12, 'step': 12428}
2024-08-06 11:52:13:INFO: {'loss': 0.27930419921875, 'learning_rate': 2.7259820218191123e-06, 'epoch': 13, 'step': 12500}
2024-08-06 11:52:53:INFO: {'loss': 1.031898193359375, 'learning_rate': 2.6523979687017516e-06, 'epoch': 13, 'step': 12600}
2024-08-06 11:53:33:INFO: {'loss': 2.3439910888671873, 'learning_rate': 2.579460481826947e-06, 'epoch': 13, 'step': 12700}
2024-08-06 11:54:13:INFO: {'loss': 0.654649658203125, 'learning_rate': 2.5071896493170533e-06, 'epoch': 13, 'step': 12800}
2024-08-06 11:54:53:INFO: {'loss': 0.1596142578125, 'learning_rate': 2.4356053756873987e-06, 'epoch': 13, 'step': 12900}
2024-08-06 11:55:32:INFO: {'loss': 0.3729669189453125, 'learning_rate': 2.3647273763642853e-06, 'epoch': 13, 'step': 13000}
2024-08-06 11:56:12:INFO: {'loss': 0.4892779541015625, 'learning_rate': 2.2945751722550384e-06, 'epoch': 13, 'step': 13100}
2024-08-06 11:56:52:INFO: {'loss': 0.226661376953125, 'learning_rate': 2.2251680843716617e-06, 'epoch': 13, 'step': 13200}
2024-08-06 11:57:32:INFO: {'loss': 0.36580078125, 'learning_rate': 2.1565252285095158e-06, 'epoch': 13, 'step': 13300}
2024-08-06 11:58:05:INFO: ***** Running Dev *****
2024-08-06 11:58:05:INFO:   Num examples = 463
2024-08-06 11:58:05:INFO:   Batch size = 16
2024-08-06 11:58:10:INFO: {'acc': 0.9768898488120951, 'p': 0.9394136807817589, 'r': 0.9632598530394122, 'f1': 0.9511873350923482, 'epoch': 13, 'step': 13384}
2024-08-06 11:58:10:INFO: ***** Running Test *****
2024-08-06 11:58:10:INFO:   Num examples = 477
2024-08-06 11:58:10:INFO:   Batch size = 16
2024-08-06 11:58:15:INFO: {'acc': 0.9717218543046358, 'p': 0.9406474820143885, 'r': 0.9625766871165644, 'f1': 0.9514857489387507, 'epoch': 13, 'step': 13384}
2024-08-06 11:58:22:INFO: {'loss': 9.979248046875e-05, 'learning_rate': 2.088665509982534e-06, 'epoch': 14, 'step': 13400}
2024-08-06 11:59:02:INFO: {'loss': 0.8223394775390624, 'learning_rate': 2.0216076184164045e-06, 'epoch': 14, 'step': 13500}
2024-08-06 11:59:41:INFO: {'loss': 0.8223046875, 'learning_rate': 1.955370022601157e-06, 'epoch': 14, 'step': 13600}
2024-08-06 12:00:21:INFO: {'loss': 0.4516461181640625, 'learning_rate': 1.8899709654045607e-06, 'epoch': 14, 'step': 13700}
2024-08-06 12:01:01:INFO: {'loss': 0.09237060546875, 'learning_rate': 1.8254284587477683e-06, 'epoch': 14, 'step': 13800}
2024-08-06 12:01:41:INFO: {'loss': 0.24996826171875, 'learning_rate': 1.7617602786445403e-06, 'epoch': 14, 'step': 13900}
2024-08-06 12:02:20:INFO: {'loss': 0.1499462890625, 'learning_rate': 1.698983960305458e-06, 'epoch': 14, 'step': 14000}
2024-08-06 12:03:00:INFO: {'loss': 0.2976171875, 'learning_rate': 1.637116793308453e-06, 'epoch': 14, 'step': 14100}
2024-08-06 12:03:40:INFO: {'loss': 0.0982489013671875, 'learning_rate': 1.5761758168369863e-06, 'epoch': 14, 'step': 14200}
2024-08-06 12:04:20:INFO: {'loss': 0.0001959228515625, 'learning_rate': 1.5161778149871874e-06, 'epoch': 14, 'step': 14300}
2024-08-06 12:04:35:INFO: ***** Running Dev *****
2024-08-06 12:04:35:INFO:   Num examples = 463
2024-08-06 12:04:35:INFO:   Batch size = 16
2024-08-06 12:04:41:INFO: {'acc': 0.9768898488120951, 'p': 0.9443352979698756, 'r': 0.9632598530394122, 'f1': 0.9537037037037036, 'epoch': 14, 'step': 14340}
2024-08-06 12:04:41:INFO: ***** Running Test *****
2024-08-06 12:04:41:INFO:   Num examples = 477
2024-08-06 12:04:41:INFO:   Batch size = 16
2024-08-06 12:04:46:INFO: {'acc': 0.9709271523178808, 'p': 0.9389221556886228, 'r': 0.9619631901840491, 'f1': 0.9503030303030302, 'epoch': 14, 'step': 14340}
2024-08-06 12:05:10:INFO: {'loss': 0.32029266357421876, 'learning_rate': 1.457139312145262e-06, 'epoch': 15, 'step': 14400}
2024-08-06 12:05:49:INFO: {'loss': 0.2424517822265625, 'learning_rate': 1.39907656843641e-06, 'epoch': 15, 'step': 14500}
2024-08-06 12:06:29:INFO: {'loss': 0.3873046875, 'learning_rate': 1.3420055752465362e-06, 'epoch': 15, 'step': 14600}
2024-08-06 12:07:09:INFO: {'loss': 0.0703887939453125, 'learning_rate': 1.285942050817971e-06, 'epoch': 15, 'step': 14700}
2024-08-06 12:07:49:INFO: {'loss': 0.1580047607421875, 'learning_rate': 1.2309014359204251e-06, 'epoch': 15, 'step': 14800}
2024-08-06 12:08:28:INFO: {'loss': 1.0103729248046875, 'learning_rate': 1.1768988895983574e-06, 'epoch': 15, 'step': 14900}
2024-08-06 12:09:08:INFO: {'loss': 2.44140625e-05, 'learning_rate': 1.123949284995935e-06, 'epoch': 15, 'step': 15000}
2024-08-06 12:09:48:INFO: {'loss': 0.0208538818359375, 'learning_rate': 1.0720672052607417e-06, 'epoch': 15, 'step': 15100}
2024-08-06 12:10:28:INFO: {'loss': 0.97915283203125, 'learning_rate': 1.021266939527356e-06, 'epoch': 15, 'step': 15200}
2024-08-06 12:11:06:INFO: ***** Running Dev *****
2024-08-06 12:11:06:INFO:   Num examples = 463
2024-08-06 12:11:06:INFO:   Batch size = 16
2024-08-06 12:11:11:INFO: {'acc': 0.9768898488120951, 'p': 0.9424460431654677, 'r': 0.9625918503674015, 'f1': 0.9524124256444151, 'epoch': 15, 'step': 15296}
2024-08-06 12:11:11:INFO: ***** Running Test *****
2024-08-06 12:11:11:INFO:   Num examples = 477
2024-08-06 12:11:11:INFO:   Batch size = 16
2024-08-06 12:11:16:INFO: {'acc': 0.9708609271523179, 'p': 0.9423423423423424, 'r': 0.9625766871165644, 'f1': 0.9523520485584218, 'epoch': 15, 'step': 15296}
2024-08-06 12:11:18:INFO: {'loss': 0.3989909362792969, 'learning_rate': 9.71562478981886e-07, 'epoch': 16, 'step': 15300}
2024-08-06 12:11:58:INFO: {'loss': 0.69438232421875, 'learning_rate': 9.229675130085919e-07, 'epoch': 16, 'step': 15400}
2024-08-06 12:12:37:INFO: {'loss': 0.05863037109375, 'learning_rate': 8.754954254196096e-07, 'epoch': 16, 'step': 15500}
2024-08-06 12:13:17:INFO: {'loss': 0.3456414794921875, 'learning_rate': 8.2915929076884e-07, 'epoch': 16, 'step': 15600}
2024-08-06 12:13:57:INFO: {'loss': 0.1075750732421875, 'learning_rate': 7.839718707510153e-07, 'epoch': 16, 'step': 15700}
2024-08-06 12:14:37:INFO: {'loss': 4.57763671875e-05, 'learning_rate': 7.399456106869296e-07, 'epoch': 16, 'step': 15800}
2024-08-06 12:15:17:INFO: {'loss': 0.01139404296875, 'learning_rate': 6.97092636095798e-07, 'epoch': 16, 'step': 15900}
2024-08-06 12:15:56:INFO: {'loss': 0.2247418212890625, 'learning_rate': 6.554247493557048e-07, 'epoch': 16, 'step': 16000}
2024-08-06 12:16:36:INFO: {'loss': 0.0998223876953125, 'learning_rate': 6.149534264530433e-07, 'epoch': 16, 'step': 16100}
2024-08-06 12:17:16:INFO: {'loss': 0.1913470458984375, 'learning_rate': 5.756898138218448e-07, 'epoch': 16, 'step': 16200}
2024-08-06 12:17:37:INFO: ***** Running Dev *****
2024-08-06 12:17:37:INFO:   Num examples = 463
2024-08-06 12:17:37:INFO:   Batch size = 16
2024-08-06 12:17:42:INFO: {'acc': 0.9768898488120951, 'p': 0.9456806282722513, 'r': 0.9652638610554443, 'f1': 0.9553719008264464, 'epoch': 16, 'step': 16252}
2024-08-06 12:17:42:INFO: ***** Running Test *****
2024-08-06 12:17:42:INFO:   Num examples = 477
2024-08-06 12:17:42:INFO:   Batch size = 16
2024-08-06 12:17:47:INFO: {'acc': 0.970728476821192, 'p': 0.9451807228915663, 'r': 0.9625766871165644, 'f1': 0.9537993920972645, 'epoch': 16, 'step': 16252}
2024-08-06 12:18:06:INFO: {'loss': 0.00469818115234375, 'learning_rate': 5.376447252738848e-07, 'epoch': 17, 'step': 16300}
2024-08-06 12:18:46:INFO: {'loss': 0.6961212158203125, 'learning_rate': 5.008286390203876e-07, 'epoch': 17, 'step': 16400}
2024-08-06 12:19:26:INFO: {'loss': 0.4378961181640625, 'learning_rate': 4.6525169478616073e-07, 'epoch': 17, 'step': 16500}
2024-08-06 12:20:06:INFO: {'loss': 0.0270465087890625, 'learning_rate': 4.309236910169562e-07, 'epoch': 17, 'step': 16600}
2024-08-06 12:20:45:INFO: {'loss': 0.09132080078125, 'learning_rate': 3.9785408218082964e-07, 'epoch': 17, 'step': 16700}
2024-08-06 12:21:25:INFO: {'loss': 1.52587890625e-05, 'learning_rate': 3.6605197616423116e-07, 'epoch': 17, 'step': 16800}
2024-08-06 12:22:05:INFO: {'loss': 0.0491839599609375, 'learning_rate': 3.355261317635472e-07, 'epoch': 17, 'step': 16900}
2024-08-06 12:22:45:INFO: {'loss': 0.143489990234375, 'learning_rate': 3.062849562727982e-07, 'epoch': 17, 'step': 17000}
2024-08-06 12:23:24:INFO: {'loss': 0.007593994140625, 'learning_rate': 2.7833650316813123e-07, 'epoch': 17, 'step': 17100}
2024-08-06 12:24:04:INFO: {'loss': 0.063814697265625, 'learning_rate': 2.51688469889772e-07, 'epoch': 17, 'step': 17200}
2024-08-06 12:24:07:INFO: ***** Running Dev *****
2024-08-06 12:24:07:INFO:   Num examples = 463
2024-08-06 12:24:07:INFO:   Batch size = 16
2024-08-06 12:24:12:INFO: {'acc': 0.9770338372930165, 'p': 0.9418680600914435, 'r': 0.9632598530394122, 'f1': 0.9524438573315721, 'epoch': 17, 'step': 17208}
2024-08-06 12:24:12:INFO: ***** Running Test *****
2024-08-06 12:24:12:INFO:   Num examples = 477
2024-08-06 12:24:12:INFO:   Batch size = 16
2024-08-06 12:24:18:INFO: {'acc': 0.9709271523178808, 'p': 0.9463208685162847, 'r': 0.9625766871165644, 'f1': 0.9543795620437956, 'epoch': 17, 'step': 17208}
2024-08-06 12:24:54:INFO: {'loss': 0.063199462890625, 'learning_rate': 2.263481957220276e-07, 'epoch': 18, 'step': 17300}
2024-08-06 12:25:34:INFO: {'loss': 2.0751953125e-05, 'learning_rate': 2.0232265977193465e-07, 'epoch': 18, 'step': 17400}
2024-08-06 12:26:14:INFO: {'loss': 2.3193359375e-05, 'learning_rate': 1.7961847904710173e-07, 'epoch': 18, 'step': 17500}
2024-08-06 12:26:54:INFO: {'loss': 7.38525390625e-05, 'learning_rate': 1.5824190663328521e-07, 'epoch': 18, 'step': 17600}
2024-08-06 12:27:33:INFO: {'loss': 0.250841064453125, 'learning_rate': 1.3819882997218981e-07, 'epoch': 18, 'step': 17700}
2024-08-06 12:28:13:INFO: {'loss': 0.001953125, 'learning_rate': 1.1949476923997394e-07, 'epoch': 18, 'step': 17800}
2024-08-06 12:28:53:INFO: {'loss': 0.080850830078125, 'learning_rate': 1.0213487582691139e-07, 'epoch': 18, 'step': 17900}
2024-08-06 12:29:32:INFO: {'loss': 0.8735003662109375, 'learning_rate': 8.612393091861349e-08, 'epoch': 18, 'step': 18000}
2024-08-06 12:30:12:INFO: {'loss': 0.065849609375, 'learning_rate': 7.146634417922016e-08, 'epoch': 18, 'step': 18100}
2024-08-06 12:30:38:INFO: ***** Running Dev *****
2024-08-06 12:30:38:INFO:   Num examples = 463
2024-08-06 12:30:38:INFO:   Batch size = 16
2024-08-06 12:30:43:INFO: {'acc': 0.9769618430525558, 'p': 0.9437540876389797, 'r': 0.9639278557114228, 'f1': 0.953734302709848, 'epoch': 18, 'step': 18164}
2024-08-06 12:30:43:INFO: ***** Running Test *****
2024-08-06 12:30:43:INFO:   Num examples = 477
2024-08-06 12:30:43:INFO:   Batch size = 16
2024-08-06 12:30:48:INFO: {'acc': 0.9711258278145696, 'p': 0.9463208685162847, 'r': 0.9625766871165644, 'f1': 0.9543795620437956, 'epoch': 18, 'step': 18164}
2024-08-06 12:31:02:INFO: {'loss': 0.6976716613769531, 'learning_rate': 5.816615253690539e-08, 'epoch': 19, 'step': 18200}
2024-08-06 12:31:42:INFO: {'loss': 0.0001165771484375, 'learning_rate': 4.622701907204652e-08, 'epoch': 19, 'step': 18300}
2024-08-06 12:32:22:INFO: {'loss': 0.040355224609375, 'learning_rate': 3.565223200835577e-08, 'epoch': 19, 'step': 18400}
2024-08-06 12:33:02:INFO: {'loss': 0.02341064453125, 'learning_rate': 2.644470380724906e-08, 'epoch': 19, 'step': 18500}
2024-08-06 12:33:41:INFO: {'loss': 2.13623046875e-05, 'learning_rate': 1.8606970365710465e-08, 'epoch': 19, 'step': 18600}
2024-08-06 12:34:21:INFO: {'loss': 0.0899169921875, 'learning_rate': 1.214119031786809e-08, 'epoch': 19, 'step': 18700}
2024-08-06 12:35:01:INFO: {'loss': 0.0557073974609375, 'learning_rate': 7.049144440469669e-09, 'epoch': 19, 'step': 18800}
2024-08-06 12:35:41:INFO: {'loss': 0.009761962890625, 'learning_rate': 3.332235162429864e-09, 'epoch': 19, 'step': 18900}
2024-08-06 12:36:21:INFO: {'loss': 0.0050335693359375, 'learning_rate': 9.914861785803587e-10, 'epoch': 19, 'step': 19000}
2024-08-06 12:37:00:INFO: {'loss': 0.07733642578125, 'learning_rate': 2.7542167727601098e-11, 'epoch': 19, 'step': 19100}
2024-08-06 12:37:08:INFO: ***** Running Dev *****
2024-08-06 12:37:08:INFO:   Num examples = 463
2024-08-06 12:37:08:INFO:   Batch size = 16
2024-08-06 12:37:13:INFO: {'acc': 0.9769618430525558, 'p': 0.9437540876389797, 'r': 0.9639278557114228, 'f1': 0.953734302709848, 'epoch': 19, 'step': 19120}
2024-08-06 12:37:13:INFO: ***** Running Test *****
2024-08-06 12:37:13:INFO:   Num examples = 477
2024-08-06 12:37:13:INFO:   Batch size = 16
2024-08-06 12:37:19:INFO: {'acc': 0.9711258278145696, 'p': 0.9463208685162847, 'r': 0.9625766871165644, 'f1': 0.9543795620437956, 'epoch': 19, 'step': 19120}
2024-08-06 12:37:19:INFO: 

Training completed. Do not forget to share your model on huggingface.co/models =)


2024-08-06 12:37:19:INFO: *** Dev Evaluate ***
2024-08-06 12:37:19:INFO: ***** Running dev *****
2024-08-06 12:37:19:INFO:   Num examples = 463
2024-08-06 12:37:19:INFO:   Batch size = 16
2024-08-06 12:37:24:INFO: Dev Result: acc: 0.9770, p: 0.9438, r: 0.9639, f1: 0.9537

2024-08-06 12:37:24:INFO: *** Test Evaluate ***
2024-08-06 12:37:24:INFO: ***** Running test *****
2024-08-06 12:37:24:INFO:   Num examples = 477
2024-08-06 12:37:24:INFO:   Batch size = 16
2024-08-06 12:37:29:INFO: Test Result: acc: 0.9711, p: 0.9463, r: 0.9626, f1: 0.9544

