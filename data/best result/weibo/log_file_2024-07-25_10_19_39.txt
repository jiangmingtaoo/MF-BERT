2024-07-25 10:19:40:INFO: Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: True, 16-bits training: False
2024-07-25 10:19:40:INFO: Training/evaluation parameters Namespace(T_mult=1, adam_epsilon=1e-08, bigram_min_freq=1, char_min_freq=1, config_name='data/berts/bert/config.json', data_dir='data/dataset/NER/weibo', dataset='weibo', decay_rate=0.999, decay_steps=200, default_label='O', device=device(type='cuda', index=0), do_eval=True, do_predict=True, do_shuffle=True, do_train=True, evaluate_during_training=True, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, label='all', label_file='data/dataset/NER/weibo/labels.txt', label_num=28, lattice=1, lattice_min_freq=1, learning_rate=1e-05, lexicon_name='yj', local_rank=0, logging_dir='data/log', logging_steps=100, max_grad_norm=1.0, max_scan_num=1000, max_seq_length=256, max_steps=-1, max_word_num=5, mid_data_dir='data/dataset/NER/weibo/mid_data', mid_label_file='data/dataset/NER/weibo/mid_data/labels.json', model_name_or_path='data/berts/bert/pytorch_model.bin', model_type='WCBertCRF_Token', n_gpu=1, no_cuda=False, nodes=2, num_tags=4, num_train_epochs=20, number_normalized=0, only_lexicon_in_train=False, only_train_min_freq=True, output_dir='data/result/NER/weibo/lebertcrf', overwrite_cache=True, per_gpu_eval_batch_size=16, per_gpu_train_batch_size=4, rewarm_epoch_num=2, save_steps=600, save_total_limit=50, saved_embedding_dir='data/dataset/NER/weibo', scheduler='CAWR', seed=106524, sgd_momentum=0.9, train_clip=False, vocab_file='data/berts/bert/vocab.txt', warmup_steps=190, weight_decay=0.0, word_embed_dim=200, word_embedding='data/embedding/word_embedding.txt', word_min_freq=1, word_vocab_file='data/vocab/tencent_vocab.txt')
2024-07-25 10:19:47:INFO: ***** Running training *****
2024-07-25 10:19:47:INFO:   Num examples = 1350
2024-07-25 10:19:47:INFO:   Num Epochs = 20
2024-07-25 10:19:47:INFO:   Instantaneous batch size per device = 4
2024-07-25 10:19:47:INFO:   Total train batch size (w. parallel, distributed & accumulation) = 4
2024-07-25 10:19:47:INFO:   Gradient Accumulation steps = 1
2024-07-25 10:19:47:INFO:   Total optimization steps = 6760
2024-07-25 10:20:19:INFO: {'loss': 6.547773418426513, 'learning_rate': 5.263157894736842e-06, 'epoch': 0, 'step': 100}
2024-07-25 10:20:44:INFO: {'loss': 1.8085450237244367, 'learning_rate': 9.999942837898412e-06, 'epoch': 0, 'step': 200}
2024-07-25 10:21:08:INFO: {'loss': 1.1873726273328067, 'learning_rate': 9.993084967039568e-06, 'epoch': 0, 'step': 300}
2024-07-25 10:21:18:INFO: ***** Running Dev *****
2024-07-25 10:21:18:INFO:   Num examples = 270
2024-07-25 10:21:18:INFO:   Batch size = 16
2024-07-25 10:21:22:INFO: {'acc': 0.9385994025887819, 'p': 0.6481481481481481, 'r': 0.10903426791277258, 'f1': 0.18666666666666668, 'epoch': 0, 'step': 338}
2024-07-25 10:21:22:INFO: ***** Running Test *****
2024-07-25 10:21:22:INFO:   Num examples = 270
2024-07-25 10:21:22:INFO:   Batch size = 16
2024-07-25 10:21:27:INFO: {'acc': 0.9362254838290687, 'p': 0.7258064516129032, 'r': 0.13157894736842105, 'f1': 0.22277227722772278, 'epoch': 0, 'step': 338}
2024-07-25 10:21:42:INFO: {'loss': 0.8258221643790603, 'learning_rate': 9.97481264038939e-06, 'epoch': 1, 'step': 400}
2024-07-25 10:22:07:INFO: {'loss': 0.5756972041912377, 'learning_rate': 9.945167629451089e-06, 'epoch': 1, 'step': 500}
2024-07-25 10:22:31:INFO: {'loss': 0.4701472792215645, 'learning_rate': 9.904217704284469e-06, 'epoch': 1, 'step': 600}
2024-07-25 10:22:49:INFO: ***** Running Dev *****
2024-07-25 10:22:49:INFO:   Num examples = 270
2024-07-25 10:22:49:INFO:   Batch size = 16
2024-07-25 10:22:54:INFO: {'acc': 0.9676734152007965, 'p': 0.7258566978193146, 'r': 0.7258566978193146, 'f1': 0.7258566978193147, 'epoch': 1, 'step': 676}
2024-07-25 10:22:54:INFO: ***** Running Test *****
2024-07-25 10:22:54:INFO:   Num examples = 270
2024-07-25 10:22:54:INFO:   Batch size = 16
2024-07-25 10:22:58:INFO: {'acc': 0.9612936745031823, 'p': 0.7065868263473054, 'r': 0.6900584795321637, 'f1': 0.6982248520710058, 'epoch': 1, 'step': 676}
2024-07-25 10:23:04:INFO: {'loss': 0.4566602799948305, 'learning_rate': 9.85205647857997e-06, 'epoch': 2, 'step': 700}
2024-07-25 10:23:28:INFO: {'loss': 0.34082887770491654, 'learning_rate': 9.788803195652852e-06, 'epoch': 2, 'step': 800}
2024-07-25 10:23:51:INFO: {'loss': 0.3382359270757297, 'learning_rate': 9.714602455846666e-06, 'epoch': 2, 'step': 900}
2024-07-25 10:24:15:INFO: {'loss': 0.35225168006581953, 'learning_rate': 9.62962388596925e-06, 'epoch': 2, 'step': 1000}
2024-07-25 10:24:18:INFO: ***** Running Dev *****
2024-07-25 10:24:18:INFO:   Num examples = 270
2024-07-25 10:24:18:INFO:   Batch size = 16
2024-07-25 10:24:23:INFO: {'acc': 0.9673415200796548, 'p': 0.7458745874587459, 'r': 0.7040498442367601, 'f1': 0.7243589743589745, 'epoch': 2, 'step': 1014}
2024-07-25 10:24:23:INFO: ***** Running Test *****
2024-07-25 10:24:23:INFO:   Num examples = 270
2024-07-25 10:24:23:INFO:   Batch size = 16
2024-07-25 10:24:27:INFO: {'acc': 0.9666190414339525, 'p': 0.7719869706840391, 'r': 0.6929824561403509, 'f1': 0.7303543913713405, 'epoch': 2, 'step': 1014}
2024-07-25 10:24:48:INFO: {'loss': 0.2844977190214559, 'learning_rate': 9.534061751516876e-06, 'epoch': 3, 'step': 1100}
2024-07-25 10:25:11:INFO: {'loss': 0.2563176006183494, 'learning_rate': 9.428134512573091e-06, 'epoch': 3, 'step': 1200}
2024-07-25 10:25:35:INFO: {'loss': 0.20351928633404895, 'learning_rate': 9.312084324397416e-06, 'epoch': 3, 'step': 1300}
2024-07-25 10:25:47:INFO: ***** Running Dev *****
2024-07-25 10:25:47:INFO:   Num examples = 270
2024-07-25 10:25:47:INFO:   Batch size = 16
2024-07-25 10:25:52:INFO: {'acc': 0.9684035844673083, 'p': 0.7357357357357357, 'r': 0.7632398753894081, 'f1': 0.7492354740061162, 'epoch': 3, 'step': 1352}
2024-07-25 10:25:52:INFO: ***** Running Test *****
2024-07-25 10:25:52:INFO:   Num examples = 270
2024-07-25 10:25:52:INFO:   Batch size = 16
2024-07-25 10:25:56:INFO: {'acc': 0.9695414988959605, 'p': 0.7462235649546828, 'r': 0.7222222222222222, 'f1': 0.7340267459138187, 'epoch': 3, 'step': 1352}
2024-07-25 10:26:08:INFO: {'loss': 0.2667860163899604, 'learning_rate': 9.186176483845655e-06, 'epoch': 4, 'step': 1400}
2024-07-25 10:26:31:INFO: {'loss': 0.21901517084043007, 'learning_rate': 9.05069882288727e-06, 'epoch': 4, 'step': 1500}
2024-07-25 10:26:55:INFO: {'loss': 0.18081524330315005, 'learning_rate': 8.905961050606311e-06, 'epoch': 4, 'step': 1600}
2024-07-25 10:27:16:INFO: ***** Running Dev *****
2024-07-25 10:27:16:INFO:   Num examples = 270
2024-07-25 10:27:16:INFO:   Batch size = 16
2024-07-25 10:27:21:INFO: {'acc': 0.9675406571523398, 'p': 0.7217125382262997, 'r': 0.735202492211838, 'f1': 0.728395061728395, 'epoch': 4, 'step': 1690}
2024-07-25 10:27:21:INFO: ***** Running Test *****
2024-07-25 10:27:21:INFO:   Num examples = 270
2024-07-25 10:27:21:INFO:   Batch size = 16
2024-07-25 10:27:25:INFO: {'acc': 0.9685024029094688, 'p': 0.7246376811594203, 'r': 0.7309941520467836, 'f1': 0.727802037845706, 'epoch': 4, 'step': 1690}
2024-07-25 10:27:27:INFO: {'loss': 0.2166192953567952, 'learning_rate': 8.7522940451901e-06, 'epoch': 5, 'step': 1700}
2024-07-25 10:27:51:INFO: {'loss': 0.1757844817318255, 'learning_rate': 8.590049097524229e-06, 'epoch': 5, 'step': 1800}
2024-07-25 10:28:15:INFO: {'loss': 0.16586060625057145, 'learning_rate': 8.419597108123054e-06, 'epoch': 5, 'step': 1900}
2024-07-25 10:28:39:INFO: {'loss': 0.15691977260074055, 'learning_rate': 8.24132773923154e-06, 'epoch': 5, 'step': 2000}
2024-07-25 10:28:45:INFO: ***** Running Dev *****
2024-07-25 10:28:45:INFO:   Num examples = 270
2024-07-25 10:28:45:INFO:   Batch size = 16
2024-07-25 10:28:50:INFO: {'acc': 0.9690673747095918, 'p': 0.7530864197530864, 'r': 0.7601246105919003, 'f1': 0.7565891472868217, 'epoch': 5, 'step': 2028}
2024-07-25 10:28:50:INFO: ***** Running Test *****
2024-07-25 10:28:50:INFO:   Num examples = 270
2024-07-25 10:28:50:INFO:   Batch size = 16
2024-07-25 10:28:54:INFO: {'acc': 0.9717495778672555, 'p': 0.7421203438395415, 'r': 0.7573099415204678, 'f1': 0.7496382054992764, 'epoch': 5, 'step': 2028}
2024-07-25 10:29:11:INFO: {'loss': 0.11621924180664792, 'learning_rate': 8.05564852403681e-06, 'epoch': 6, 'step': 2100}
2024-07-25 10:29:35:INFO: {'loss': 0.16260211804656138, 'learning_rate': 7.862983935025745e-06, 'epoch': 6, 'step': 2200}
2024-07-25 10:29:59:INFO: {'loss': 0.14430574053856618, 'learning_rate': 7.663774413618504e-06, 'epoch': 6, 'step': 2300}
2024-07-25 10:30:14:INFO: ***** Running Dev *****
2024-07-25 10:30:14:INFO:   Num examples = 270
2024-07-25 10:30:14:INFO:   Batch size = 16
2024-07-25 10:30:19:INFO: {'acc': 0.968536342515765, 'p': 0.7704918032786885, 'r': 0.7320872274143302, 'f1': 0.7507987220447284, 'epoch': 6, 'step': 2366}
2024-07-25 10:30:19:INFO: ***** Running Test *****
2024-07-25 10:30:19:INFO:   Num examples = 270
2024-07-25 10:30:19:INFO:   Batch size = 16
2024-07-25 10:30:23:INFO: {'acc': 0.9708403688790752, 'p': 0.7720364741641338, 'r': 0.7426900584795322, 'f1': 0.7570789865871833, 'epoch': 6, 'step': 2366}
2024-07-25 10:30:31:INFO: {'loss': 0.14609931694572878, 'learning_rate': 7.45847536329616e-06, 'epoch': 7, 'step': 2400}
2024-07-25 10:30:55:INFO: {'loss': 0.10915247229706437, 'learning_rate': 7.24755610852433e-06, 'epoch': 7, 'step': 2500}
2024-07-25 10:31:19:INFO: {'loss': 0.12512696061050518, 'learning_rate': 7.031498821852654e-06, 'epoch': 7, 'step': 2600}
2024-07-25 10:31:43:INFO: {'loss': 0.13118433486470166, 'learning_rate': 6.8107974216429005e-06, 'epoch': 7, 'step': 2700}
2024-07-25 10:31:43:INFO: ***** Running Dev *****
2024-07-25 10:31:43:INFO:   Num examples = 270
2024-07-25 10:31:43:INFO:   Batch size = 16
2024-07-25 10:31:48:INFO: {'acc': 0.9707268503153004, 'p': 0.7959183673469388, 'r': 0.7289719626168224, 'f1': 0.7609756097560975, 'epoch': 7, 'step': 2704}
2024-07-25 10:31:48:INFO: ***** Running Test *****
2024-07-25 10:31:48:INFO:   Num examples = 270
2024-07-25 10:31:48:INFO:   Batch size = 16
2024-07-25 10:31:52:INFO: {'acc': 0.9710351993765424, 'p': 0.7678018575851393, 'r': 0.7251461988304093, 'f1': 0.7458646616541353, 'epoch': 7, 'step': 2704}
2024-07-25 10:32:15:INFO: {'loss': 0.08293242936742899, 'learning_rate': 6.585956442945531e-06, 'epoch': 8, 'step': 2800}
2024-07-25 10:32:39:INFO: {'loss': 0.09401407326500703, 'learning_rate': 6.357489884105927e-06, 'epoch': 8, 'step': 2900}
2024-07-25 10:33:03:INFO: {'loss': 0.12969724144951214, 'learning_rate': 6.125920031737054e-06, 'epoch': 8, 'step': 3000}
2024-07-25 10:33:13:INFO: ***** Running Dev *****
2024-07-25 10:33:13:INFO:   Num examples = 270
2024-07-25 10:33:13:INFO:   Batch size = 16
2024-07-25 10:33:17:INFO: {'acc': 0.9697311649518752, 'p': 0.7546583850931677, 'r': 0.7570093457943925, 'f1': 0.7558320373250388, 'epoch': 8, 'step': 3042}
2024-07-25 10:33:17:INFO: ***** Running Test *****
2024-07-25 10:33:17:INFO:   Num examples = 270
2024-07-25 10:33:17:INFO:   Batch size = 16
2024-07-25 10:33:21:INFO: {'acc': 0.9722691258605014, 'p': 0.7421203438395415, 'r': 0.7573099415204678, 'f1': 0.7496382054992764, 'epoch': 8, 'step': 3042}
2024-07-25 10:33:35:INFO: {'loss': 0.09504194438001833, 'learning_rate': 5.891776266744686e-06, 'epoch': 9, 'step': 3100}
2024-07-25 10:33:59:INFO: {'loss': 0.07337756567030737, 'learning_rate': 5.655593854134721e-06, 'epoch': 9, 'step': 3200}
2024-07-25 10:34:22:INFO: {'loss': 0.11205403094925714, 'learning_rate': 5.417912719369116e-06, 'epoch': 9, 'step': 3300}
2024-07-25 10:34:42:INFO: ***** Running Dev *****
2024-07-25 10:34:42:INFO:   Num examples = 270
2024-07-25 10:34:42:INFO:   Batch size = 16
2024-07-25 10:34:46:INFO: {'acc': 0.9705277132426153, 'p': 0.7552870090634441, 'r': 0.778816199376947, 'f1': 0.7668711656441717, 'epoch': 9, 'step': 3380}
2024-07-25 10:34:46:INFO: ***** Running Test *****
2024-07-25 10:34:46:INFO:   Num examples = 270
2024-07-25 10:34:46:INFO:   Batch size = 16
2024-07-25 10:34:51:INFO: {'acc': 0.9717495778672555, 'p': 0.7344632768361582, 'r': 0.7602339181286549, 'f1': 0.7471264367816092, 'epoch': 9, 'step': 3380}
2024-07-25 10:34:55:INFO: {'loss': 0.10147562729174751, 'learning_rate': 5.179276214067788e-06, 'epoch': 10, 'step': 3400}
2024-07-25 10:35:19:INFO: {'loss': 0.06027394528297009, 'learning_rate': 4.940229873878123e-06, 'epoch': 10, 'step': 3500}
2024-07-25 10:35:43:INFO: {'loss': 0.07344762737415295, 'learning_rate': 4.7013201713517006e-06, 'epoch': 10, 'step': 3600}
2024-07-25 10:36:07:INFO: {'loss': 0.08340244253347918, 'learning_rate': 4.463093266679185e-06, 'epoch': 10, 'step': 3700}
2024-07-25 10:36:12:INFO: ***** Running Dev *****
2024-07-25 10:36:12:INFO:   Num examples = 270
2024-07-25 10:36:12:INFO:   Batch size = 16
2024-07-25 10:36:16:INFO: {'acc': 0.9701958181214736, 'p': 0.7371601208459214, 'r': 0.7601246105919003, 'f1': 0.7484662576687117, 'epoch': 10, 'step': 3718}
2024-07-25 10:36:16:INFO: ***** Running Test *****
2024-07-25 10:36:16:INFO:   Num examples = 270
2024-07-25 10:36:16:INFO:   Batch size = 16
2024-07-25 10:36:20:INFO: {'acc': 0.9711650863748539, 'p': 0.7401129943502824, 'r': 0.7660818713450293, 'f1': 0.7528735632183908, 'epoch': 10, 'step': 3718}
2024-07-25 10:36:40:INFO: {'loss': 0.04903685104514352, 'learning_rate': 4.226093759139307e-06, 'epoch': 11, 'step': 3800}
2024-07-25 10:37:04:INFO: {'loss': 0.05585093264243369, 'learning_rate': 3.990863442116164e-06, 'epoch': 11, 'step': 3900}
2024-07-25 10:37:28:INFO: {'loss': 0.0661400418903213, 'learning_rate': 3.75794006453095e-06, 'epoch': 11, 'step': 4000}
2024-07-25 10:37:41:INFO: ***** Running Dev *****
2024-07-25 10:37:41:INFO:   Num examples = 270
2024-07-25 10:37:41:INFO:   Batch size = 16
2024-07-25 10:37:45:INFO: {'acc': 0.9720544307998672, 'p': 0.771875, 'r': 0.7694704049844237, 'f1': 0.7706708268330733, 'epoch': 11, 'step': 4056}
2024-07-25 10:37:45:INFO: ***** Running Test *****
2024-07-25 10:37:45:INFO:   Num examples = 270
2024-07-25 10:37:45:INFO:   Batch size = 16
2024-07-25 10:37:49:INFO: {'acc': 0.9721392388621899, 'p': 0.7397660818713451, 'r': 0.7397660818713451, 'f1': 0.7397660818713451, 'epoch': 11, 'step': 4056}
2024-07-25 10:38:00:INFO: {'loss': 0.08415112077773301, 'learning_rate': 3.5278561015195273e-06, 'epoch': 12, 'step': 4100}
2024-07-25 10:38:24:INFO: {'loss': 0.046481747933999035, 'learning_rate': 3.3011375371661723e-06, 'epoch': 12, 'step': 4200}
2024-07-25 10:38:48:INFO: {'loss': 0.07535104007629798, 'learning_rate': 3.0783026620761846e-06, 'epoch': 12, 'step': 4300}
2024-07-25 10:39:10:INFO: ***** Running Dev *****
2024-07-25 10:39:10:INFO:   Num examples = 270
2024-07-25 10:39:10:INFO:   Batch size = 16
2024-07-25 10:39:15:INFO: {'acc': 0.9708596083637571, 'p': 0.7507507507507507, 'r': 0.778816199376947, 'f1': 0.764525993883792, 'epoch': 12, 'step': 4394}
2024-07-25 10:39:15:INFO: ***** Running Test *****
2024-07-25 10:39:15:INFO:   Num examples = 270
2024-07-25 10:39:15:INFO:   Batch size = 16
2024-07-25 10:39:19:INFO: {'acc': 0.9735030523444603, 'p': 0.7298050139275766, 'r': 0.7660818713450293, 'f1': 0.7475035663338089, 'epoch': 12, 'step': 4394}
2024-07-25 10:39:20:INFO: {'loss': 0.05017548512081703, 'learning_rate': 2.8598608885362124e-06, 'epoch': 13, 'step': 4400}
2024-07-25 10:39:44:INFO: {'loss': 0.04441981427373321, 'learning_rate': 2.64631158597087e-06, 'epoch': 13, 'step': 4500}
2024-07-25 10:40:08:INFO: {'loss': 0.05313015108384661, 'learning_rate': 2.438142939357882e-06, 'epoch': 13, 'step': 4600}
2024-07-25 10:40:32:INFO: {'loss': 0.0575213403280577, 'learning_rate': 2.2358308332114497e-06, 'epoch': 13, 'step': 4700}
2024-07-25 10:40:39:INFO: ***** Running Dev *****
2024-07-25 10:40:39:INFO:   Num examples = 270
2024-07-25 10:40:39:INFO:   Batch size = 16
2024-07-25 10:40:44:INFO: {'acc': 0.9695984069034185, 'p': 0.7315634218289085, 'r': 0.7725856697819314, 'f1': 0.7515151515151515, 'epoch': 13, 'step': 4732}
2024-07-25 10:40:44:INFO: ***** Running Test *****
2024-07-25 10:40:44:INFO:   Num examples = 270
2024-07-25 10:40:44:INFO:   Batch size = 16
2024-07-25 10:40:48:INFO: {'acc': 0.9729835043512144, 'p': 0.7394957983193278, 'r': 0.7719298245614035, 'f1': 0.7553648068669527, 'epoch': 13, 'step': 4732}
2024-07-25 10:41:04:INFO: {'loss': 0.04742433372321557, 'learning_rate': 2.0398377636851364e-06, 'epoch': 14, 'step': 4800}
2024-07-25 10:41:28:INFO: {'loss': 0.05570257131736753, 'learning_rate': 1.850611781281239e-06, 'epoch': 14, 'step': 4900}
2024-07-25 10:41:52:INFO: {'loss': 0.04566772248160305, 'learning_rate': 1.6685854665837037e-06, 'epoch': 14, 'step': 5000}
2024-07-25 10:42:08:INFO: ***** Running Dev *****
2024-07-25 10:42:08:INFO:   Num examples = 270
2024-07-25 10:42:08:INFO:   Batch size = 16
2024-07-25 10:42:13:INFO: {'acc': 0.9699303020245602, 'p': 0.75625, 'r': 0.7538940809968847, 'f1': 0.7550702028081123, 'epoch': 14, 'step': 5070}
2024-07-25 10:42:13:INFO: ***** Running Test *****
2024-07-25 10:42:13:INFO:   Num examples = 270
2024-07-25 10:42:13:INFO:   Batch size = 16
2024-07-25 10:42:17:INFO: {'acc': 0.9730484478503701, 'p': 0.7610619469026548, 'r': 0.7543859649122807, 'f1': 0.7577092511013216, 'epoch': 14, 'step': 5070}
2024-07-25 10:42:24:INFO: {'loss': 0.04196357186960313, 'learning_rate': 1.4941749413560675e-06, 'epoch': 15, 'step': 5100}
2024-07-25 10:42:48:INFO: {'loss': 0.028217620181005713, 'learning_rate': 1.327778917265144e-06, 'epoch': 15, 'step': 5200}
2024-07-25 10:43:12:INFO: {'loss': 0.04007468825530168, 'learning_rate': 1.1697777844051105e-06, 'epoch': 15, 'step': 5300}
2024-07-25 10:43:36:INFO: {'loss': 0.057643082032213896, 'learning_rate': 1.0205327417056681e-06, 'epoch': 15, 'step': 5400}
2024-07-25 10:43:38:INFO: ***** Running Dev *****
2024-07-25 10:43:38:INFO:   Num examples = 270
2024-07-25 10:43:38:INFO:   Batch size = 16
2024-07-25 10:43:42:INFO: {'acc': 0.9705277132426153, 'p': 0.759375, 'r': 0.7570093457943925, 'f1': 0.7581903276131045, 'epoch': 15, 'step': 5408}
2024-07-25 10:43:42:INFO: ***** Running Test *****
2024-07-25 10:43:42:INFO:   Num examples = 270
2024-07-25 10:43:42:INFO:   Batch size = 16
2024-07-25 10:43:46:INFO: {'acc': 0.9727886738537472, 'p': 0.752906976744186, 'r': 0.7573099415204678, 'f1': 0.7551020408163266, 'epoch': 15, 'step': 5408}
2024-07-25 10:44:08:INFO: {'loss': 0.02939036670192763, 'learning_rate': 8.803849712122292e-07, 'epoch': 16, 'step': 5500}
2024-07-25 10:44:32:INFO: {'loss': 0.04818489423090796, 'learning_rate': 7.49654858125749e-07, 'epoch': 16, 'step': 5600}
2024-07-25 10:44:55:INFO: {'loss': 0.04345179227899962, 'learning_rate': 6.28641258385247e-07, 'epoch': 16, 'step': 5700}
2024-07-25 10:45:06:INFO: ***** Running Dev *****
2024-07-25 10:45:06:INFO:   Num examples = 270
2024-07-25 10:45:06:INFO:   Batch size = 16
2024-07-25 10:45:11:INFO: {'acc': 0.9711251244606705, 'p': 0.7585139318885449, 'r': 0.7632398753894081, 'f1': 0.7608695652173914, 'epoch': 16, 'step': 5746}
2024-07-25 10:45:11:INFO: ***** Running Test *****
2024-07-25 10:45:11:INFO:   Num examples = 270
2024-07-25 10:45:11:INFO:   Batch size = 16
2024-07-25 10:45:15:INFO: {'acc': 0.9720742953630341, 'p': 0.752906976744186, 'r': 0.7573099415204678, 'f1': 0.7551020408163266, 'epoch': 16, 'step': 5746}
2024-07-25 10:45:28:INFO: {'loss': 0.03957470876519892, 'learning_rate': 5.176208154673502e-07, 'epoch': 17, 'step': 5800}
2024-07-25 10:45:52:INFO: {'loss': 0.045090160285219553, 'learning_rate': 4.1684732796471115e-07, 'epoch': 17, 'step': 5900}
2024-07-25 10:46:15:INFO: {'loss': 0.04017417258872911, 'learning_rate': 3.2655116938902167e-07, 'epoch': 17, 'step': 6000}
2024-07-25 10:46:35:INFO: ***** Running Dev *****
2024-07-25 10:46:35:INFO:   Num examples = 270
2024-07-25 10:46:35:INFO:   Batch size = 16
2024-07-25 10:46:40:INFO: {'acc': 0.9703285761699303, 'p': 0.7469512195121951, 'r': 0.7632398753894081, 'f1': 0.7550077041602464, 'epoch': 17, 'step': 6084}
2024-07-25 10:46:40:INFO: ***** Running Test *****
2024-07-25 10:46:40:INFO:   Num examples = 270
2024-07-25 10:46:40:INFO:   Batch size = 16
2024-07-25 10:46:44:INFO: {'acc': 0.9724639563579686, 'p': 0.7449856733524355, 'r': 0.7602339181286549, 'f1': 0.752532561505065, 'epoch': 17, 'step': 6084}
2024-07-25 10:46:48:INFO: {'loss': 0.03266106403475078, 'learning_rate': 2.469387615250096e-07, 'epoch': 18, 'step': 6100}
2024-07-25 10:47:12:INFO: {'loss': 0.03939570749291988, 'learning_rate': 1.7819210253934072e-07, 'epoch': 18, 'step': 6200}
2024-07-25 10:47:36:INFO: {'loss': 0.03068101321450058, 'learning_rate': 1.2046835092320132e-07, 'epoch': 18, 'step': 6300}
2024-07-25 10:48:00:INFO: {'loss': 0.0275312914520714, 'learning_rate': 7.389946621969679e-08, 'epoch': 18, 'step': 6400}
2024-07-25 10:48:05:INFO: ***** Running Dev *****
2024-07-25 10:48:05:INFO:   Num examples = 270
2024-07-25 10:48:05:INFO:   Batch size = 16
2024-07-25 10:48:09:INFO: {'acc': 0.9705277132426153, 'p': 0.7515337423312883, 'r': 0.7632398753894081, 'f1': 0.7573415765069551, 'epoch': 18, 'step': 6422}
2024-07-25 10:48:09:INFO: ***** Running Test *****
2024-07-25 10:48:09:INFO:   Num examples = 270
2024-07-25 10:48:09:INFO:   Batch size = 16
2024-07-25 10:48:14:INFO: {'acc': 0.9720093518638784, 'p': 0.7492795389048992, 'r': 0.7602339181286549, 'f1': 0.7547169811320754, 'epoch': 18, 'step': 6422}
2024-07-25 10:48:32:INFO: {'loss': 0.041344969843116815, 'learning_rate': 3.859190735736762e-08, 'epoch': 19, 'step': 6500}
2024-07-25 10:48:56:INFO: {'loss': 0.026727895529352282, 'learning_rate': 1.4626389279458475e-08, 'epoch': 19, 'step': 6600}
2024-07-25 10:49:20:INFO: {'loss': 0.03898981658247522, 'learning_rate': 2.05769842529957e-09, 'epoch': 19, 'step': 6700}
2024-07-25 10:49:34:INFO: ***** Running Dev *****
2024-07-25 10:49:34:INFO:   Num examples = 270
2024-07-25 10:49:34:INFO:   Batch size = 16
2024-07-25 10:49:38:INFO: {'acc': 0.970461334218387, 'p': 0.7492354740061162, 'r': 0.7632398753894081, 'f1': 0.7561728395061729, 'epoch': 19, 'step': 6760}
2024-07-25 10:49:38:INFO: ***** Running Test *****
2024-07-25 10:49:38:INFO:   Num examples = 270
2024-07-25 10:49:38:INFO:   Batch size = 16
2024-07-25 10:49:43:INFO: {'acc': 0.9722691258605014, 'p': 0.7492795389048992, 'r': 0.7602339181286549, 'f1': 0.7547169811320754, 'epoch': 19, 'step': 6760}
2024-07-25 10:49:43:INFO: 

Training completed. Do not forget to share your model on huggingface.co/models =)


2024-07-25 10:49:43:INFO: *** Dev Evaluate ***
2024-07-25 10:49:43:INFO: ***** Running dev *****
2024-07-25 10:49:43:INFO:   Num examples = 270
2024-07-25 10:49:43:INFO:   Batch size = 16
2024-07-25 10:49:47:INFO: Dev Result: acc: 0.9705, p: 0.7492, r: 0.7632, f1: 0.7562

2024-07-25 10:49:47:INFO: *** Test Evaluate ***
2024-07-25 10:49:47:INFO: ***** Running test *****
2024-07-25 10:49:47:INFO:   Num examples = 270
2024-07-25 10:49:47:INFO:   Batch size = 16
2024-07-25 10:49:52:INFO: Test Result: acc: 0.9723, p: 0.7493, r: 0.7602, f1: 0.7547

